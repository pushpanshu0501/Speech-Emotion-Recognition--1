{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "actors_split ~ 39%CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+VIXk7hVufVz5769MoWE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaka3021/Speech-Emotion-Recognition--1/blob/main/actors_split_~_39_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clob-Oh-_TYT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foo3EgoQM1eu"
      },
      "source": [
        "def plotter(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'],label='train loss')\n",
        "  plt.plot(history.history['val_loss'],label='test loss')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('losses')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'],label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'],label='test accuracy')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HAccvSC_XWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "d67e294e-212f-4490-eaa7-ea227051dae1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Features = pd.read_csv('/content/drive/MyDrive/features_dataset.csv')\n",
        "Features.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.272267</td>\n",
              "      <td>0.689451</td>\n",
              "      <td>0.708028</td>\n",
              "      <td>0.666473</td>\n",
              "      <td>0.715468</td>\n",
              "      <td>0.694820</td>\n",
              "      <td>0.627661</td>\n",
              "      <td>0.632560</td>\n",
              "      <td>0.687715</td>\n",
              "      <td>0.712157</td>\n",
              "      <td>0.706116</td>\n",
              "      <td>0.696561</td>\n",
              "      <td>0.666424</td>\n",
              "      <td>-505.009247</td>\n",
              "      <td>64.000099</td>\n",
              "      <td>-2.749660</td>\n",
              "      <td>16.950371</td>\n",
              "      <td>-1.089467</td>\n",
              "      <td>-2.046432</td>\n",
              "      <td>-7.829981</td>\n",
              "      <td>-8.716751</td>\n",
              "      <td>-19.273317</td>\n",
              "      <td>-5.294091</td>\n",
              "      <td>-5.584455</td>\n",
              "      <td>-5.783628</td>\n",
              "      <td>-1.870991</td>\n",
              "      <td>-7.146638</td>\n",
              "      <td>-3.675263</td>\n",
              "      <td>-0.451763</td>\n",
              "      <td>-11.253410</td>\n",
              "      <td>-3.521277</td>\n",
              "      <td>-3.482842</td>\n",
              "      <td>-5.802355</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.018095</td>\n",
              "      <td>0.134511</td>\n",
              "      <td>0.229614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>0.002306</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001945</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.003231</td>\n",
              "      <td>0.002353</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.002131</td>\n",
              "      <td>0.001839</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001006</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>1.498768e-05</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.262035</td>\n",
              "      <td>0.603476</td>\n",
              "      <td>0.668302</td>\n",
              "      <td>0.692199</td>\n",
              "      <td>0.709884</td>\n",
              "      <td>0.658301</td>\n",
              "      <td>0.605176</td>\n",
              "      <td>0.609343</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>0.689348</td>\n",
              "      <td>0.702884</td>\n",
              "      <td>0.687124</td>\n",
              "      <td>0.663653</td>\n",
              "      <td>-626.262817</td>\n",
              "      <td>93.897247</td>\n",
              "      <td>-0.691273</td>\n",
              "      <td>17.833763</td>\n",
              "      <td>9.502007</td>\n",
              "      <td>2.030928</td>\n",
              "      <td>-2.721135</td>\n",
              "      <td>-8.514406</td>\n",
              "      <td>-12.427499</td>\n",
              "      <td>-6.575863</td>\n",
              "      <td>-0.015912</td>\n",
              "      <td>-2.750585</td>\n",
              "      <td>0.777975</td>\n",
              "      <td>-5.365466</td>\n",
              "      <td>-0.337154</td>\n",
              "      <td>1.482861</td>\n",
              "      <td>-8.703282</td>\n",
              "      <td>-2.764846</td>\n",
              "      <td>-1.618086</td>\n",
              "      <td>-1.523441</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.008725</td>\n",
              "      <td>0.090577</td>\n",
              "      <td>0.060794</td>\n",
              "      <td>0.002684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>8.432723e-07</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.195466</td>\n",
              "      <td>0.628032</td>\n",
              "      <td>0.687169</td>\n",
              "      <td>0.651985</td>\n",
              "      <td>0.621273</td>\n",
              "      <td>0.604192</td>\n",
              "      <td>0.640623</td>\n",
              "      <td>0.626136</td>\n",
              "      <td>0.652430</td>\n",
              "      <td>0.685134</td>\n",
              "      <td>0.653014</td>\n",
              "      <td>0.649654</td>\n",
              "      <td>0.632400</td>\n",
              "      <td>-535.881226</td>\n",
              "      <td>82.281357</td>\n",
              "      <td>-9.010551</td>\n",
              "      <td>20.842283</td>\n",
              "      <td>5.421832</td>\n",
              "      <td>-3.754339</td>\n",
              "      <td>-10.541499</td>\n",
              "      <td>-13.465772</td>\n",
              "      <td>-27.917681</td>\n",
              "      <td>-6.894572</td>\n",
              "      <td>-3.809465</td>\n",
              "      <td>-10.429282</td>\n",
              "      <td>0.157545</td>\n",
              "      <td>-7.953777</td>\n",
              "      <td>-6.011678</td>\n",
              "      <td>2.456674</td>\n",
              "      <td>-10.448029</td>\n",
              "      <td>-6.485257</td>\n",
              "      <td>-4.687830</td>\n",
              "      <td>-3.553447</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.016251</td>\n",
              "      <td>0.110550</td>\n",
              "      <td>0.186236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.000436</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>2.326331e-06</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.173769</td>\n",
              "      <td>0.720864</td>\n",
              "      <td>0.685492</td>\n",
              "      <td>0.655122</td>\n",
              "      <td>0.652557</td>\n",
              "      <td>0.587786</td>\n",
              "      <td>0.550012</td>\n",
              "      <td>0.638170</td>\n",
              "      <td>0.707171</td>\n",
              "      <td>0.648498</td>\n",
              "      <td>0.604207</td>\n",
              "      <td>0.638241</td>\n",
              "      <td>0.707306</td>\n",
              "      <td>-526.520569</td>\n",
              "      <td>84.466164</td>\n",
              "      <td>-6.822329</td>\n",
              "      <td>22.756920</td>\n",
              "      <td>8.021371</td>\n",
              "      <td>-0.836710</td>\n",
              "      <td>-6.375116</td>\n",
              "      <td>-13.950517</td>\n",
              "      <td>-15.801805</td>\n",
              "      <td>-1.701238</td>\n",
              "      <td>-3.240356</td>\n",
              "      <td>-2.120920</td>\n",
              "      <td>-1.001574</td>\n",
              "      <td>-5.576652</td>\n",
              "      <td>-0.277861</td>\n",
              "      <td>0.180505</td>\n",
              "      <td>-5.214784</td>\n",
              "      <td>-4.889361</td>\n",
              "      <td>-1.206443</td>\n",
              "      <td>2.497521</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.052773</td>\n",
              "      <td>0.284222</td>\n",
              "      <td>0.078999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>0.001356</td>\n",
              "      <td>0.000967</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>4.691918e-06</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.207284</td>\n",
              "      <td>0.692981</td>\n",
              "      <td>0.737456</td>\n",
              "      <td>0.726056</td>\n",
              "      <td>0.685032</td>\n",
              "      <td>0.636497</td>\n",
              "      <td>0.568223</td>\n",
              "      <td>0.528898</td>\n",
              "      <td>0.598124</td>\n",
              "      <td>0.635435</td>\n",
              "      <td>0.643268</td>\n",
              "      <td>0.671737</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>-591.298523</td>\n",
              "      <td>92.935883</td>\n",
              "      <td>-4.376369</td>\n",
              "      <td>22.136271</td>\n",
              "      <td>9.728477</td>\n",
              "      <td>-3.868228</td>\n",
              "      <td>-4.231765</td>\n",
              "      <td>-12.517565</td>\n",
              "      <td>-17.417633</td>\n",
              "      <td>-6.273466</td>\n",
              "      <td>-7.159021</td>\n",
              "      <td>-2.124696</td>\n",
              "      <td>-2.085358</td>\n",
              "      <td>-9.489192</td>\n",
              "      <td>-3.802913</td>\n",
              "      <td>-1.608241</td>\n",
              "      <td>-9.055273</td>\n",
              "      <td>-6.693238</td>\n",
              "      <td>-5.338201</td>\n",
              "      <td>-0.922801</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.001787</td>\n",
              "      <td>0.018344</td>\n",
              "      <td>0.063987</td>\n",
              "      <td>0.039720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.218449e-07</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1  ...       159           160  labels\n",
              "0           0  0.272267  0.689451  ...  0.000143  1.498768e-05   angry\n",
              "1           1  0.262035  0.603476  ...  0.000011  8.432723e-07    calm\n",
              "2           2  0.195466  0.628032  ...  0.000031  2.326331e-06     sad\n",
              "3           3  0.173769  0.720864  ...  0.000074  4.691918e-06    fear\n",
              "4           4  0.207284  0.692981  ...  0.000008  4.218449e-07     sad\n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFwdQVP_cIo",
        "outputId": "e23dc844-c19d-4c46-a0bd-d4640fe28d98"
      },
      "source": [
        "print(Features.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1440, 163)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa_TVTXk_tap"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8W3pRHg_25_",
        "outputId": "b9700f1a-378d-40fd-cd92-85640a64dc4d"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = Features.iloc[:, :-1]\n",
        "y = Features.iloc[:, -1:]\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, shuffle = False)\n",
        "\n",
        "print(train_features)\n",
        "print(train_labels)\n",
        "print(test_features)\n",
        "print(test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0         0         1  ...       158       159           160\n",
            "0              0  0.272267  0.689451  ...  0.000349  0.000143  1.498768e-05\n",
            "1              1  0.262035  0.603476  ...  0.000032  0.000011  8.432723e-07\n",
            "2              2  0.195466  0.628032  ...  0.000090  0.000031  2.326331e-06\n",
            "3              3  0.173769  0.720864  ...  0.000190  0.000074  4.691918e-06\n",
            "4              4  0.207284  0.692981  ...  0.000016  0.000008  4.218449e-07\n",
            "...          ...       ...       ...  ...       ...       ...           ...\n",
            "1075        1075  0.268699  0.653078  ...  0.000087  0.000028  1.314719e-06\n",
            "1076        1076  0.253282  0.658438  ...  0.000367  0.000131  5.384827e-06\n",
            "1077        1077  0.202781  0.504101  ...  0.000406  0.000102  7.310160e-06\n",
            "1078        1078  0.264436  0.465156  ...  0.003773  0.001310  6.904505e-05\n",
            "1079        1079  0.252297  0.660724  ...  0.000255  0.000088  1.012989e-05\n",
            "\n",
            "[1080 rows x 162 columns]\n",
            "        labels\n",
            "0        angry\n",
            "1         calm\n",
            "2          sad\n",
            "3         fear\n",
            "4          sad\n",
            "...        ...\n",
            "1075  surprise\n",
            "1076      fear\n",
            "1077     angry\n",
            "1078      fear\n",
            "1079  surprise\n",
            "\n",
            "[1080 rows x 1 columns]\n",
            "      Unnamed: 0         0         1  ...       158           159           160\n",
            "1080        1080  0.185664  0.589081  ...  0.000014  4.292963e-06  2.335350e-07\n",
            "1081        1081  0.164280  0.599939  ...  0.000009  2.973806e-06  2.068603e-07\n",
            "1082        1082  0.205526  0.629672  ...  0.000002  6.027217e-07  5.679533e-08\n",
            "1083        1083  0.129991  0.416947  ...  0.000007  2.100346e-06  1.210619e-07\n",
            "1084        1084  0.114158  0.636168  ...  0.000008  2.345038e-06  2.528446e-07\n",
            "...          ...       ...       ...  ...       ...           ...           ...\n",
            "1435        1435  0.215621  0.676596  ...  0.001930  5.237590e-04  4.048015e-05\n",
            "1436        1436  0.286517  0.659849  ...  0.000245  8.034449e-05  6.749073e-06\n",
            "1437        1437  0.215757  0.712286  ...  0.000032  1.159408e-05  1.061039e-06\n",
            "1438        1438  0.225016  0.702249  ...  0.002030  6.978391e-04  3.368497e-05\n",
            "1439        1439  0.197704  0.676930  ...  0.000567  1.824358e-04  1.365664e-05\n",
            "\n",
            "[360 rows x 162 columns]\n",
            "        labels\n",
            "1080   neutral\n",
            "1081      calm\n",
            "1082   neutral\n",
            "1083      calm\n",
            "1084      calm\n",
            "...        ...\n",
            "1435  surprise\n",
            "1436  surprise\n",
            "1437   disgust\n",
            "1438   disgust\n",
            "1439   disgust\n",
            "\n",
            "[360 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOnzfilhxGaw",
        "outputId": "b4666ec9-8214-4400-8cef-33184c170928"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 162)\n",
            "(360, 162)\n",
            "(1080, 1)\n",
            "(360, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFujBWkgE5PC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d41851-6a3e-4d7b-fdef-07e1ed6f0a0b"
      },
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# train_features = scaler.fit_transform(train_features)\n",
        "# test_features = scaler.transform(test_features)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train = np.array(train_features)\n",
        "y_train = np.array(train_labels)\n",
        "X_test = np.array(test_features)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "[[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "[[0.00000000e+00 2.72266529e-01 6.89450800e-01 ... 3.48939153e-04\n",
            "  1.43479163e-04 1.49876769e-05]\n",
            " [1.00000000e+00 2.62035229e-01 6.03476107e-01 ... 3.21593106e-05\n",
            "  1.13361612e-05 8.43272346e-07]\n",
            " [2.00000000e+00 1.95466218e-01 6.28031611e-01 ... 8.95039266e-05\n",
            "  3.05781650e-05 2.32633079e-06]\n",
            " ...\n",
            " [1.07700000e+03 2.02781395e-01 5.04100502e-01 ... 4.05550440e-04\n",
            "  1.01599842e-04 7.31016007e-06]\n",
            " [1.07800000e+03 2.64435945e-01 4.65155989e-01 ... 3.77334305e-03\n",
            "  1.31023477e-03 6.90450543e-05]\n",
            " [1.07900000e+03 2.52296730e-01 6.60724103e-01 ... 2.55107298e-04\n",
            "  8.76567647e-05 1.01298874e-05]]\n",
            "[[1.08000000e+03 1.85664424e-01 5.89080572e-01 ... 1.40154862e-05\n",
            "  4.29296279e-06 2.33535033e-07]\n",
            " [1.08100000e+03 1.64279514e-01 5.99938989e-01 ... 8.90708088e-06\n",
            "  2.97380643e-06 2.06860278e-07]\n",
            " [1.08200000e+03 2.05525716e-01 6.29672348e-01 ... 2.19595836e-06\n",
            "  6.02721684e-07 5.67953329e-08]\n",
            " ...\n",
            " [1.43700000e+03 2.15757017e-01 7.12286234e-01 ... 3.17970844e-05\n",
            "  1.15940811e-05 1.06103914e-06]\n",
            " [1.43800000e+03 2.25016276e-01 7.02248812e-01 ... 2.02970090e-03\n",
            "  6.97839132e-04 3.36849735e-05]\n",
            " [1.43900000e+03 1.97704174e-01 6.76929712e-01 ... 5.66771720e-04\n",
            "  1.82435848e-04 1.36566414e-05]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcJxphzkF5A1"
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peGRc-1CF7s1",
        "outputId": "239ff094-b728-4836-9460-6b9a1688dad5"
      },
      "source": [
        "print('Train dimension:')\n",
        "print(x_train.shape)\n",
        "print('Test dimension:')\n",
        "print(x_test.shape)\n",
        "\n",
        "print('Train labels dimension:')\n",
        "print(y_train.shape)\n",
        "print('Test labels dimension:')\n",
        "print(y_test.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dimension:\n",
            "(1080, 162, 1)\n",
            "Test dimension:\n",
            "(360, 162, 1)\n",
            "Train labels dimension:\n",
            "(1080, 8)\n",
            "Test labels dimension:\n",
            "(360, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPPiB15mF-W4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dd3dd5-34ed-4a7f-a79b-8d3a2b1e7f49"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers, optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(64, 5,padding='same',))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
        "opt = keras.optimizers.Adam(lr=0.0001)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdy6dtQ_GHOj",
        "outputId": "0d2798e2-f1c9-4390-cde2-0e1d55ce5dfa"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy'])\n",
        "history=model.fit(x_traincnn, y_train, batch_size=256, epochs=1000, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 34s 249ms/step - loss: 3.5036 - accuracy: 0.1298 - val_loss: 2.0438 - val_accuracy: 0.1694\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0948 - accuracy: 0.1699 - val_loss: 2.0309 - val_accuracy: 0.1833\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0777 - accuracy: 0.1602 - val_loss: 1.9835 - val_accuracy: 0.1750\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0378 - accuracy: 0.1835 - val_loss: 1.9580 - val_accuracy: 0.2361\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9974 - accuracy: 0.1879 - val_loss: 1.9368 - val_accuracy: 0.2250\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0069 - accuracy: 0.1914 - val_loss: 1.9668 - val_accuracy: 0.1972\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9752 - accuracy: 0.2092 - val_loss: 1.9181 - val_accuracy: 0.2250\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9788 - accuracy: 0.1941 - val_loss: 1.9384 - val_accuracy: 0.2667\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9781 - accuracy: 0.2147 - val_loss: 1.9036 - val_accuracy: 0.2778\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9457 - accuracy: 0.2119 - val_loss: 1.9253 - val_accuracy: 0.2306\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9172 - accuracy: 0.2256 - val_loss: 1.8759 - val_accuracy: 0.2583\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9215 - accuracy: 0.2218 - val_loss: 1.8644 - val_accuracy: 0.2806\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9580 - accuracy: 0.2170 - val_loss: 1.9021 - val_accuracy: 0.2472\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8976 - accuracy: 0.2267 - val_loss: 1.8913 - val_accuracy: 0.2417\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8965 - accuracy: 0.2386 - val_loss: 1.8566 - val_accuracy: 0.2694\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9224 - accuracy: 0.2278 - val_loss: 1.9075 - val_accuracy: 0.2056\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8967 - accuracy: 0.2253 - val_loss: 1.8950 - val_accuracy: 0.3028\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8868 - accuracy: 0.2504 - val_loss: 1.8489 - val_accuracy: 0.2611\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8658 - accuracy: 0.2546 - val_loss: 1.8598 - val_accuracy: 0.2944\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8252 - accuracy: 0.2791 - val_loss: 1.9563 - val_accuracy: 0.1972\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8729 - accuracy: 0.2493 - val_loss: 1.8542 - val_accuracy: 0.2917\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8235 - accuracy: 0.2716 - val_loss: 1.8772 - val_accuracy: 0.2944\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8134 - accuracy: 0.2546 - val_loss: 1.8236 - val_accuracy: 0.3139\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8244 - accuracy: 0.2703 - val_loss: 1.8320 - val_accuracy: 0.3083\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7941 - accuracy: 0.2712 - val_loss: 1.8312 - val_accuracy: 0.2472\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8534 - accuracy: 0.2582 - val_loss: 1.7971 - val_accuracy: 0.3583\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7995 - accuracy: 0.2819 - val_loss: 1.8240 - val_accuracy: 0.2222\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8184 - accuracy: 0.2708 - val_loss: 1.8034 - val_accuracy: 0.2917\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7985 - accuracy: 0.2614 - val_loss: 1.7886 - val_accuracy: 0.2944\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7749 - accuracy: 0.2822 - val_loss: 1.8001 - val_accuracy: 0.3250\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7831 - accuracy: 0.2757 - val_loss: 1.8229 - val_accuracy: 0.3000\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7587 - accuracy: 0.3045 - val_loss: 1.7953 - val_accuracy: 0.3611\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7473 - accuracy: 0.3089 - val_loss: 1.8589 - val_accuracy: 0.3389\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7948 - accuracy: 0.3049 - val_loss: 1.7485 - val_accuracy: 0.3417\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7391 - accuracy: 0.3081 - val_loss: 1.7901 - val_accuracy: 0.3333\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7342 - accuracy: 0.3074 - val_loss: 1.8657 - val_accuracy: 0.2639\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7611 - accuracy: 0.3053 - val_loss: 1.8164 - val_accuracy: 0.3278\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7244 - accuracy: 0.2935 - val_loss: 1.7630 - val_accuracy: 0.3306\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7327 - accuracy: 0.3090 - val_loss: 1.9035 - val_accuracy: 0.2528\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7128 - accuracy: 0.3236 - val_loss: 1.8471 - val_accuracy: 0.3167\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7317 - accuracy: 0.3157 - val_loss: 1.7938 - val_accuracy: 0.3167\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6964 - accuracy: 0.3306 - val_loss: 1.8243 - val_accuracy: 0.2833\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7452 - accuracy: 0.3129 - val_loss: 1.7871 - val_accuracy: 0.3083\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6947 - accuracy: 0.3301 - val_loss: 1.9104 - val_accuracy: 0.2806\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6769 - accuracy: 0.3603 - val_loss: 1.8677 - val_accuracy: 0.2972\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7225 - accuracy: 0.3375 - val_loss: 1.8275 - val_accuracy: 0.3111\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6790 - accuracy: 0.3330 - val_loss: 1.7593 - val_accuracy: 0.3500\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6752 - accuracy: 0.3570 - val_loss: 1.9512 - val_accuracy: 0.3194\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7006 - accuracy: 0.3483 - val_loss: 1.8728 - val_accuracy: 0.3306\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6571 - accuracy: 0.3583 - val_loss: 1.8245 - val_accuracy: 0.3417\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6472 - accuracy: 0.3687 - val_loss: 1.8538 - val_accuracy: 0.3500\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6082 - accuracy: 0.3920 - val_loss: 1.7578 - val_accuracy: 0.3639\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6543 - accuracy: 0.3557 - val_loss: 1.7590 - val_accuracy: 0.3639\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6435 - accuracy: 0.3765 - val_loss: 1.7505 - val_accuracy: 0.3722\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6778 - accuracy: 0.3455 - val_loss: 1.8037 - val_accuracy: 0.3611\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7196 - accuracy: 0.3514 - val_loss: 1.7533 - val_accuracy: 0.3583\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5893 - accuracy: 0.3989 - val_loss: 1.7907 - val_accuracy: 0.3583\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5986 - accuracy: 0.3778 - val_loss: 1.8583 - val_accuracy: 0.3500\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6150 - accuracy: 0.3729 - val_loss: 1.9269 - val_accuracy: 0.3278\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6788 - accuracy: 0.3600 - val_loss: 1.7614 - val_accuracy: 0.3694\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5312 - accuracy: 0.4345 - val_loss: 1.7718 - val_accuracy: 0.3556\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5186 - accuracy: 0.4310 - val_loss: 1.8175 - val_accuracy: 0.3639\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5442 - accuracy: 0.4070 - val_loss: 1.8703 - val_accuracy: 0.3583\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5684 - accuracy: 0.3947 - val_loss: 1.9912 - val_accuracy: 0.3639\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5544 - accuracy: 0.3945 - val_loss: 1.9090 - val_accuracy: 0.3639\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5270 - accuracy: 0.4204 - val_loss: 1.8875 - val_accuracy: 0.3472\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5056 - accuracy: 0.4276 - val_loss: 2.1356 - val_accuracy: 0.3083\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5176 - accuracy: 0.4292 - val_loss: 1.9031 - val_accuracy: 0.3667\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4450 - accuracy: 0.4580 - val_loss: 2.2599 - val_accuracy: 0.3278\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5880 - accuracy: 0.4212 - val_loss: 2.0022 - val_accuracy: 0.2889\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4654 - accuracy: 0.4558 - val_loss: 2.0214 - val_accuracy: 0.3056\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4532 - accuracy: 0.4369 - val_loss: 2.0094 - val_accuracy: 0.3611\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4480 - accuracy: 0.4462 - val_loss: 2.1235 - val_accuracy: 0.3389\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5011 - accuracy: 0.4187 - val_loss: 2.0600 - val_accuracy: 0.3583\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4021 - accuracy: 0.4776 - val_loss: 1.9461 - val_accuracy: 0.3361\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4747 - accuracy: 0.4594 - val_loss: 1.8670 - val_accuracy: 0.3694\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4845 - accuracy: 0.4397 - val_loss: 2.2322 - val_accuracy: 0.3361\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3976 - accuracy: 0.4947 - val_loss: 2.0158 - val_accuracy: 0.3611\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4988 - accuracy: 0.4989 - val_loss: 1.8949 - val_accuracy: 0.3500\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4331 - accuracy: 0.4640 - val_loss: 2.0901 - val_accuracy: 0.3389\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3795 - accuracy: 0.4918 - val_loss: 1.8295 - val_accuracy: 0.3750\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3789 - accuracy: 0.4940 - val_loss: 2.3261 - val_accuracy: 0.2917\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4800 - accuracy: 0.4460 - val_loss: 2.2058 - val_accuracy: 0.3167\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4358 - accuracy: 0.4549 - val_loss: 1.9557 - val_accuracy: 0.3389\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4243 - accuracy: 0.4784 - val_loss: 2.0414 - val_accuracy: 0.3833\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3130 - accuracy: 0.5039 - val_loss: 1.8861 - val_accuracy: 0.3528\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2940 - accuracy: 0.5385 - val_loss: 2.1502 - val_accuracy: 0.3667\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3280 - accuracy: 0.5163 - val_loss: 2.0460 - val_accuracy: 0.3250\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4199 - accuracy: 0.4752 - val_loss: 2.1536 - val_accuracy: 0.3583\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2910 - accuracy: 0.5246 - val_loss: 2.1165 - val_accuracy: 0.3611\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1906 - accuracy: 0.5573 - val_loss: 1.9855 - val_accuracy: 0.3917\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2669 - accuracy: 0.5457 - val_loss: 2.0910 - val_accuracy: 0.3889\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2413 - accuracy: 0.5522 - val_loss: 2.1208 - val_accuracy: 0.3306\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4289 - accuracy: 0.4750 - val_loss: 2.2348 - val_accuracy: 0.3556\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1924 - accuracy: 0.5589 - val_loss: 2.1727 - val_accuracy: 0.3556\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2192 - accuracy: 0.5308 - val_loss: 2.1516 - val_accuracy: 0.3583\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2397 - accuracy: 0.5261 - val_loss: 2.0891 - val_accuracy: 0.3667\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2063 - accuracy: 0.5628 - val_loss: 2.1181 - val_accuracy: 0.3639\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1258 - accuracy: 0.5877 - val_loss: 2.2539 - val_accuracy: 0.3722\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1236 - accuracy: 0.5833 - val_loss: 2.4304 - val_accuracy: 0.3389\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2197 - accuracy: 0.5404 - val_loss: 2.3464 - val_accuracy: 0.3639\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2300 - accuracy: 0.5603 - val_loss: 2.8477 - val_accuracy: 0.3000\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2320 - accuracy: 0.5493 - val_loss: 2.3019 - val_accuracy: 0.3750\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1334 - accuracy: 0.5707 - val_loss: 2.2710 - val_accuracy: 0.3806\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1210 - accuracy: 0.5816 - val_loss: 2.2811 - val_accuracy: 0.3750\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1772 - accuracy: 0.5783 - val_loss: 2.3954 - val_accuracy: 0.3361\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1599 - accuracy: 0.5753 - val_loss: 2.3467 - val_accuracy: 0.3583\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0923 - accuracy: 0.5956 - val_loss: 2.2029 - val_accuracy: 0.3417\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1267 - accuracy: 0.5984 - val_loss: 2.2260 - val_accuracy: 0.3278\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2609 - accuracy: 0.5473 - val_loss: 2.4286 - val_accuracy: 0.3556\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0145 - accuracy: 0.6247 - val_loss: 2.8104 - val_accuracy: 0.3222\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2212 - accuracy: 0.5640 - val_loss: 2.5694 - val_accuracy: 0.3250\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0735 - accuracy: 0.5984 - val_loss: 2.6171 - val_accuracy: 0.3444\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1545 - accuracy: 0.5532 - val_loss: 2.3284 - val_accuracy: 0.3917\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0523 - accuracy: 0.6299 - val_loss: 2.6976 - val_accuracy: 0.3500\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0810 - accuracy: 0.6156 - val_loss: 2.5914 - val_accuracy: 0.3472\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0929 - accuracy: 0.6100 - val_loss: 2.5806 - val_accuracy: 0.3722\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0906 - accuracy: 0.6162 - val_loss: 2.5846 - val_accuracy: 0.3611\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9475 - accuracy: 0.6552 - val_loss: 3.1953 - val_accuracy: 0.3083\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3236 - accuracy: 0.5389 - val_loss: 2.3369 - val_accuracy: 0.3833\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1440 - accuracy: 0.6091 - val_loss: 2.3600 - val_accuracy: 0.3528\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9876 - accuracy: 0.6464 - val_loss: 2.4420 - val_accuracy: 0.3639\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1843 - accuracy: 0.5786 - val_loss: 2.5686 - val_accuracy: 0.3444\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9247 - accuracy: 0.6821 - val_loss: 2.7156 - val_accuracy: 0.3528\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9891 - accuracy: 0.6563 - val_loss: 2.7009 - val_accuracy: 0.3722\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9942 - accuracy: 0.6427 - val_loss: 2.4499 - val_accuracy: 0.3472\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9207 - accuracy: 0.6705 - val_loss: 2.4507 - val_accuracy: 0.3889\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0010 - accuracy: 0.6501 - val_loss: 2.8093 - val_accuracy: 0.3361\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1001 - accuracy: 0.5995 - val_loss: 2.4121 - val_accuracy: 0.3556\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8651 - accuracy: 0.6949 - val_loss: 2.5569 - val_accuracy: 0.3611\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8556 - accuracy: 0.6922 - val_loss: 2.5344 - val_accuracy: 0.3389\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0076 - accuracy: 0.6391 - val_loss: 2.5766 - val_accuracy: 0.3500\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8474 - accuracy: 0.6881 - val_loss: 2.4768 - val_accuracy: 0.3667\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.6928 - val_loss: 2.8266 - val_accuracy: 0.3861\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9776 - accuracy: 0.6747 - val_loss: 2.9313 - val_accuracy: 0.3472\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0188 - accuracy: 0.6330 - val_loss: 2.9591 - val_accuracy: 0.3583\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8135 - accuracy: 0.7294 - val_loss: 2.9411 - val_accuracy: 0.3278\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9016 - accuracy: 0.6689 - val_loss: 2.9690 - val_accuracy: 0.3417\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8187 - accuracy: 0.7168 - val_loss: 2.4070 - val_accuracy: 0.3778\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9589 - accuracy: 0.6560 - val_loss: 2.5377 - val_accuracy: 0.3667\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7933 - accuracy: 0.7254 - val_loss: 2.5926 - val_accuracy: 0.3917\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8112 - accuracy: 0.7198 - val_loss: 3.0208 - val_accuracy: 0.3444\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9078 - accuracy: 0.6932 - val_loss: 2.8109 - val_accuracy: 0.3944\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7269 - accuracy: 0.7305 - val_loss: 2.9035 - val_accuracy: 0.3556\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0487 - accuracy: 0.6554 - val_loss: 3.3700 - val_accuracy: 0.3611\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8954 - accuracy: 0.6843 - val_loss: 2.5954 - val_accuracy: 0.3611\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7453 - accuracy: 0.7444 - val_loss: 2.5843 - val_accuracy: 0.3528\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7778 - accuracy: 0.7175 - val_loss: 2.6797 - val_accuracy: 0.3389\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8318 - accuracy: 0.7037 - val_loss: 2.7548 - val_accuracy: 0.3417\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7659 - accuracy: 0.7274 - val_loss: 2.6933 - val_accuracy: 0.3500\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8497 - accuracy: 0.7028 - val_loss: 3.2682 - val_accuracy: 0.3417\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6874 - accuracy: 0.7514 - val_loss: 2.7886 - val_accuracy: 0.3833\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7460 - accuracy: 0.7412 - val_loss: 5.2784 - val_accuracy: 0.2861\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.2748 - accuracy: 0.5361 - val_loss: 2.7588 - val_accuracy: 0.3194\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6578 - accuracy: 0.7662 - val_loss: 2.8719 - val_accuracy: 0.3444\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6832 - accuracy: 0.7593 - val_loss: 2.9865 - val_accuracy: 0.3611\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6535 - accuracy: 0.7734 - val_loss: 2.7798 - val_accuracy: 0.3694\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6774 - accuracy: 0.7549 - val_loss: 3.4802 - val_accuracy: 0.3306\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8640 - accuracy: 0.6945 - val_loss: 2.9058 - val_accuracy: 0.3806\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7964 - accuracy: 0.7505 - val_loss: 2.6489 - val_accuracy: 0.3778\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6394 - accuracy: 0.7751 - val_loss: 3.5317 - val_accuracy: 0.3056\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8861 - accuracy: 0.7058 - val_loss: 3.5432 - val_accuracy: 0.3389\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8294 - accuracy: 0.7256 - val_loss: 2.7309 - val_accuracy: 0.3472\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8167 - accuracy: 0.6964 - val_loss: 2.5164 - val_accuracy: 0.3778\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7165 - accuracy: 0.7520 - val_loss: 2.9679 - val_accuracy: 0.3417\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6670 - accuracy: 0.7697 - val_loss: 2.8860 - val_accuracy: 0.3472\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7342 - accuracy: 0.7569 - val_loss: 3.2524 - val_accuracy: 0.3389\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7480 - accuracy: 0.7508 - val_loss: 2.9793 - val_accuracy: 0.3778\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6106 - accuracy: 0.7775 - val_loss: 2.9842 - val_accuracy: 0.3278\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6331 - accuracy: 0.7834 - val_loss: 3.0353 - val_accuracy: 0.3694\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6366 - accuracy: 0.7787 - val_loss: 2.9599 - val_accuracy: 0.3500\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0144 - accuracy: 0.6918 - val_loss: 3.3923 - val_accuracy: 0.3500\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6843 - accuracy: 0.7651 - val_loss: 3.0643 - val_accuracy: 0.3528\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5673 - accuracy: 0.8181 - val_loss: 3.3268 - val_accuracy: 0.3694\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6068 - accuracy: 0.7950 - val_loss: 3.5808 - val_accuracy: 0.3250\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6235 - accuracy: 0.7804 - val_loss: 3.3188 - val_accuracy: 0.3750\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7135 - accuracy: 0.7652 - val_loss: 3.2794 - val_accuracy: 0.3917\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7210 - accuracy: 0.7604 - val_loss: 3.1884 - val_accuracy: 0.3806\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5915 - accuracy: 0.8023 - val_loss: 3.2932 - val_accuracy: 0.3361\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6276 - accuracy: 0.7777 - val_loss: 3.2294 - val_accuracy: 0.3500\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6089 - accuracy: 0.7856 - val_loss: 3.6119 - val_accuracy: 0.3528\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6117 - accuracy: 0.7944 - val_loss: 3.0787 - val_accuracy: 0.3583\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6451 - accuracy: 0.7900 - val_loss: 3.9984 - val_accuracy: 0.3250\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6429 - accuracy: 0.7873 - val_loss: 3.4081 - val_accuracy: 0.3472\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5687 - accuracy: 0.8057 - val_loss: 3.6545 - val_accuracy: 0.3444\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6183 - accuracy: 0.7714 - val_loss: 3.7666 - val_accuracy: 0.3528\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.8093 - val_loss: 3.0346 - val_accuracy: 0.3556\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5734 - accuracy: 0.7961 - val_loss: 3.1570 - val_accuracy: 0.3583\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5337 - accuracy: 0.8220 - val_loss: 3.1906 - val_accuracy: 0.3444\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5798 - accuracy: 0.8055 - val_loss: 3.1262 - val_accuracy: 0.3444\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4789 - accuracy: 0.8433 - val_loss: 3.2172 - val_accuracy: 0.3639\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4924 - accuracy: 0.8376 - val_loss: 3.5331 - val_accuracy: 0.3583\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4347 - accuracy: 0.8502 - val_loss: 3.9985 - val_accuracy: 0.3417\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5460 - accuracy: 0.8007 - val_loss: 3.4092 - val_accuracy: 0.3556\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4885 - accuracy: 0.8310 - val_loss: 3.0916 - val_accuracy: 0.3417\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5682 - accuracy: 0.8084 - val_loss: 4.4963 - val_accuracy: 0.3333\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5699 - accuracy: 0.5615 - val_loss: 3.7943 - val_accuracy: 0.3444\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1979 - accuracy: 0.6745 - val_loss: 3.2965 - val_accuracy: 0.3639\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5247 - accuracy: 0.8174 - val_loss: 3.2017 - val_accuracy: 0.3667\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4598 - accuracy: 0.8400 - val_loss: 3.0438 - val_accuracy: 0.3667\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4713 - accuracy: 0.8413 - val_loss: 3.4719 - val_accuracy: 0.3361\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.8444 - val_loss: 3.3738 - val_accuracy: 0.3528\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5525 - accuracy: 0.8029 - val_loss: 3.2826 - val_accuracy: 0.3389\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4433 - accuracy: 0.8435 - val_loss: 3.3806 - val_accuracy: 0.3194\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6608 - accuracy: 0.7723 - val_loss: 3.6413 - val_accuracy: 0.3583\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5384 - accuracy: 0.7992 - val_loss: 3.7632 - val_accuracy: 0.3417\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.8249 - val_loss: 3.2155 - val_accuracy: 0.3556\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4838 - accuracy: 0.8344 - val_loss: 3.2599 - val_accuracy: 0.3694\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4867 - accuracy: 0.8494 - val_loss: 3.3389 - val_accuracy: 0.3750\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8594 - accuracy: 0.7325 - val_loss: 3.8991 - val_accuracy: 0.3667\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5859 - accuracy: 0.7945 - val_loss: 3.9641 - val_accuracy: 0.3417\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4684 - accuracy: 0.8359 - val_loss: 3.2909 - val_accuracy: 0.3611\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3930 - accuracy: 0.8638 - val_loss: 3.5729 - val_accuracy: 0.3417\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5043 - accuracy: 0.8342 - val_loss: 3.6895 - val_accuracy: 0.3750\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5422 - accuracy: 0.8067 - val_loss: 3.4739 - val_accuracy: 0.3583\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4672 - accuracy: 0.8289 - val_loss: 3.3350 - val_accuracy: 0.3667\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4728 - accuracy: 0.8433 - val_loss: 3.7756 - val_accuracy: 0.3750\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3861 - accuracy: 0.8599 - val_loss: 3.6395 - val_accuracy: 0.3528\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.8314 - val_loss: 3.6677 - val_accuracy: 0.3472\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4472 - accuracy: 0.8411 - val_loss: 3.9436 - val_accuracy: 0.3500\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4433 - accuracy: 0.8548 - val_loss: 4.0318 - val_accuracy: 0.3583\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4254 - accuracy: 0.8541 - val_loss: 4.0785 - val_accuracy: 0.3611\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5159 - accuracy: 0.8567 - val_loss: 3.6864 - val_accuracy: 0.3444\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4516 - accuracy: 0.8610 - val_loss: 3.5695 - val_accuracy: 0.3472\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4086 - accuracy: 0.8595 - val_loss: 3.7066 - val_accuracy: 0.3667\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4119 - accuracy: 0.8557 - val_loss: 4.0772 - val_accuracy: 0.3778\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5652 - accuracy: 0.8069 - val_loss: 3.6422 - val_accuracy: 0.3361\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3409 - accuracy: 0.8924 - val_loss: 3.8887 - val_accuracy: 0.3417\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3345 - accuracy: 0.8829 - val_loss: 3.9043 - val_accuracy: 0.3417\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7572 - accuracy: 0.7654 - val_loss: 3.3193 - val_accuracy: 0.3556\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3656 - accuracy: 0.8767 - val_loss: 3.8364 - val_accuracy: 0.3694\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8598 - val_loss: 4.2394 - val_accuracy: 0.3639\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4253 - accuracy: 0.8528 - val_loss: 3.7425 - val_accuracy: 0.3500\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.8602 - val_loss: 3.6173 - val_accuracy: 0.3556\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4702 - accuracy: 0.8422 - val_loss: 3.8579 - val_accuracy: 0.3556\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5038 - accuracy: 0.8344 - val_loss: 3.3272 - val_accuracy: 0.3722\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3407 - accuracy: 0.8657 - val_loss: 3.9571 - val_accuracy: 0.3444\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.8576 - val_loss: 3.3998 - val_accuracy: 0.2944\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4612 - accuracy: 0.8366 - val_loss: 4.0853 - val_accuracy: 0.3583\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3596 - accuracy: 0.8940 - val_loss: 3.8022 - val_accuracy: 0.3500\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3531 - accuracy: 0.8754 - val_loss: 3.9463 - val_accuracy: 0.3722\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3354 - accuracy: 0.8808 - val_loss: 4.1391 - val_accuracy: 0.3694\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4517 - accuracy: 0.8635 - val_loss: 3.9342 - val_accuracy: 0.3472\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3353 - accuracy: 0.8788 - val_loss: 4.4702 - val_accuracy: 0.3472\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4876 - accuracy: 0.8539 - val_loss: 3.7751 - val_accuracy: 0.3611\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8791 - val_loss: 3.7959 - val_accuracy: 0.3472\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4765 - accuracy: 0.8401 - val_loss: 3.8792 - val_accuracy: 0.3694\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3053 - accuracy: 0.8898 - val_loss: 4.2109 - val_accuracy: 0.3250\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3507 - accuracy: 0.8844 - val_loss: 4.2056 - val_accuracy: 0.3611\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3007 - accuracy: 0.9017 - val_loss: 4.1012 - val_accuracy: 0.3806\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4532 - accuracy: 0.8549 - val_loss: 5.0233 - val_accuracy: 0.3250\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1171 - accuracy: 0.7386 - val_loss: 4.0433 - val_accuracy: 0.3556\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3040 - accuracy: 0.8914 - val_loss: 3.6148 - val_accuracy: 0.3667\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3556 - accuracy: 0.8759 - val_loss: 3.8551 - val_accuracy: 0.3694\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3302 - accuracy: 0.8923 - val_loss: 4.0698 - val_accuracy: 0.3222\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3425 - accuracy: 0.8837 - val_loss: 3.9103 - val_accuracy: 0.3528\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6431 - accuracy: 0.8021 - val_loss: 3.9754 - val_accuracy: 0.3611\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2957 - accuracy: 0.9087 - val_loss: 3.6169 - val_accuracy: 0.3667\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3023 - accuracy: 0.9094 - val_loss: 4.1090 - val_accuracy: 0.3361\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3230 - accuracy: 0.8979 - val_loss: 4.2301 - val_accuracy: 0.3333\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4538 - accuracy: 0.8473 - val_loss: 4.2389 - val_accuracy: 0.3361\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.8586 - val_loss: 3.6740 - val_accuracy: 0.3972\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5090 - accuracy: 0.8450 - val_loss: 3.6994 - val_accuracy: 0.3250\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3552 - accuracy: 0.8949 - val_loss: 3.6559 - val_accuracy: 0.3583\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3660 - accuracy: 0.8644 - val_loss: 3.7832 - val_accuracy: 0.3556\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3682 - accuracy: 0.8822 - val_loss: 4.6516 - val_accuracy: 0.3389\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3112 - accuracy: 0.9042 - val_loss: 4.1260 - val_accuracy: 0.3417\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3286 - accuracy: 0.9020 - val_loss: 4.6154 - val_accuracy: 0.3139\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3781 - accuracy: 0.8771 - val_loss: 4.0001 - val_accuracy: 0.3694\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2920 - accuracy: 0.9061 - val_loss: 4.2050 - val_accuracy: 0.3611\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3090 - accuracy: 0.8959 - val_loss: 4.0866 - val_accuracy: 0.3750\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3484 - accuracy: 0.8815 - val_loss: 4.6169 - val_accuracy: 0.3611\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2472 - accuracy: 0.9216 - val_loss: 4.2816 - val_accuracy: 0.3556\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3331 - accuracy: 0.8926 - val_loss: 4.4451 - val_accuracy: 0.3611\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5532 - accuracy: 0.8304 - val_loss: 3.7737 - val_accuracy: 0.3722\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5430 - accuracy: 0.8389 - val_loss: 4.2798 - val_accuracy: 0.3667\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2990 - accuracy: 0.9034 - val_loss: 4.1842 - val_accuracy: 0.3944\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2743 - accuracy: 0.9093 - val_loss: 4.3400 - val_accuracy: 0.3444\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2893 - accuracy: 0.9193 - val_loss: 4.5061 - val_accuracy: 0.3667\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2840 - accuracy: 0.8971 - val_loss: 3.9152 - val_accuracy: 0.3639\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2772 - accuracy: 0.9064 - val_loss: 3.8792 - val_accuracy: 0.3639\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3603 - accuracy: 0.8643 - val_loss: 4.7142 - val_accuracy: 0.3667\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5273 - accuracy: 0.8447 - val_loss: 3.9836 - val_accuracy: 0.3583\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2904 - accuracy: 0.9130 - val_loss: 4.0700 - val_accuracy: 0.3583\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3004 - accuracy: 0.9129 - val_loss: 4.0711 - val_accuracy: 0.3778\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2251 - accuracy: 0.9209 - val_loss: 4.5335 - val_accuracy: 0.3583\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2580 - accuracy: 0.9150 - val_loss: 4.2460 - val_accuracy: 0.3722\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2978 - accuracy: 0.8950 - val_loss: 4.3442 - val_accuracy: 0.3639\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2692 - accuracy: 0.9174 - val_loss: 4.4851 - val_accuracy: 0.3500\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2226 - accuracy: 0.9226 - val_loss: 4.3926 - val_accuracy: 0.3417\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2413 - accuracy: 0.9218 - val_loss: 4.2631 - val_accuracy: 0.3611\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2640 - accuracy: 0.9127 - val_loss: 4.2844 - val_accuracy: 0.3361\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5611 - accuracy: 0.7004 - val_loss: 4.5190 - val_accuracy: 0.3944\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5606 - accuracy: 0.8353 - val_loss: 3.7903 - val_accuracy: 0.3722\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2645 - accuracy: 0.9185 - val_loss: 4.1714 - val_accuracy: 0.3500\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2006 - accuracy: 0.9355 - val_loss: 4.5243 - val_accuracy: 0.3472\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2439 - accuracy: 0.9148 - val_loss: 4.3205 - val_accuracy: 0.3472\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2529 - accuracy: 0.9147 - val_loss: 4.8609 - val_accuracy: 0.3500\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3586 - accuracy: 0.8890 - val_loss: 4.1754 - val_accuracy: 0.3722\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3341 - accuracy: 0.8937 - val_loss: 4.3179 - val_accuracy: 0.3583\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2419 - accuracy: 0.9171 - val_loss: 4.4835 - val_accuracy: 0.3556\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2613 - accuracy: 0.9197 - val_loss: 4.4996 - val_accuracy: 0.3694\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2837 - accuracy: 0.9052 - val_loss: 4.2104 - val_accuracy: 0.3806\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2882 - accuracy: 0.9029 - val_loss: 3.8184 - val_accuracy: 0.3444\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2792 - accuracy: 0.8969 - val_loss: 4.2874 - val_accuracy: 0.3444\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2524 - accuracy: 0.9207 - val_loss: 4.2836 - val_accuracy: 0.3528\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2411 - accuracy: 0.9127 - val_loss: 4.7924 - val_accuracy: 0.3639\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5948 - accuracy: 0.8589 - val_loss: 3.7621 - val_accuracy: 0.3472\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2434 - accuracy: 0.9138 - val_loss: 4.3470 - val_accuracy: 0.3278\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2576 - accuracy: 0.9105 - val_loss: 4.0554 - val_accuracy: 0.3889\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2259 - accuracy: 0.9250 - val_loss: 4.5435 - val_accuracy: 0.3222\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3605 - accuracy: 0.8919 - val_loss: 4.3900 - val_accuracy: 0.3722\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2772 - accuracy: 0.9094 - val_loss: 4.2963 - val_accuracy: 0.3444\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2645 - accuracy: 0.9169 - val_loss: 4.0082 - val_accuracy: 0.3889\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2342 - accuracy: 0.9230 - val_loss: 3.8498 - val_accuracy: 0.4028\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5478 - accuracy: 0.8463 - val_loss: 4.1636 - val_accuracy: 0.3583\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3346 - accuracy: 0.8890 - val_loss: 4.0259 - val_accuracy: 0.3389\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2570 - accuracy: 0.9228 - val_loss: 4.0231 - val_accuracy: 0.3472\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2193 - accuracy: 0.9245 - val_loss: 3.8430 - val_accuracy: 0.3528\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2312 - accuracy: 0.9168 - val_loss: 4.5904 - val_accuracy: 0.3139\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2751 - accuracy: 0.9118 - val_loss: 4.5177 - val_accuracy: 0.3361\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3857 - accuracy: 0.8714 - val_loss: 4.1790 - val_accuracy: 0.3583\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2190 - accuracy: 0.9294 - val_loss: 4.7705 - val_accuracy: 0.3444\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2376 - accuracy: 0.9294 - val_loss: 4.6241 - val_accuracy: 0.3444\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2116 - accuracy: 0.9300 - val_loss: 4.6171 - val_accuracy: 0.3472\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2889 - accuracy: 0.9085 - val_loss: 4.4064 - val_accuracy: 0.3528\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2645 - accuracy: 0.9309 - val_loss: 4.4892 - val_accuracy: 0.3389\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2566 - accuracy: 0.9110 - val_loss: 4.2575 - val_accuracy: 0.3500\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3080 - accuracy: 0.9044 - val_loss: 4.4931 - val_accuracy: 0.3611\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2081 - accuracy: 0.9316 - val_loss: 5.2363 - val_accuracy: 0.3500\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.9207 - val_loss: 4.5134 - val_accuracy: 0.3750\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3270 - accuracy: 0.9013 - val_loss: 4.6121 - val_accuracy: 0.3306\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2716 - accuracy: 0.9003 - val_loss: 4.2258 - val_accuracy: 0.3500\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 0.9107 - val_loss: 3.9209 - val_accuracy: 0.3861\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1972 - accuracy: 0.9406 - val_loss: 3.9197 - val_accuracy: 0.3722\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2311 - accuracy: 0.9306 - val_loss: 3.8322 - val_accuracy: 0.3361\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2920 - accuracy: 0.9304 - val_loss: 3.9577 - val_accuracy: 0.3639\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2360 - accuracy: 0.9166 - val_loss: 4.0303 - val_accuracy: 0.3667\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1832 - accuracy: 0.9302 - val_loss: 4.0443 - val_accuracy: 0.3722\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7980 - accuracy: 0.8460 - val_loss: 4.4707 - val_accuracy: 0.3833\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3766 - accuracy: 0.8724 - val_loss: 3.8643 - val_accuracy: 0.3639\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1595 - accuracy: 0.9467 - val_loss: 4.0188 - val_accuracy: 0.3611\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2117 - accuracy: 0.9187 - val_loss: 3.9995 - val_accuracy: 0.3667\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1926 - accuracy: 0.9358 - val_loss: 4.0496 - val_accuracy: 0.3833\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3361 - accuracy: 0.8967 - val_loss: 3.7827 - val_accuracy: 0.3639\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2127 - accuracy: 0.9251 - val_loss: 3.9253 - val_accuracy: 0.3889\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1779 - accuracy: 0.9324 - val_loss: 4.2077 - val_accuracy: 0.3778\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2705 - accuracy: 0.9064 - val_loss: 4.2550 - val_accuracy: 0.3556\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.8991 - val_loss: 4.3639 - val_accuracy: 0.3500\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2218 - accuracy: 0.9248 - val_loss: 5.3199 - val_accuracy: 0.3472\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3745 - accuracy: 0.8845 - val_loss: 7.4868 - val_accuracy: 0.3056\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.5648 - accuracy: 0.7402 - val_loss: 4.0904 - val_accuracy: 0.3639\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2169 - accuracy: 0.9214 - val_loss: 3.9905 - val_accuracy: 0.3556\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1928 - accuracy: 0.9423 - val_loss: 4.0005 - val_accuracy: 0.3722\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1611 - accuracy: 0.9505 - val_loss: 3.9874 - val_accuracy: 0.3750\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1678 - accuracy: 0.9429 - val_loss: 4.5448 - val_accuracy: 0.3694\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2097 - accuracy: 0.9275 - val_loss: 4.2073 - val_accuracy: 0.3778\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2405 - accuracy: 0.9146 - val_loss: 4.2935 - val_accuracy: 0.3444\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1652 - accuracy: 0.9385 - val_loss: 4.3293 - val_accuracy: 0.3722\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1901 - accuracy: 0.9346 - val_loss: 4.4380 - val_accuracy: 0.3444\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2365 - accuracy: 0.9290 - val_loss: 4.3004 - val_accuracy: 0.3444\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1943 - accuracy: 0.9396 - val_loss: 4.4080 - val_accuracy: 0.3556\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2323 - accuracy: 0.9212 - val_loss: 4.3186 - val_accuracy: 0.3528\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1872 - accuracy: 0.9395 - val_loss: 4.3805 - val_accuracy: 0.3333\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3250 - accuracy: 0.8979 - val_loss: 4.3144 - val_accuracy: 0.3528\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1689 - accuracy: 0.9412 - val_loss: 4.2870 - val_accuracy: 0.3667\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1936 - accuracy: 0.9361 - val_loss: 4.1056 - val_accuracy: 0.3722\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1866 - accuracy: 0.9404 - val_loss: 4.1333 - val_accuracy: 0.3667\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2983 - accuracy: 0.9115 - val_loss: 4.8107 - val_accuracy: 0.3500\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3536 - accuracy: 0.8862 - val_loss: 4.0167 - val_accuracy: 0.3556\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1497 - accuracy: 0.9588 - val_loss: 3.9646 - val_accuracy: 0.3528\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2366 - accuracy: 0.9349 - val_loss: 4.1196 - val_accuracy: 0.3528\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1943 - accuracy: 0.9366 - val_loss: 3.9948 - val_accuracy: 0.3444\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1824 - accuracy: 0.9439 - val_loss: 4.0603 - val_accuracy: 0.3500\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2159 - accuracy: 0.9285 - val_loss: 4.2505 - val_accuracy: 0.3611\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2029 - accuracy: 0.9391 - val_loss: 4.5059 - val_accuracy: 0.3639\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3706 - accuracy: 0.9012 - val_loss: 4.4149 - val_accuracy: 0.3472\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2413 - accuracy: 0.9203 - val_loss: 4.4834 - val_accuracy: 0.3556\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 0.9336 - val_loss: 4.6100 - val_accuracy: 0.3500\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2167 - accuracy: 0.9241 - val_loss: 4.1997 - val_accuracy: 0.3556\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2100 - accuracy: 0.9364 - val_loss: 4.3247 - val_accuracy: 0.3417\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1586 - accuracy: 0.9483 - val_loss: 4.5332 - val_accuracy: 0.3694\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1890 - accuracy: 0.9464 - val_loss: 4.0903 - val_accuracy: 0.3667\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1772 - accuracy: 0.9399 - val_loss: 4.3379 - val_accuracy: 0.3472\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1923 - accuracy: 0.9374 - val_loss: 4.4773 - val_accuracy: 0.3639\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1615 - accuracy: 0.9489 - val_loss: 4.6022 - val_accuracy: 0.3528\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2516 - accuracy: 0.9213 - val_loss: 4.8186 - val_accuracy: 0.3500\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1602 - accuracy: 0.9404 - val_loss: 4.5891 - val_accuracy: 0.3472\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2785 - accuracy: 0.9177 - val_loss: 4.5570 - val_accuracy: 0.3417\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7177 - accuracy: 0.8562 - val_loss: 4.7253 - val_accuracy: 0.3583\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2496 - accuracy: 0.9125 - val_loss: 4.9140 - val_accuracy: 0.3500\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1865 - accuracy: 0.9353 - val_loss: 4.4386 - val_accuracy: 0.3278\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1514 - accuracy: 0.9445 - val_loss: 4.5157 - val_accuracy: 0.3444\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2565 - accuracy: 0.9278 - val_loss: 4.2679 - val_accuracy: 0.3417\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.9387 - val_loss: 4.0789 - val_accuracy: 0.3583\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2298 - accuracy: 0.9322 - val_loss: 4.4691 - val_accuracy: 0.3639\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1220 - accuracy: 0.9561 - val_loss: 4.2374 - val_accuracy: 0.3750\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1877 - accuracy: 0.9406 - val_loss: 4.3503 - val_accuracy: 0.3861\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1530 - accuracy: 0.9481 - val_loss: 4.4155 - val_accuracy: 0.3639\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2383 - accuracy: 0.9216 - val_loss: 4.4481 - val_accuracy: 0.3417\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6757 - accuracy: 0.8779 - val_loss: 4.5539 - val_accuracy: 0.3167\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5213 - accuracy: 0.7193 - val_loss: 4.1459 - val_accuracy: 0.3806\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2388 - accuracy: 0.9134 - val_loss: 3.9512 - val_accuracy: 0.3639\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4148 - accuracy: 0.8951 - val_loss: 3.9420 - val_accuracy: 0.3639\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1477 - accuracy: 0.9496 - val_loss: 4.1769 - val_accuracy: 0.3667\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1650 - accuracy: 0.9569 - val_loss: 4.1405 - val_accuracy: 0.3778\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.9604 - val_loss: 4.1694 - val_accuracy: 0.3694\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1554 - accuracy: 0.9554 - val_loss: 4.0854 - val_accuracy: 0.3806\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1285 - accuracy: 0.9545 - val_loss: 4.0504 - val_accuracy: 0.3750\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1873 - accuracy: 0.9344 - val_loss: 3.9436 - val_accuracy: 0.3778\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1621 - accuracy: 0.9493 - val_loss: 4.1936 - val_accuracy: 0.3528\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 0.9437 - val_loss: 3.9830 - val_accuracy: 0.3556\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1633 - accuracy: 0.9502 - val_loss: 4.1748 - val_accuracy: 0.3639\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.9542 - val_loss: 4.4338 - val_accuracy: 0.3417\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5442 - accuracy: 0.8820 - val_loss: 4.8915 - val_accuracy: 0.2944\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8057 - accuracy: 0.8016 - val_loss: 4.1338 - val_accuracy: 0.3722\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2183 - accuracy: 0.9268 - val_loss: 4.0972 - val_accuracy: 0.3861\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1337 - accuracy: 0.9559 - val_loss: 3.4848 - val_accuracy: 0.3833\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1551 - accuracy: 0.9516 - val_loss: 3.8017 - val_accuracy: 0.3778\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1405 - accuracy: 0.9483 - val_loss: 3.8086 - val_accuracy: 0.3917\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1531 - accuracy: 0.9556 - val_loss: 3.7277 - val_accuracy: 0.3806\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1627 - accuracy: 0.9465 - val_loss: 4.1866 - val_accuracy: 0.3556\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1841 - accuracy: 0.9431 - val_loss: 4.3127 - val_accuracy: 0.3639\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1852 - accuracy: 0.9469 - val_loss: 4.2802 - val_accuracy: 0.3389\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1398 - accuracy: 0.9542 - val_loss: 4.3309 - val_accuracy: 0.3500\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1015 - accuracy: 0.9700 - val_loss: 4.6747 - val_accuracy: 0.3444\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9639 - val_loss: 4.9499 - val_accuracy: 0.3167\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4034 - accuracy: 0.8966 - val_loss: 4.5912 - val_accuracy: 0.3472\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2373 - accuracy: 0.9292 - val_loss: 5.7578 - val_accuracy: 0.3222\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1876 - accuracy: 0.9328 - val_loss: 4.6402 - val_accuracy: 0.3556\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1227 - accuracy: 0.9647 - val_loss: 4.6625 - val_accuracy: 0.3861\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1579 - accuracy: 0.9470 - val_loss: 4.3723 - val_accuracy: 0.3611\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2448 - accuracy: 0.9325 - val_loss: 4.0636 - val_accuracy: 0.3722\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2501 - accuracy: 0.9319 - val_loss: 4.2607 - val_accuracy: 0.3750\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1397 - accuracy: 0.9543 - val_loss: 4.3282 - val_accuracy: 0.3722\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1115 - accuracy: 0.9665 - val_loss: 4.0954 - val_accuracy: 0.3778\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1134 - accuracy: 0.9696 - val_loss: 4.9482 - val_accuracy: 0.3333\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2991 - accuracy: 0.9151 - val_loss: 4.3825 - val_accuracy: 0.3583\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1609 - accuracy: 0.9486 - val_loss: 4.5464 - val_accuracy: 0.3750\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1549 - accuracy: 0.9476 - val_loss: 4.0268 - val_accuracy: 0.3556\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2235 - accuracy: 0.9223 - val_loss: 4.3494 - val_accuracy: 0.3444\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1368 - accuracy: 0.9527 - val_loss: 4.3259 - val_accuracy: 0.3611\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1745 - accuracy: 0.9442 - val_loss: 4.6518 - val_accuracy: 0.3556\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1992 - accuracy: 0.9387 - val_loss: 4.2262 - val_accuracy: 0.3639\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1224 - accuracy: 0.9554 - val_loss: 4.3349 - val_accuracy: 0.3667\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1467 - accuracy: 0.9503 - val_loss: 4.3991 - val_accuracy: 0.3417\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1406 - accuracy: 0.9526 - val_loss: 4.4583 - val_accuracy: 0.3778\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1624 - accuracy: 0.9469 - val_loss: 4.0607 - val_accuracy: 0.3694\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9593 - val_loss: 4.5537 - val_accuracy: 0.3917\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1799 - accuracy: 0.9409 - val_loss: 4.1830 - val_accuracy: 0.3667\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 0.9464 - val_loss: 4.3181 - val_accuracy: 0.3528\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1910 - accuracy: 0.9350 - val_loss: 3.9255 - val_accuracy: 0.3528\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.9386 - val_loss: 4.1012 - val_accuracy: 0.3694\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1951 - accuracy: 0.9327 - val_loss: 4.2792 - val_accuracy: 0.3917\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1197 - accuracy: 0.9656 - val_loss: 4.5845 - val_accuracy: 0.3806\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2646 - accuracy: 0.9229 - val_loss: 4.8226 - val_accuracy: 0.3528\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2855 - accuracy: 0.9069 - val_loss: 4.1763 - val_accuracy: 0.4083\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1674 - accuracy: 0.9437 - val_loss: 4.6503 - val_accuracy: 0.3667\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1184 - accuracy: 0.9572 - val_loss: 4.4079 - val_accuracy: 0.3833\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1326 - accuracy: 0.9550 - val_loss: 4.3873 - val_accuracy: 0.3528\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1112 - accuracy: 0.9726 - val_loss: 4.5293 - val_accuracy: 0.3528\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1465 - accuracy: 0.9520 - val_loss: 4.5462 - val_accuracy: 0.3611\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1474 - accuracy: 0.9544 - val_loss: 4.7803 - val_accuracy: 0.3583\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3653 - accuracy: 0.8905 - val_loss: 4.3363 - val_accuracy: 0.3778\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1436 - accuracy: 0.9556 - val_loss: 4.9432 - val_accuracy: 0.3389\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1341 - accuracy: 0.9574 - val_loss: 4.5561 - val_accuracy: 0.3528\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1642 - accuracy: 0.9555 - val_loss: 4.6309 - val_accuracy: 0.3417\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2022 - accuracy: 0.9318 - val_loss: 4.5235 - val_accuracy: 0.3472\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1695 - accuracy: 0.9429 - val_loss: 4.9131 - val_accuracy: 0.3556\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1457 - accuracy: 0.9565 - val_loss: 4.6741 - val_accuracy: 0.3722\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1194 - accuracy: 0.9616 - val_loss: 4.9024 - val_accuracy: 0.3778\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1472 - accuracy: 0.9481 - val_loss: 4.5013 - val_accuracy: 0.3583\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1273 - accuracy: 0.9620 - val_loss: 4.7334 - val_accuracy: 0.3722\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1541 - accuracy: 0.9410 - val_loss: 4.8232 - val_accuracy: 0.3278\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2084 - accuracy: 0.9284 - val_loss: 4.9337 - val_accuracy: 0.3444\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.9601 - val_loss: 4.6106 - val_accuracy: 0.3389\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1754 - accuracy: 0.9469 - val_loss: 4.8981 - val_accuracy: 0.3667\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3341 - accuracy: 0.9064 - val_loss: 4.7339 - val_accuracy: 0.3556\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1338 - accuracy: 0.9547 - val_loss: 4.6095 - val_accuracy: 0.3611\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1728 - accuracy: 0.9507 - val_loss: 4.9129 - val_accuracy: 0.3444\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2882 - accuracy: 0.9252 - val_loss: 4.5862 - val_accuracy: 0.3722\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1079 - accuracy: 0.9669 - val_loss: 4.8918 - val_accuracy: 0.3500\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1093 - accuracy: 0.9678 - val_loss: 4.6813 - val_accuracy: 0.3722\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1287 - accuracy: 0.9524 - val_loss: 4.9263 - val_accuracy: 0.3667\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1154 - accuracy: 0.9644 - val_loss: 5.6934 - val_accuracy: 0.2972\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4961 - accuracy: 0.8641 - val_loss: 4.8391 - val_accuracy: 0.3694\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1638 - accuracy: 0.9457 - val_loss: 6.0484 - val_accuracy: 0.3361\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.8631 - val_loss: 4.8012 - val_accuracy: 0.3472\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2373 - accuracy: 0.9190 - val_loss: 4.8705 - val_accuracy: 0.3694\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1314 - accuracy: 0.9658 - val_loss: 4.6015 - val_accuracy: 0.3722\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1238 - accuracy: 0.9517 - val_loss: 4.3524 - val_accuracy: 0.3611\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0964 - accuracy: 0.9635 - val_loss: 4.4454 - val_accuracy: 0.3583\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1497 - accuracy: 0.9432 - val_loss: 4.2761 - val_accuracy: 0.3583\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1044 - accuracy: 0.9698 - val_loss: 4.7708 - val_accuracy: 0.3472\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1587 - accuracy: 0.9582 - val_loss: 5.2475 - val_accuracy: 0.3444\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1454 - accuracy: 0.9504 - val_loss: 4.7614 - val_accuracy: 0.3444\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1095 - accuracy: 0.9683 - val_loss: 4.3754 - val_accuracy: 0.3583\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1395 - accuracy: 0.9511 - val_loss: 4.7136 - val_accuracy: 0.3611\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1914 - accuracy: 0.9350 - val_loss: 4.8046 - val_accuracy: 0.3333\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1219 - accuracy: 0.9622 - val_loss: 4.6231 - val_accuracy: 0.3639\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0774 - accuracy: 0.9764 - val_loss: 5.0336 - val_accuracy: 0.3667\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1396 - accuracy: 0.9538 - val_loss: 5.0420 - val_accuracy: 0.3528\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2413 - accuracy: 0.9397 - val_loss: 4.6024 - val_accuracy: 0.3611\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1920 - accuracy: 0.9373 - val_loss: 4.7249 - val_accuracy: 0.3528\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 0.9428 - val_loss: 4.8170 - val_accuracy: 0.3667\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2610 - accuracy: 0.9441 - val_loss: 4.9230 - val_accuracy: 0.3639\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1895 - accuracy: 0.9542 - val_loss: 4.2275 - val_accuracy: 0.3694\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1419 - accuracy: 0.9536 - val_loss: 4.2996 - val_accuracy: 0.3639\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1206 - accuracy: 0.9593 - val_loss: 4.6233 - val_accuracy: 0.3778\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1511 - accuracy: 0.9483 - val_loss: 4.6916 - val_accuracy: 0.3583\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0928 - accuracy: 0.9652 - val_loss: 4.7208 - val_accuracy: 0.3806\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1114 - accuracy: 0.9693 - val_loss: 4.7054 - val_accuracy: 0.3556\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.9509 - val_loss: 4.3566 - val_accuracy: 0.3389\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6616 - accuracy: 0.8804 - val_loss: 4.8427 - val_accuracy: 0.3250\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8807 - accuracy: 0.8033 - val_loss: 4.3641 - val_accuracy: 0.3556\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1555 - accuracy: 0.9481 - val_loss: 3.9487 - val_accuracy: 0.3500\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9774 - val_loss: 3.9978 - val_accuracy: 0.3472\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1181 - accuracy: 0.9667 - val_loss: 4.1505 - val_accuracy: 0.3694\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1080 - accuracy: 0.9581 - val_loss: 4.2154 - val_accuracy: 0.3694\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1529 - accuracy: 0.9520 - val_loss: 4.5623 - val_accuracy: 0.3583\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 4.5324 - val_accuracy: 0.3806\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 0.9081 - val_loss: 4.5982 - val_accuracy: 0.3667\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1202 - accuracy: 0.9652 - val_loss: 4.1661 - val_accuracy: 0.3556\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3470 - accuracy: 0.8934 - val_loss: 4.5939 - val_accuracy: 0.3667\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1194 - accuracy: 0.9571 - val_loss: 4.2230 - val_accuracy: 0.3472\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1437 - accuracy: 0.9519 - val_loss: 4.3384 - val_accuracy: 0.3806\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1211 - accuracy: 0.9614 - val_loss: 4.5596 - val_accuracy: 0.3806\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1711 - accuracy: 0.9397 - val_loss: 4.7745 - val_accuracy: 0.3389\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3034 - accuracy: 0.9344 - val_loss: 4.3294 - val_accuracy: 0.4111\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1671 - accuracy: 0.9484 - val_loss: 3.7341 - val_accuracy: 0.3861\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.9656 - val_loss: 4.3155 - val_accuracy: 0.3472\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1092 - accuracy: 0.9651 - val_loss: 4.2418 - val_accuracy: 0.3778\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9630 - val_loss: 4.6703 - val_accuracy: 0.3472\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.8644 - val_loss: 4.1696 - val_accuracy: 0.3694\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1732 - accuracy: 0.9391 - val_loss: 3.7840 - val_accuracy: 0.3972\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1015 - accuracy: 0.9625 - val_loss: 3.9573 - val_accuracy: 0.3972\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1426 - accuracy: 0.9653 - val_loss: 3.9775 - val_accuracy: 0.3944\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1207 - accuracy: 0.9586 - val_loss: 4.1349 - val_accuracy: 0.3806\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1026 - accuracy: 0.9656 - val_loss: 4.2073 - val_accuracy: 0.3750\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1233 - accuracy: 0.9606 - val_loss: 4.1019 - val_accuracy: 0.3806\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0976 - accuracy: 0.9687 - val_loss: 4.1848 - val_accuracy: 0.3556\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2485 - accuracy: 0.9426 - val_loss: 4.3732 - val_accuracy: 0.3583\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 4.2933 - val_accuracy: 0.3889\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0843 - accuracy: 0.9757 - val_loss: 4.4387 - val_accuracy: 0.3722\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 4.3876 - val_accuracy: 0.3694\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1284 - accuracy: 0.9611 - val_loss: 4.8854 - val_accuracy: 0.3667\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1456 - accuracy: 0.9496 - val_loss: 4.5420 - val_accuracy: 0.3667\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1106 - accuracy: 0.9606 - val_loss: 4.6454 - val_accuracy: 0.3917\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1926 - accuracy: 0.9322 - val_loss: 4.8325 - val_accuracy: 0.3639\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1321 - accuracy: 0.9530 - val_loss: 4.6006 - val_accuracy: 0.3639\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0947 - accuracy: 0.9714 - val_loss: 4.7547 - val_accuracy: 0.3667\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9467 - val_loss: 4.6670 - val_accuracy: 0.3722\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1178 - accuracy: 0.9752 - val_loss: 5.5494 - val_accuracy: 0.3222\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2226 - accuracy: 0.9520 - val_loss: 4.9902 - val_accuracy: 0.3694\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2572 - accuracy: 0.9443 - val_loss: 4.7668 - val_accuracy: 0.3611\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1458 - accuracy: 0.9516 - val_loss: 4.5407 - val_accuracy: 0.3861\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4519 - accuracy: 0.9034 - val_loss: 4.4943 - val_accuracy: 0.3583\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1121 - accuracy: 0.9628 - val_loss: 4.8666 - val_accuracy: 0.3667\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0862 - accuracy: 0.9761 - val_loss: 4.7770 - val_accuracy: 0.3639\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.9627 - val_loss: 4.7552 - val_accuracy: 0.3778\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4805 - accuracy: 0.8931 - val_loss: 4.4898 - val_accuracy: 0.3639\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1073 - accuracy: 0.9652 - val_loss: 4.3408 - val_accuracy: 0.3806\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0830 - accuracy: 0.9707 - val_loss: 4.3367 - val_accuracy: 0.3750\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1076 - accuracy: 0.9655 - val_loss: 4.1326 - val_accuracy: 0.3778\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0899 - accuracy: 0.9727 - val_loss: 4.3726 - val_accuracy: 0.3722\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9680 - val_loss: 4.5073 - val_accuracy: 0.3389\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.9563 - val_loss: 4.4432 - val_accuracy: 0.3722\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1977 - accuracy: 0.9394 - val_loss: 4.1329 - val_accuracy: 0.3667\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1077 - accuracy: 0.9684 - val_loss: 4.3299 - val_accuracy: 0.3528\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9707 - val_loss: 4.1312 - val_accuracy: 0.3444\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2109 - accuracy: 0.9284 - val_loss: 4.6422 - val_accuracy: 0.3611\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9552 - val_loss: 4.4601 - val_accuracy: 0.3361\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1075 - accuracy: 0.9683 - val_loss: 4.4924 - val_accuracy: 0.3556\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1166 - accuracy: 0.9588 - val_loss: 4.8700 - val_accuracy: 0.3500\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.9687 - val_loss: 4.5473 - val_accuracy: 0.3806\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1128 - accuracy: 0.9643 - val_loss: 5.5849 - val_accuracy: 0.3444\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.9244 - val_loss: 5.1662 - val_accuracy: 0.3667\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0950 - accuracy: 0.9647 - val_loss: 5.0410 - val_accuracy: 0.3833\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1095 - accuracy: 0.9653 - val_loss: 4.5225 - val_accuracy: 0.3750\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5764 - accuracy: 0.8504 - val_loss: 5.0015 - val_accuracy: 0.3083\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.8899 - val_loss: 4.5581 - val_accuracy: 0.3667\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0937 - accuracy: 0.9703 - val_loss: 5.0626 - val_accuracy: 0.3667\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0968 - accuracy: 0.9666 - val_loss: 4.8465 - val_accuracy: 0.3806\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1183 - accuracy: 0.9604 - val_loss: 4.9585 - val_accuracy: 0.3556\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1082 - accuracy: 0.9611 - val_loss: 4.5021 - val_accuracy: 0.3583\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0749 - accuracy: 0.9788 - val_loss: 4.7644 - val_accuracy: 0.3667\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.9578 - val_loss: 5.0648 - val_accuracy: 0.3389\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2167 - accuracy: 0.9427 - val_loss: 5.2041 - val_accuracy: 0.3722\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1951 - accuracy: 0.9466 - val_loss: 6.3896 - val_accuracy: 0.2833\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0961 - accuracy: 0.7811 - val_loss: 4.9854 - val_accuracy: 0.3583\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1438 - accuracy: 0.9615 - val_loss: 4.4767 - val_accuracy: 0.3611\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1659 - accuracy: 0.9504 - val_loss: 4.4953 - val_accuracy: 0.3750\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1426 - accuracy: 0.9531 - val_loss: 4.8160 - val_accuracy: 0.3806\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1520 - accuracy: 0.9469 - val_loss: 4.7121 - val_accuracy: 0.3722\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0785 - accuracy: 0.9752 - val_loss: 4.6732 - val_accuracy: 0.3750\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0881 - accuracy: 0.9729 - val_loss: 4.4958 - val_accuracy: 0.3639\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0849 - accuracy: 0.9780 - val_loss: 4.9795 - val_accuracy: 0.3611\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2275 - accuracy: 0.9433 - val_loss: 5.1601 - val_accuracy: 0.3722\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1174 - accuracy: 0.9715 - val_loss: 5.1052 - val_accuracy: 0.3639\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0978 - accuracy: 0.9636 - val_loss: 5.0358 - val_accuracy: 0.3472\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1286 - accuracy: 0.9627 - val_loss: 4.7635 - val_accuracy: 0.3806\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0966 - accuracy: 0.9650 - val_loss: 5.3019 - val_accuracy: 0.3667\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0994 - accuracy: 0.9703 - val_loss: 5.6749 - val_accuracy: 0.3889\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1329 - accuracy: 0.9523 - val_loss: 5.8342 - val_accuracy: 0.3556\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1841 - accuracy: 0.9385 - val_loss: 5.0681 - val_accuracy: 0.3694\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1325 - accuracy: 0.9595 - val_loss: 4.9564 - val_accuracy: 0.3750\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 0.9611 - val_loss: 5.3493 - val_accuracy: 0.3639\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0936 - accuracy: 0.9723 - val_loss: 5.0911 - val_accuracy: 0.3889\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0986 - accuracy: 0.9759 - val_loss: 4.7119 - val_accuracy: 0.3889\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0881 - accuracy: 0.9733 - val_loss: 5.0252 - val_accuracy: 0.3722\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1317 - accuracy: 0.9498 - val_loss: 5.2124 - val_accuracy: 0.3861\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1677 - accuracy: 0.9392 - val_loss: 5.0236 - val_accuracy: 0.3778\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0971 - accuracy: 0.9723 - val_loss: 5.1929 - val_accuracy: 0.3778\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1597 - accuracy: 0.9595 - val_loss: 5.1097 - val_accuracy: 0.3750\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1147 - accuracy: 0.9624 - val_loss: 5.0238 - val_accuracy: 0.3722\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9612 - val_loss: 5.1395 - val_accuracy: 0.3778\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0909 - accuracy: 0.9674 - val_loss: 5.0513 - val_accuracy: 0.3639\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0965 - accuracy: 0.9728 - val_loss: 5.5040 - val_accuracy: 0.3528\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1282 - accuracy: 0.9622 - val_loss: 5.5849 - val_accuracy: 0.3528\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1429 - accuracy: 0.9499 - val_loss: 5.0473 - val_accuracy: 0.3722\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1097 - accuracy: 0.9642 - val_loss: 5.3409 - val_accuracy: 0.3861\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 5.6200 - val_accuracy: 0.3806\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0932 - accuracy: 0.9649 - val_loss: 5.6580 - val_accuracy: 0.3472\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1194 - accuracy: 0.9612 - val_loss: 5.7328 - val_accuracy: 0.3639\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1103 - accuracy: 0.9639 - val_loss: 5.2988 - val_accuracy: 0.3556\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1210 - accuracy: 0.9642 - val_loss: 5.2418 - val_accuracy: 0.3556\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1168 - accuracy: 0.9693 - val_loss: 4.4817 - val_accuracy: 0.3722\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1318 - accuracy: 0.9671 - val_loss: 4.9861 - val_accuracy: 0.3500\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 0.9670 - val_loss: 4.9678 - val_accuracy: 0.3889\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1183 - accuracy: 0.9577 - val_loss: 5.1452 - val_accuracy: 0.3667\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1140 - accuracy: 0.9586 - val_loss: 4.7131 - val_accuracy: 0.3472\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1350 - accuracy: 0.9643 - val_loss: 4.4633 - val_accuracy: 0.3944\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2517 - accuracy: 0.9335 - val_loss: 4.7442 - val_accuracy: 0.3972\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1015 - accuracy: 0.9699 - val_loss: 5.0547 - val_accuracy: 0.3833\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1139 - accuracy: 0.9573 - val_loss: 5.3972 - val_accuracy: 0.3750\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.9769 - val_loss: 5.0056 - val_accuracy: 0.3694\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1456 - accuracy: 0.9549 - val_loss: 4.9628 - val_accuracy: 0.3583\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1761 - accuracy: 0.9457 - val_loss: 6.0479 - val_accuracy: 0.3222\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1469 - accuracy: 0.9532 - val_loss: 4.7297 - val_accuracy: 0.3639\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0808 - accuracy: 0.9724 - val_loss: 4.6576 - val_accuracy: 0.3694\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1172 - accuracy: 0.9713 - val_loss: 4.9069 - val_accuracy: 0.3972\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1188 - accuracy: 0.9543 - val_loss: 4.5528 - val_accuracy: 0.3333\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7447 - accuracy: 0.8688 - val_loss: 4.4169 - val_accuracy: 0.3361\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2816 - accuracy: 0.9082 - val_loss: 4.4450 - val_accuracy: 0.3861\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 4.4532 - val_accuracy: 0.3500\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0958 - accuracy: 0.9699 - val_loss: 4.3207 - val_accuracy: 0.3806\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1070 - accuracy: 0.9695 - val_loss: 4.0630 - val_accuracy: 0.3861\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1295 - accuracy: 0.9622 - val_loss: 4.3927 - val_accuracy: 0.3972\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0697 - accuracy: 0.9788 - val_loss: 4.7099 - val_accuracy: 0.3833\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1089 - accuracy: 0.9607 - val_loss: 4.5673 - val_accuracy: 0.3778\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1535 - accuracy: 0.9603 - val_loss: 4.5171 - val_accuracy: 0.3778\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.9791 - val_loss: 4.3192 - val_accuracy: 0.3917\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1771 - accuracy: 0.9542 - val_loss: 4.8252 - val_accuracy: 0.3861\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1100 - accuracy: 0.9621 - val_loss: 5.1862 - val_accuracy: 0.3806\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1936 - accuracy: 0.9454 - val_loss: 5.1113 - val_accuracy: 0.3583\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 4.7946 - val_accuracy: 0.3583\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0946 - accuracy: 0.9662 - val_loss: 5.0114 - val_accuracy: 0.3889\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1351 - accuracy: 0.9570 - val_loss: 4.1908 - val_accuracy: 0.4000\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1119 - accuracy: 0.9638 - val_loss: 4.1686 - val_accuracy: 0.3611\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1060 - accuracy: 0.9689 - val_loss: 4.8785 - val_accuracy: 0.3917\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1287 - accuracy: 0.9578 - val_loss: 4.6710 - val_accuracy: 0.3750\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1137 - accuracy: 0.9655 - val_loss: 4.4333 - val_accuracy: 0.3667\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9690 - val_loss: 4.7857 - val_accuracy: 0.3944\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1000 - accuracy: 0.9739 - val_loss: 5.2925 - val_accuracy: 0.3861\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2907 - accuracy: 0.9111 - val_loss: 4.9973 - val_accuracy: 0.3667\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 5.7929 - val_accuracy: 0.3694\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1134 - accuracy: 0.9702 - val_loss: 5.4283 - val_accuracy: 0.3694\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1480 - accuracy: 0.9576 - val_loss: 5.1540 - val_accuracy: 0.3750\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0740 - accuracy: 0.9782 - val_loss: 5.1957 - val_accuracy: 0.3944\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1307 - accuracy: 0.9657 - val_loss: 4.8674 - val_accuracy: 0.3861\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1416 - accuracy: 0.9611 - val_loss: 5.6592 - val_accuracy: 0.3917\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1121 - accuracy: 0.9674 - val_loss: 5.7587 - val_accuracy: 0.3583\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.9503 - val_loss: 5.4410 - val_accuracy: 0.3667\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0602 - accuracy: 0.9868 - val_loss: 5.0107 - val_accuracy: 0.3583\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0684 - accuracy: 0.9788 - val_loss: 5.4289 - val_accuracy: 0.3694\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 0.9633 - val_loss: 5.2971 - val_accuracy: 0.3444\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1211 - accuracy: 0.9579 - val_loss: 5.2602 - val_accuracy: 0.3722\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1065 - accuracy: 0.9628 - val_loss: 5.7055 - val_accuracy: 0.3861\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.9150 - val_loss: 5.6866 - val_accuracy: 0.3639\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0860 - accuracy: 0.9719 - val_loss: 5.1288 - val_accuracy: 0.3694\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1067 - accuracy: 0.9726 - val_loss: 5.0317 - val_accuracy: 0.3667\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0998 - accuracy: 0.9747 - val_loss: 4.7334 - val_accuracy: 0.3750\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 4.5443 - val_accuracy: 0.3833\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1179 - accuracy: 0.9636 - val_loss: 4.6537 - val_accuracy: 0.3583\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 4.9081 - val_accuracy: 0.3472\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0803 - accuracy: 0.9693 - val_loss: 5.2910 - val_accuracy: 0.3389\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2149 - accuracy: 0.9372 - val_loss: 5.0076 - val_accuracy: 0.3444\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1580 - accuracy: 0.9549 - val_loss: 5.0657 - val_accuracy: 0.3639\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0800 - accuracy: 0.9692 - val_loss: 4.9998 - val_accuracy: 0.3444\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0600 - accuracy: 0.9777 - val_loss: 4.9083 - val_accuracy: 0.3750\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0952 - accuracy: 0.9616 - val_loss: 4.7357 - val_accuracy: 0.3806\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1260 - accuracy: 0.9633 - val_loss: 5.0679 - val_accuracy: 0.3778\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 5.1124 - val_accuracy: 0.3639\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9665 - val_loss: 5.1173 - val_accuracy: 0.3722\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0954 - accuracy: 0.9682 - val_loss: 5.0945 - val_accuracy: 0.3639\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 0.9777 - val_loss: 5.4510 - val_accuracy: 0.3472\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1530 - accuracy: 0.9552 - val_loss: 4.9729 - val_accuracy: 0.3444\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1437 - accuracy: 0.9583 - val_loss: 5.3750 - val_accuracy: 0.3472\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0600 - accuracy: 0.9807 - val_loss: 5.5281 - val_accuracy: 0.3528\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1138 - accuracy: 0.9645 - val_loss: 5.7489 - val_accuracy: 0.3556\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1073 - accuracy: 0.9659 - val_loss: 5.9348 - val_accuracy: 0.3389\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1269 - accuracy: 0.9672 - val_loss: 5.1256 - val_accuracy: 0.3389\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1286 - accuracy: 0.9553 - val_loss: 5.4786 - val_accuracy: 0.3694\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0880 - accuracy: 0.9787 - val_loss: 5.6142 - val_accuracy: 0.3472\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1403 - accuracy: 0.9500 - val_loss: 5.2417 - val_accuracy: 0.3778\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9847 - val_loss: 5.4921 - val_accuracy: 0.3639\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0962 - accuracy: 0.9707 - val_loss: 5.5876 - val_accuracy: 0.3528\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0802 - accuracy: 0.9719 - val_loss: 5.4959 - val_accuracy: 0.3500\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1042 - accuracy: 0.9697 - val_loss: 5.3432 - val_accuracy: 0.3528\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1354 - accuracy: 0.9545 - val_loss: 6.1818 - val_accuracy: 0.3361\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1097 - accuracy: 0.9683 - val_loss: 4.9734 - val_accuracy: 0.3694\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 5.2236 - val_accuracy: 0.3889\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0972 - accuracy: 0.9754 - val_loss: 5.0152 - val_accuracy: 0.3833\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0481 - accuracy: 0.9869 - val_loss: 5.1051 - val_accuracy: 0.3889\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1787 - accuracy: 0.9542 - val_loss: 5.3395 - val_accuracy: 0.3972\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0862 - accuracy: 0.9655 - val_loss: 4.9814 - val_accuracy: 0.3667\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1016 - accuracy: 0.9674 - val_loss: 5.5879 - val_accuracy: 0.3333\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3474 - accuracy: 0.9206 - val_loss: 5.4770 - val_accuracy: 0.3556\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1093 - accuracy: 0.9668 - val_loss: 5.1544 - val_accuracy: 0.3778\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0987 - accuracy: 0.9645 - val_loss: 6.0128 - val_accuracy: 0.3306\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4500 - accuracy: 0.8894 - val_loss: 5.4088 - val_accuracy: 0.3611\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0847 - accuracy: 0.9740 - val_loss: 5.0422 - val_accuracy: 0.3556\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1342 - accuracy: 0.9588 - val_loss: 5.1217 - val_accuracy: 0.3833\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.9736 - val_loss: 4.3544 - val_accuracy: 0.3639\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0902 - accuracy: 0.9708 - val_loss: 4.8238 - val_accuracy: 0.3500\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1032 - accuracy: 0.9674 - val_loss: 5.1406 - val_accuracy: 0.3556\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0721 - accuracy: 0.9860 - val_loss: 5.3515 - val_accuracy: 0.3417\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1157 - accuracy: 0.9644 - val_loss: 5.3301 - val_accuracy: 0.3667\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 5.6469 - val_accuracy: 0.3583\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 5.0471 - val_accuracy: 0.3611\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0929 - accuracy: 0.9741 - val_loss: 5.0977 - val_accuracy: 0.3611\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 4.7325 - val_accuracy: 0.3528\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4104 - accuracy: 0.9101 - val_loss: 4.7586 - val_accuracy: 0.3694\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 4.9308 - val_accuracy: 0.3722\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1627 - accuracy: 0.9587 - val_loss: 5.1105 - val_accuracy: 0.3583\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0990 - accuracy: 0.9660 - val_loss: 4.9801 - val_accuracy: 0.3694\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0615 - accuracy: 0.9784 - val_loss: 5.1980 - val_accuracy: 0.3639\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9647 - val_loss: 4.6924 - val_accuracy: 0.3917\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0767 - accuracy: 0.9781 - val_loss: 4.7152 - val_accuracy: 0.3833\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1474 - accuracy: 0.9580 - val_loss: 4.8067 - val_accuracy: 0.3833\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0951 - accuracy: 0.9758 - val_loss: 5.3792 - val_accuracy: 0.3833\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.9712 - val_loss: 4.8743 - val_accuracy: 0.3667\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3247 - accuracy: 0.9175 - val_loss: 5.3906 - val_accuracy: 0.3500\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1263 - accuracy: 0.9586 - val_loss: 5.3080 - val_accuracy: 0.3667\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2219 - accuracy: 0.9404 - val_loss: 4.8828 - val_accuracy: 0.3722\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1102 - accuracy: 0.9673 - val_loss: 4.9986 - val_accuracy: 0.3528\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0870 - accuracy: 0.9690 - val_loss: 5.0403 - val_accuracy: 0.3639\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0721 - accuracy: 0.9731 - val_loss: 5.1440 - val_accuracy: 0.3639\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0761 - accuracy: 0.9762 - val_loss: 4.8758 - val_accuracy: 0.3917\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1117 - accuracy: 0.9717 - val_loss: 5.2106 - val_accuracy: 0.3722\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1095 - accuracy: 0.9682 - val_loss: 4.8278 - val_accuracy: 0.3806\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1517 - accuracy: 0.9550 - val_loss: 5.0702 - val_accuracy: 0.3583\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1194 - accuracy: 0.9577 - val_loss: 5.0678 - val_accuracy: 0.3778\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0988 - accuracy: 0.9695 - val_loss: 5.4432 - val_accuracy: 0.3389\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9808 - val_loss: 5.3204 - val_accuracy: 0.3444\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1036 - accuracy: 0.9613 - val_loss: 5.3582 - val_accuracy: 0.3583\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1391 - accuracy: 0.9616 - val_loss: 5.4649 - val_accuracy: 0.3444\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1233 - accuracy: 0.9746 - val_loss: 5.5588 - val_accuracy: 0.3611\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9863 - accuracy: 0.8485 - val_loss: 5.2895 - val_accuracy: 0.3667\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4036 - accuracy: 0.8785 - val_loss: 4.3283 - val_accuracy: 0.3944\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1333 - accuracy: 0.9478 - val_loss: 4.3976 - val_accuracy: 0.3861\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0915 - accuracy: 0.9726 - val_loss: 4.4147 - val_accuracy: 0.3667\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0799 - accuracy: 0.9680 - val_loss: 4.9610 - val_accuracy: 0.3417\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9489 - val_loss: 4.2076 - val_accuracy: 0.3833\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0720 - accuracy: 0.9791 - val_loss: 4.8352 - val_accuracy: 0.3694\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1300 - accuracy: 0.9714 - val_loss: 4.4424 - val_accuracy: 0.3667\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1230 - accuracy: 0.9635 - val_loss: 4.8812 - val_accuracy: 0.3722\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0944 - accuracy: 0.9683 - val_loss: 4.8401 - val_accuracy: 0.3806\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1187 - accuracy: 0.9651 - val_loss: 5.1024 - val_accuracy: 0.3750\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1146 - accuracy: 0.9619 - val_loss: 4.5111 - val_accuracy: 0.3889\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1132 - accuracy: 0.9667 - val_loss: 4.5311 - val_accuracy: 0.3861\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1650 - accuracy: 0.9559 - val_loss: 5.0807 - val_accuracy: 0.3694\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0716 - accuracy: 0.9792 - val_loss: 5.0702 - val_accuracy: 0.3889\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0595 - accuracy: 0.9792 - val_loss: 5.4868 - val_accuracy: 0.3556\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0596 - accuracy: 0.9798 - val_loss: 5.1814 - val_accuracy: 0.3278\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1262 - accuracy: 0.9608 - val_loss: 4.7068 - val_accuracy: 0.3944\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9723 - val_loss: 5.3491 - val_accuracy: 0.3583\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3268 - accuracy: 0.9393 - val_loss: 5.1483 - val_accuracy: 0.3667\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1142 - accuracy: 0.9648 - val_loss: 5.2816 - val_accuracy: 0.3778\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9728 - val_loss: 4.7562 - val_accuracy: 0.3750\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 0.9748 - val_loss: 4.7873 - val_accuracy: 0.3750\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0787 - accuracy: 0.9805 - val_loss: 4.8784 - val_accuracy: 0.3833\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9804 - val_loss: 5.0943 - val_accuracy: 0.3694\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0713 - accuracy: 0.9766 - val_loss: 5.3464 - val_accuracy: 0.3583\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: 5.2993 - val_accuracy: 0.3583\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0734 - accuracy: 0.9779 - val_loss: 5.4640 - val_accuracy: 0.3694\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 0.9700 - val_loss: 5.1204 - val_accuracy: 0.3917\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2291 - accuracy: 0.8453 - val_loss: 4.7910 - val_accuracy: 0.3667\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1034 - accuracy: 0.9619 - val_loss: 5.1171 - val_accuracy: 0.3889\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 5.2035 - val_accuracy: 0.4139\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.9846 - val_loss: 4.9880 - val_accuracy: 0.3778\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 4.9426 - val_accuracy: 0.4028\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 5.7380 - val_accuracy: 0.3778\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1051 - accuracy: 0.9694 - val_loss: 6.1798 - val_accuracy: 0.3778\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1470 - accuracy: 0.9564 - val_loss: 4.9975 - val_accuracy: 0.3583\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0970 - accuracy: 0.9602 - val_loss: 4.7486 - val_accuracy: 0.3833\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9672 - val_loss: 5.2629 - val_accuracy: 0.3806\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1285 - accuracy: 0.9580 - val_loss: 5.0327 - val_accuracy: 0.3417\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1390 - accuracy: 0.9551 - val_loss: 5.1806 - val_accuracy: 0.3750\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0738 - accuracy: 0.9784 - val_loss: 5.8474 - val_accuracy: 0.3667\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1140 - accuracy: 0.9654 - val_loss: 5.4234 - val_accuracy: 0.3694\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2132 - accuracy: 0.9313 - val_loss: 4.8909 - val_accuracy: 0.3778\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1268 - accuracy: 0.9710 - val_loss: 4.9146 - val_accuracy: 0.3833\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0728 - accuracy: 0.9708 - val_loss: 4.8982 - val_accuracy: 0.3806\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0720 - accuracy: 0.9792 - val_loss: 5.1981 - val_accuracy: 0.3500\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 5.1027 - val_accuracy: 0.3639\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 5.1140 - val_accuracy: 0.3722\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0899 - accuracy: 0.9677 - val_loss: 5.2602 - val_accuracy: 0.3778\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9762 - val_loss: 5.1383 - val_accuracy: 0.3917\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0647 - accuracy: 0.9747 - val_loss: 5.4920 - val_accuracy: 0.3472\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0628 - accuracy: 0.9746 - val_loss: 5.7071 - val_accuracy: 0.3611\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0755 - accuracy: 0.9673 - val_loss: 6.0523 - val_accuracy: 0.3583\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 5.7292 - val_accuracy: 0.3861\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 6.0579 - val_accuracy: 0.3833\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0811 - accuracy: 0.9788 - val_loss: 5.7948 - val_accuracy: 0.3583\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0647 - accuracy: 0.9748 - val_loss: 6.1589 - val_accuracy: 0.3444\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1384 - accuracy: 0.9630 - val_loss: 5.9263 - val_accuracy: 0.3778\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0881 - accuracy: 0.9699 - val_loss: 5.7185 - val_accuracy: 0.3639\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0633 - accuracy: 0.9795 - val_loss: 5.8588 - val_accuracy: 0.3806\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9901 - val_loss: 5.8476 - val_accuracy: 0.3722\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1234 - accuracy: 0.9675 - val_loss: 6.0273 - val_accuracy: 0.3667\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0737 - accuracy: 0.9778 - val_loss: 6.2391 - val_accuracy: 0.3556\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0909 - accuracy: 0.9784 - val_loss: 5.3931 - val_accuracy: 0.3639\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 5.6574 - val_accuracy: 0.3556\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1790 - accuracy: 0.9526 - val_loss: 6.4291 - val_accuracy: 0.3667\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3065 - accuracy: 0.9273 - val_loss: 6.0968 - val_accuracy: 0.3583\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1426 - accuracy: 0.9672 - val_loss: 5.6708 - val_accuracy: 0.3556\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1073 - accuracy: 0.9651 - val_loss: 5.3460 - val_accuracy: 0.3861\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0898 - accuracy: 0.9729 - val_loss: 5.7837 - val_accuracy: 0.3667\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1480 - accuracy: 0.9580 - val_loss: 5.1552 - val_accuracy: 0.3806\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1078 - accuracy: 0.9740 - val_loss: 5.5587 - val_accuracy: 0.3722\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1404 - accuracy: 0.9687 - val_loss: 5.2419 - val_accuracy: 0.3833\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0887 - accuracy: 0.9753 - val_loss: 5.0649 - val_accuracy: 0.3639\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1331 - accuracy: 0.9537 - val_loss: 5.1515 - val_accuracy: 0.3611\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0394 - accuracy: 0.9866 - val_loss: 5.6322 - val_accuracy: 0.3750\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1230 - accuracy: 0.9748 - val_loss: 5.5420 - val_accuracy: 0.3861\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 5.0909 - val_accuracy: 0.3639\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1000 - accuracy: 0.9642 - val_loss: 5.3334 - val_accuracy: 0.3861\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0516 - accuracy: 0.9864 - val_loss: 6.0435 - val_accuracy: 0.3583\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.9702 - val_loss: 5.2011 - val_accuracy: 0.3583\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0825 - accuracy: 0.9710 - val_loss: 5.1292 - val_accuracy: 0.3778\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0744 - accuracy: 0.9737 - val_loss: 5.4949 - val_accuracy: 0.3861\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1130 - accuracy: 0.9580 - val_loss: 4.7684 - val_accuracy: 0.3667\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0984 - accuracy: 0.9704 - val_loss: 6.2296 - val_accuracy: 0.3667\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1685 - accuracy: 0.9556 - val_loss: 5.0948 - val_accuracy: 0.4000\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1042 - accuracy: 0.9691 - val_loss: 5.0787 - val_accuracy: 0.3972\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0672 - accuracy: 0.9838 - val_loss: 4.7915 - val_accuracy: 0.3917\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 5.2574 - val_accuracy: 0.3861\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0874 - accuracy: 0.9771 - val_loss: 4.7786 - val_accuracy: 0.4083\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0718 - accuracy: 0.9784 - val_loss: 4.8057 - val_accuracy: 0.3889\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9700 - val_loss: 5.4118 - val_accuracy: 0.3500\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 5.2061 - val_accuracy: 0.3750\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 0.9660 - val_loss: 5.2284 - val_accuracy: 0.3611\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1074 - accuracy: 0.9716 - val_loss: 5.4243 - val_accuracy: 0.3833\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1017 - accuracy: 0.9666 - val_loss: 4.4999 - val_accuracy: 0.3806\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0742 - accuracy: 0.9793 - val_loss: 5.1066 - val_accuracy: 0.3778\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1342 - accuracy: 0.9571 - val_loss: 4.6924 - val_accuracy: 0.3917\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 4.9206 - val_accuracy: 0.3917\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0865 - accuracy: 0.9772 - val_loss: 5.1791 - val_accuracy: 0.3750\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1375 - accuracy: 0.9572 - val_loss: 4.8893 - val_accuracy: 0.3694\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 5.4340 - val_accuracy: 0.3750\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0667 - accuracy: 0.9763 - val_loss: 5.8616 - val_accuracy: 0.3583\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1282 - accuracy: 0.9481 - val_loss: 6.4649 - val_accuracy: 0.3750\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1199 - accuracy: 0.9650 - val_loss: 5.4127 - val_accuracy: 0.3694\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 0.9883 - val_loss: 5.1617 - val_accuracy: 0.3833\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2284 - accuracy: 0.9406 - val_loss: 4.9365 - val_accuracy: 0.3361\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1599 - accuracy: 0.9468 - val_loss: 4.8652 - val_accuracy: 0.3556\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1327 - accuracy: 0.9578 - val_loss: 5.0284 - val_accuracy: 0.3583\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1350 - accuracy: 0.9594 - val_loss: 5.4779 - val_accuracy: 0.3667\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0659 - accuracy: 0.9748 - val_loss: 4.6966 - val_accuracy: 0.3639\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0772 - accuracy: 0.9756 - val_loss: 5.2906 - val_accuracy: 0.3889\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1247 - accuracy: 0.9642 - val_loss: 5.0810 - val_accuracy: 0.3778\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0583 - accuracy: 0.9828 - val_loss: 4.7288 - val_accuracy: 0.3750\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0793 - accuracy: 0.9726 - val_loss: 4.9697 - val_accuracy: 0.3750\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1095 - accuracy: 0.9629 - val_loss: 5.1584 - val_accuracy: 0.3667\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.9763 - val_loss: 4.8527 - val_accuracy: 0.3944\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.9807 - val_loss: 5.4477 - val_accuracy: 0.3694\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1094 - accuracy: 0.9689 - val_loss: 5.5108 - val_accuracy: 0.3667\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 5.3972 - val_accuracy: 0.3611\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0472 - accuracy: 0.9837 - val_loss: 5.7759 - val_accuracy: 0.3694\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1016 - accuracy: 0.9723 - val_loss: 5.3720 - val_accuracy: 0.3750\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1915 - accuracy: 0.9537 - val_loss: 5.7102 - val_accuracy: 0.3444\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0667 - accuracy: 0.9809 - val_loss: 5.6390 - val_accuracy: 0.3694\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 5.6895 - val_accuracy: 0.3611\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1142 - accuracy: 0.9677 - val_loss: 6.3482 - val_accuracy: 0.3917\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1999 - accuracy: 0.9553 - val_loss: 5.7931 - val_accuracy: 0.3694\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1058 - accuracy: 0.9695 - val_loss: 5.6931 - val_accuracy: 0.3778\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0570 - accuracy: 0.9806 - val_loss: 5.5749 - val_accuracy: 0.3694\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0675 - accuracy: 0.9799 - val_loss: 5.6481 - val_accuracy: 0.3833\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 0.9731 - val_loss: 5.1654 - val_accuracy: 0.3861\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0959 - accuracy: 0.9691 - val_loss: 5.4886 - val_accuracy: 0.3694\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2418 - accuracy: 0.9442 - val_loss: 5.0198 - val_accuracy: 0.3500\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1332 - accuracy: 0.9637 - val_loss: 4.7621 - val_accuracy: 0.3639\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0689 - accuracy: 0.9804 - val_loss: 4.8673 - val_accuracy: 0.3583\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 5.6107 - val_accuracy: 0.3889\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0457 - accuracy: 0.9889 - val_loss: 4.9083 - val_accuracy: 0.3639\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1347 - accuracy: 0.9617 - val_loss: 4.8240 - val_accuracy: 0.3861\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 5.6176 - val_accuracy: 0.3556\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1461 - accuracy: 0.9585 - val_loss: 4.8762 - val_accuracy: 0.3611\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3267 - accuracy: 0.9150 - val_loss: 5.7315 - val_accuracy: 0.3639\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1183 - accuracy: 0.9638 - val_loss: 5.1169 - val_accuracy: 0.3944\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1014 - accuracy: 0.9701 - val_loss: 5.5585 - val_accuracy: 0.3556\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1025 - accuracy: 0.9687 - val_loss: 5.2180 - val_accuracy: 0.3750\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 5.3233 - val_accuracy: 0.3750\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0582 - accuracy: 0.9843 - val_loss: 5.2555 - val_accuracy: 0.3861\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0571 - accuracy: 0.9798 - val_loss: 5.6261 - val_accuracy: 0.3778\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1162 - accuracy: 0.9564 - val_loss: 5.5079 - val_accuracy: 0.3833\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0903 - accuracy: 0.9830 - val_loss: 6.0747 - val_accuracy: 0.3778\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0661 - accuracy: 0.9768 - val_loss: 6.6276 - val_accuracy: 0.3611\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1253 - accuracy: 0.9585 - val_loss: 5.7459 - val_accuracy: 0.3722\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 5.7319 - val_accuracy: 0.3778\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2516 - accuracy: 0.9474 - val_loss: 5.6827 - val_accuracy: 0.3750\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0878 - accuracy: 0.9764 - val_loss: 5.2317 - val_accuracy: 0.3889\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0747 - accuracy: 0.9788 - val_loss: 5.8393 - val_accuracy: 0.3722\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.9667 - val_loss: 5.7420 - val_accuracy: 0.3889\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0698 - accuracy: 0.9783 - val_loss: 5.7653 - val_accuracy: 0.3750\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 5.9242 - val_accuracy: 0.3528\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.9846 - val_loss: 5.7248 - val_accuracy: 0.3611\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 5.8544 - val_accuracy: 0.3722\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1061 - accuracy: 0.9697 - val_loss: 5.0896 - val_accuracy: 0.3778\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0749 - accuracy: 0.9756 - val_loss: 6.1572 - val_accuracy: 0.3833\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0705 - accuracy: 0.9765 - val_loss: 5.5236 - val_accuracy: 0.3861\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1697 - accuracy: 0.9508 - val_loss: 5.6545 - val_accuracy: 0.3611\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1030 - accuracy: 0.9609 - val_loss: 6.1814 - val_accuracy: 0.3139\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1159 - accuracy: 0.9690 - val_loss: 6.5170 - val_accuracy: 0.3639\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2381 - accuracy: 0.9393 - val_loss: 5.7193 - val_accuracy: 0.3861\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9788 - val_loss: 5.2058 - val_accuracy: 0.3806\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9840 - val_loss: 5.3854 - val_accuracy: 0.3583\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0899 - accuracy: 0.9711 - val_loss: 5.9524 - val_accuracy: 0.3667\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0974 - accuracy: 0.9682 - val_loss: 5.9190 - val_accuracy: 0.3833\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0766 - accuracy: 0.9814 - val_loss: 6.1678 - val_accuracy: 0.3917\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.9858 - val_loss: 5.7590 - val_accuracy: 0.3833\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 6.0794 - val_accuracy: 0.3694\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0816 - accuracy: 0.9708 - val_loss: 6.5722 - val_accuracy: 0.3722\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 6.5798 - val_accuracy: 0.3667\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0712 - accuracy: 0.9791 - val_loss: 6.0422 - val_accuracy: 0.3667\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1045 - accuracy: 0.9718 - val_loss: 4.9329 - val_accuracy: 0.3722\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 5.9360 - val_accuracy: 0.3611\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1263 - accuracy: 0.9648 - val_loss: 5.7261 - val_accuracy: 0.3917\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0847 - accuracy: 0.9712 - val_loss: 6.1738 - val_accuracy: 0.3778\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1028 - accuracy: 0.9645 - val_loss: 6.3281 - val_accuracy: 0.3611\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 5.5375 - val_accuracy: 0.3778\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0718 - accuracy: 0.9755 - val_loss: 5.8041 - val_accuracy: 0.3833\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.9486 - val_loss: 5.3867 - val_accuracy: 0.3889\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1348 - accuracy: 0.9682 - val_loss: 5.3934 - val_accuracy: 0.3750\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0937 - accuracy: 0.9756 - val_loss: 5.7187 - val_accuracy: 0.3889\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0890 - accuracy: 0.9780 - val_loss: 5.6922 - val_accuracy: 0.3972\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0672 - accuracy: 0.9747 - val_loss: 5.6124 - val_accuracy: 0.3917\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0711 - accuracy: 0.9786 - val_loss: 5.1026 - val_accuracy: 0.3861\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0947 - accuracy: 0.9718 - val_loss: 6.2906 - val_accuracy: 0.3667\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0604 - accuracy: 0.9737 - val_loss: 5.6850 - val_accuracy: 0.4056\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0953 - accuracy: 0.9756 - val_loss: 5.8815 - val_accuracy: 0.3833\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9809 - val_loss: 5.8898 - val_accuracy: 0.3833\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0728 - accuracy: 0.9744 - val_loss: 5.8613 - val_accuracy: 0.3778\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.9864 - val_loss: 6.2603 - val_accuracy: 0.3833\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0594 - accuracy: 0.9853 - val_loss: 6.1416 - val_accuracy: 0.3583\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1449 - accuracy: 0.9615 - val_loss: 5.5728 - val_accuracy: 0.3806\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 5.9389 - val_accuracy: 0.3667\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0834 - accuracy: 0.9758 - val_loss: 5.3915 - val_accuracy: 0.3556\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8237 - accuracy: 0.8811 - val_loss: 5.8628 - val_accuracy: 0.3889\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0891 - accuracy: 0.9740 - val_loss: 5.3834 - val_accuracy: 0.3861\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0373 - accuracy: 0.9913 - val_loss: 5.9170 - val_accuracy: 0.3750\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 8.2911 - val_accuracy: 0.3500\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 5.8441 - accuracy: 0.7735 - val_loss: 6.6762 - val_accuracy: 0.3750\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1052 - accuracy: 0.9676 - val_loss: 5.7522 - val_accuracy: 0.3833\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0569 - accuracy: 0.9789 - val_loss: 5.7834 - val_accuracy: 0.3694\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 6.1636 - val_accuracy: 0.3639\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0655 - accuracy: 0.9792 - val_loss: 5.2001 - val_accuracy: 0.3833\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0876 - accuracy: 0.9680 - val_loss: 5.7855 - val_accuracy: 0.3472\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 5.7770 - val_accuracy: 0.3583\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 5.9438 - val_accuracy: 0.3639\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0634 - accuracy: 0.9760 - val_loss: 5.9903 - val_accuracy: 0.3750\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1031 - accuracy: 0.9602 - val_loss: 5.8217 - val_accuracy: 0.3806\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1252 - accuracy: 0.9797 - val_loss: 6.0785 - val_accuracy: 0.3556\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.9752 - val_loss: 7.5974 - val_accuracy: 0.3222\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1982 - accuracy: 0.9395 - val_loss: 5.5799 - val_accuracy: 0.3861\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0668 - accuracy: 0.9727 - val_loss: 5.4146 - val_accuracy: 0.3722\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0630 - accuracy: 0.9745 - val_loss: 5.2369 - val_accuracy: 0.3472\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0999 - accuracy: 0.9772 - val_loss: 5.1982 - val_accuracy: 0.3417\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0482 - accuracy: 0.9806 - val_loss: 5.4218 - val_accuracy: 0.3639\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.9816 - val_loss: 6.2650 - val_accuracy: 0.3972\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1048 - accuracy: 0.9702 - val_loss: 6.1859 - val_accuracy: 0.3556\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1081 - accuracy: 0.9771 - val_loss: 6.4109 - val_accuracy: 0.3639\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0657 - accuracy: 0.9790 - val_loss: 6.1304 - val_accuracy: 0.3694\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1253 - accuracy: 0.9670 - val_loss: 6.0300 - val_accuracy: 0.3667\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0752 - accuracy: 0.9747 - val_loss: 6.2641 - val_accuracy: 0.3722\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0707 - accuracy: 0.9810 - val_loss: 5.7306 - val_accuracy: 0.4028\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 6.5600 - val_accuracy: 0.3444\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 6.9202 - val_accuracy: 0.3639\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 7.0894 - val_accuracy: 0.3556\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0947 - accuracy: 0.9717 - val_loss: 5.6043 - val_accuracy: 0.3806\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1045 - accuracy: 0.9740 - val_loss: 6.4569 - val_accuracy: 0.3500\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2677 - accuracy: 0.9317 - val_loss: 6.0147 - val_accuracy: 0.3778\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9779 - val_loss: 6.2247 - val_accuracy: 0.3444\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 6.0546 - val_accuracy: 0.3667\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9880 - val_loss: 6.3506 - val_accuracy: 0.3583\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0558 - accuracy: 0.9824 - val_loss: 5.6651 - val_accuracy: 0.3694\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0759 - accuracy: 0.9771 - val_loss: 6.3305 - val_accuracy: 0.3583\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0919 - accuracy: 0.9725 - val_loss: 5.9896 - val_accuracy: 0.3722\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0982 - accuracy: 0.9711 - val_loss: 6.0530 - val_accuracy: 0.3917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mhMVRCMGQiH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb11bf1b-9887-4db2-af6b-ca57c025bf23"
      },
      "source": [
        "plotter(history)\n",
        "\n",
        "model.summary()\n",
        "result = model.evaluate(X_test,y_test)\n",
        "print(result)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_13 (ModuleWra (None, 153, 64)           704       \n",
            "_________________________________________________________________\n",
            "module_wrapper_14 (ModuleWra (None, 144, 128)          82048     \n",
            "_________________________________________________________________\n",
            "module_wrapper_15 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_16 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_17 (ModuleWra (None, 9, 128)            163968    \n",
            "_________________________________________________________________\n",
            "module_wrapper_18 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_19 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_20 (ModuleWra (None, 1, 64)             41024     \n",
            "_________________________________________________________________\n",
            "module_wrapper_21 (ModuleWra (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_22 (ModuleWra (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_23 (ModuleWra (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "module_wrapper_24 (ModuleWra (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_25 (ModuleWra (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 306,440\n",
            "Trainable params: 306,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "12/12 [==============================] - 1s 10ms/step - loss: 6.0530 - accuracy: 0.3917\n",
            "[6.053044319152832, 0.3916666805744171]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}