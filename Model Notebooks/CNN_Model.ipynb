{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6 CNN Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdxwpf0bGdq0"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN4ZdCEVGojS"
      },
      "source": [
        "def plotter(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'],label='train loss')\n",
        "  plt.plot(history.history['val_loss'],label='test loss')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('losses')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'],label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'],label='test accuracy')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nUFvHQGnsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "d324af35-ca9d-48e2-bbde-46e0bdf965ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Features = pd.read_csv('/content/drive/MyDrive/features_dataset.csv')\n",
        "Features.head()\n",
        "# Features.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.272267</td>\n",
              "      <td>0.689451</td>\n",
              "      <td>0.708028</td>\n",
              "      <td>0.666473</td>\n",
              "      <td>0.715468</td>\n",
              "      <td>0.694820</td>\n",
              "      <td>0.627661</td>\n",
              "      <td>0.632560</td>\n",
              "      <td>0.687715</td>\n",
              "      <td>0.712157</td>\n",
              "      <td>0.706116</td>\n",
              "      <td>0.696561</td>\n",
              "      <td>0.666424</td>\n",
              "      <td>-505.009247</td>\n",
              "      <td>64.000099</td>\n",
              "      <td>-2.749660</td>\n",
              "      <td>16.950371</td>\n",
              "      <td>-1.089467</td>\n",
              "      <td>-2.046432</td>\n",
              "      <td>-7.829981</td>\n",
              "      <td>-8.716751</td>\n",
              "      <td>-19.273317</td>\n",
              "      <td>-5.294091</td>\n",
              "      <td>-5.584455</td>\n",
              "      <td>-5.783628</td>\n",
              "      <td>-1.870991</td>\n",
              "      <td>-7.146638</td>\n",
              "      <td>-3.675263</td>\n",
              "      <td>-0.451763</td>\n",
              "      <td>-11.253410</td>\n",
              "      <td>-3.521277</td>\n",
              "      <td>-3.482842</td>\n",
              "      <td>-5.802355</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.018095</td>\n",
              "      <td>0.134511</td>\n",
              "      <td>0.229614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>0.002306</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001945</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.003231</td>\n",
              "      <td>0.002353</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.002131</td>\n",
              "      <td>0.001839</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001006</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>1.498768e-05</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.262035</td>\n",
              "      <td>0.603476</td>\n",
              "      <td>0.668302</td>\n",
              "      <td>0.692199</td>\n",
              "      <td>0.709884</td>\n",
              "      <td>0.658301</td>\n",
              "      <td>0.605176</td>\n",
              "      <td>0.609343</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>0.689348</td>\n",
              "      <td>0.702884</td>\n",
              "      <td>0.687124</td>\n",
              "      <td>0.663653</td>\n",
              "      <td>-626.262817</td>\n",
              "      <td>93.897247</td>\n",
              "      <td>-0.691273</td>\n",
              "      <td>17.833763</td>\n",
              "      <td>9.502007</td>\n",
              "      <td>2.030928</td>\n",
              "      <td>-2.721135</td>\n",
              "      <td>-8.514406</td>\n",
              "      <td>-12.427499</td>\n",
              "      <td>-6.575863</td>\n",
              "      <td>-0.015912</td>\n",
              "      <td>-2.750585</td>\n",
              "      <td>0.777975</td>\n",
              "      <td>-5.365466</td>\n",
              "      <td>-0.337154</td>\n",
              "      <td>1.482861</td>\n",
              "      <td>-8.703282</td>\n",
              "      <td>-2.764846</td>\n",
              "      <td>-1.618086</td>\n",
              "      <td>-1.523441</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.008725</td>\n",
              "      <td>0.090577</td>\n",
              "      <td>0.060794</td>\n",
              "      <td>0.002684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>8.432723e-07</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.195466</td>\n",
              "      <td>0.628032</td>\n",
              "      <td>0.687169</td>\n",
              "      <td>0.651985</td>\n",
              "      <td>0.621273</td>\n",
              "      <td>0.604192</td>\n",
              "      <td>0.640623</td>\n",
              "      <td>0.626136</td>\n",
              "      <td>0.652430</td>\n",
              "      <td>0.685134</td>\n",
              "      <td>0.653014</td>\n",
              "      <td>0.649654</td>\n",
              "      <td>0.632400</td>\n",
              "      <td>-535.881226</td>\n",
              "      <td>82.281357</td>\n",
              "      <td>-9.010551</td>\n",
              "      <td>20.842283</td>\n",
              "      <td>5.421832</td>\n",
              "      <td>-3.754339</td>\n",
              "      <td>-10.541499</td>\n",
              "      <td>-13.465772</td>\n",
              "      <td>-27.917681</td>\n",
              "      <td>-6.894572</td>\n",
              "      <td>-3.809465</td>\n",
              "      <td>-10.429282</td>\n",
              "      <td>0.157545</td>\n",
              "      <td>-7.953777</td>\n",
              "      <td>-6.011678</td>\n",
              "      <td>2.456674</td>\n",
              "      <td>-10.448029</td>\n",
              "      <td>-6.485257</td>\n",
              "      <td>-4.687830</td>\n",
              "      <td>-3.553447</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.016251</td>\n",
              "      <td>0.110550</td>\n",
              "      <td>0.186236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.000436</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>2.326331e-06</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.173769</td>\n",
              "      <td>0.720864</td>\n",
              "      <td>0.685492</td>\n",
              "      <td>0.655122</td>\n",
              "      <td>0.652557</td>\n",
              "      <td>0.587786</td>\n",
              "      <td>0.550012</td>\n",
              "      <td>0.638170</td>\n",
              "      <td>0.707171</td>\n",
              "      <td>0.648498</td>\n",
              "      <td>0.604207</td>\n",
              "      <td>0.638241</td>\n",
              "      <td>0.707306</td>\n",
              "      <td>-526.520569</td>\n",
              "      <td>84.466164</td>\n",
              "      <td>-6.822329</td>\n",
              "      <td>22.756920</td>\n",
              "      <td>8.021371</td>\n",
              "      <td>-0.836710</td>\n",
              "      <td>-6.375116</td>\n",
              "      <td>-13.950517</td>\n",
              "      <td>-15.801805</td>\n",
              "      <td>-1.701238</td>\n",
              "      <td>-3.240356</td>\n",
              "      <td>-2.120920</td>\n",
              "      <td>-1.001574</td>\n",
              "      <td>-5.576652</td>\n",
              "      <td>-0.277861</td>\n",
              "      <td>0.180505</td>\n",
              "      <td>-5.214784</td>\n",
              "      <td>-4.889361</td>\n",
              "      <td>-1.206443</td>\n",
              "      <td>2.497521</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.052773</td>\n",
              "      <td>0.284222</td>\n",
              "      <td>0.078999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>0.001356</td>\n",
              "      <td>0.000967</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>4.691918e-06</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.207284</td>\n",
              "      <td>0.692981</td>\n",
              "      <td>0.737456</td>\n",
              "      <td>0.726056</td>\n",
              "      <td>0.685032</td>\n",
              "      <td>0.636497</td>\n",
              "      <td>0.568223</td>\n",
              "      <td>0.528898</td>\n",
              "      <td>0.598124</td>\n",
              "      <td>0.635435</td>\n",
              "      <td>0.643268</td>\n",
              "      <td>0.671737</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>-591.298523</td>\n",
              "      <td>92.935883</td>\n",
              "      <td>-4.376369</td>\n",
              "      <td>22.136271</td>\n",
              "      <td>9.728477</td>\n",
              "      <td>-3.868228</td>\n",
              "      <td>-4.231765</td>\n",
              "      <td>-12.517565</td>\n",
              "      <td>-17.417633</td>\n",
              "      <td>-6.273466</td>\n",
              "      <td>-7.159021</td>\n",
              "      <td>-2.124696</td>\n",
              "      <td>-2.085358</td>\n",
              "      <td>-9.489192</td>\n",
              "      <td>-3.802913</td>\n",
              "      <td>-1.608241</td>\n",
              "      <td>-9.055273</td>\n",
              "      <td>-6.693238</td>\n",
              "      <td>-5.338201</td>\n",
              "      <td>-0.922801</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.001787</td>\n",
              "      <td>0.018344</td>\n",
              "      <td>0.063987</td>\n",
              "      <td>0.039720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.218449e-07</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1  ...       159           160  labels\n",
              "0           0  0.272267  0.689451  ...  0.000143  1.498768e-05   angry\n",
              "1           1  0.262035  0.603476  ...  0.000011  8.432723e-07    calm\n",
              "2           2  0.195466  0.628032  ...  0.000031  2.326331e-06     sad\n",
              "3           3  0.173769  0.720864  ...  0.000074  4.691918e-06    fear\n",
              "4           4  0.207284  0.692981  ...  0.000008  4.218449e-07     sad\n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B88N9_mJ6S_Y"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "temp = shuffle(Features)\n",
        "# temp[:10]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5kFASY7Fql"
      },
      "source": [
        "df = np.random.rand(len(temp)) < 0.8\n",
        "train = temp[df]\n",
        "test = temp[~df]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh5rIXz87gEE"
      },
      "source": [
        "trainfeatures = train.iloc[:, :-1]\n",
        "trainlabel = train.iloc[:, -1:]\n",
        "testfeatures = test.iloc[:, :-1]\n",
        "testlabel = test.iloc[:, -1:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fqDHjxq7vUF"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train = np.array(trainfeatures)\n",
        "y_train = np.array(trainlabel)\n",
        "X_test = np.array(testfeatures)\n",
        "y_test = np.array(testlabel)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKd_61MS76ML"
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3MRQgDr8Aqj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers, optimizers\n",
        "\n",
        "# model = models.Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(256, 5,padding='same', input_shape=(x_traincnn.shape[1],1)))\n",
        "# model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(128, 5,padding='same'))\n",
        "# model.add(tf.keras.layers.Activation('relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.1))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(128, 5,padding='same',))\n",
        "# model.add(tf.keras.layers.Activation('relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.1))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(64, 5,padding='same',))\n",
        "# model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(8))\n",
        "# model.add(tf.keras.layers.Activation('softmax'))\n",
        "# opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(64, 5,padding='same',))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
        "opt = keras.optimizers.Adam(lr=0.0001)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-0SUzFP-zpU"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBpYQEyA_IeQ",
        "outputId": "c5aff658-ba3c-49fd-aa93-d944d4feb333"
      },
      "source": [
        "history=model.fit(x_traincnn, y_train, batch_size=256, epochs=1000, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 2s 133ms/step - loss: 3.4503 - accuracy: 0.1321 - val_loss: 2.0599 - val_accuracy: 0.1376\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.7673 - accuracy: 0.1346 - val_loss: 2.0665 - val_accuracy: 0.1477\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.5812 - accuracy: 0.1415 - val_loss: 2.0638 - val_accuracy: 0.1711\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.3832 - accuracy: 0.1243 - val_loss: 2.0618 - val_accuracy: 0.1745\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.3183 - accuracy: 0.1314 - val_loss: 2.0574 - val_accuracy: 0.1779\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.2288 - accuracy: 0.1355 - val_loss: 2.0591 - val_accuracy: 0.1745\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.2132 - accuracy: 0.1167 - val_loss: 2.0611 - val_accuracy: 0.1678\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1728 - accuracy: 0.1518 - val_loss: 2.0632 - val_accuracy: 0.1544\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1316 - accuracy: 0.1419 - val_loss: 2.0651 - val_accuracy: 0.1510\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1303 - accuracy: 0.1238 - val_loss: 2.0655 - val_accuracy: 0.1611\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.1151 - accuracy: 0.1395 - val_loss: 2.0644 - val_accuracy: 0.1644\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1137 - accuracy: 0.1474 - val_loss: 2.0627 - val_accuracy: 0.1678\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1194 - accuracy: 0.1322 - val_loss: 2.0616 - val_accuracy: 0.1779\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1068 - accuracy: 0.1655 - val_loss: 2.0595 - val_accuracy: 0.1913\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1252 - accuracy: 0.1325 - val_loss: 2.0571 - val_accuracy: 0.1913\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1202 - accuracy: 0.1258 - val_loss: 2.0558 - val_accuracy: 0.1678\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0937 - accuracy: 0.1420 - val_loss: 2.0539 - val_accuracy: 0.1745\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1004 - accuracy: 0.1260 - val_loss: 2.0514 - val_accuracy: 0.2349\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0892 - accuracy: 0.1522 - val_loss: 2.0482 - val_accuracy: 0.2483\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0935 - accuracy: 0.1638 - val_loss: 2.0439 - val_accuracy: 0.2282\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0667 - accuracy: 0.1405 - val_loss: 2.0388 - val_accuracy: 0.2349\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0607 - accuracy: 0.1620 - val_loss: 2.0342 - val_accuracy: 0.2349\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0781 - accuracy: 0.1478 - val_loss: 2.0279 - val_accuracy: 0.2215\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0733 - accuracy: 0.1627 - val_loss: 2.0216 - val_accuracy: 0.2114\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.0489 - accuracy: 0.1709 - val_loss: 2.0164 - val_accuracy: 0.1980\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0388 - accuracy: 0.1802 - val_loss: 2.0103 - val_accuracy: 0.1745\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0646 - accuracy: 0.1618 - val_loss: 2.0031 - val_accuracy: 0.1913\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0446 - accuracy: 0.1601 - val_loss: 1.9948 - val_accuracy: 0.1980\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0729 - accuracy: 0.1798 - val_loss: 1.9891 - val_accuracy: 0.1946\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0327 - accuracy: 0.1751 - val_loss: 1.9830 - val_accuracy: 0.1879\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0484 - accuracy: 0.1702 - val_loss: 1.9770 - val_accuracy: 0.2047\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0293 - accuracy: 0.1789 - val_loss: 1.9708 - val_accuracy: 0.2148\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0268 - accuracy: 0.1851 - val_loss: 1.9657 - val_accuracy: 0.2047\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0181 - accuracy: 0.1881 - val_loss: 1.9597 - val_accuracy: 0.1980\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0113 - accuracy: 0.2040 - val_loss: 1.9552 - val_accuracy: 0.2349\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9958 - accuracy: 0.1849 - val_loss: 1.9510 - val_accuracy: 0.2181\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0235 - accuracy: 0.1849 - val_loss: 1.9463 - val_accuracy: 0.2148\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9974 - accuracy: 0.1992 - val_loss: 1.9405 - val_accuracy: 0.2148\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0303 - accuracy: 0.1764 - val_loss: 1.9354 - val_accuracy: 0.2215\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0028 - accuracy: 0.1826 - val_loss: 1.9300 - val_accuracy: 0.2215\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0030 - accuracy: 0.1974 - val_loss: 1.9277 - val_accuracy: 0.2315\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0016 - accuracy: 0.1879 - val_loss: 1.9265 - val_accuracy: 0.2383\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9882 - accuracy: 0.2050 - val_loss: 1.9224 - val_accuracy: 0.2450\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9793 - accuracy: 0.2071 - val_loss: 1.9182 - val_accuracy: 0.2315\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0099 - accuracy: 0.1760 - val_loss: 1.9172 - val_accuracy: 0.2315\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9946 - accuracy: 0.1817 - val_loss: 1.9175 - val_accuracy: 0.2282\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9922 - accuracy: 0.2034 - val_loss: 1.9175 - val_accuracy: 0.2282\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9807 - accuracy: 0.2065 - val_loss: 1.9156 - val_accuracy: 0.2282\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9576 - accuracy: 0.2137 - val_loss: 1.9117 - val_accuracy: 0.2349\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9508 - accuracy: 0.2239 - val_loss: 1.9073 - val_accuracy: 0.2282\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9690 - accuracy: 0.2021 - val_loss: 1.9031 - val_accuracy: 0.2282\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.9483 - accuracy: 0.2075 - val_loss: 1.8984 - val_accuracy: 0.2315\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9810 - accuracy: 0.2036 - val_loss: 1.8940 - val_accuracy: 0.2349\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9592 - accuracy: 0.2212 - val_loss: 1.8923 - val_accuracy: 0.2349\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9449 - accuracy: 0.2276 - val_loss: 1.8913 - val_accuracy: 0.2315\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9457 - accuracy: 0.2244 - val_loss: 1.8886 - val_accuracy: 0.2282\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.9333 - accuracy: 0.2270 - val_loss: 1.8840 - val_accuracy: 0.2383\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9738 - accuracy: 0.2093 - val_loss: 1.8807 - val_accuracy: 0.2282\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9509 - accuracy: 0.2137 - val_loss: 1.8794 - val_accuracy: 0.2282\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9406 - accuracy: 0.2282 - val_loss: 1.8778 - val_accuracy: 0.2282\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9480 - accuracy: 0.2110 - val_loss: 1.8767 - val_accuracy: 0.2383\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9600 - accuracy: 0.1950 - val_loss: 1.8762 - val_accuracy: 0.2349\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9432 - accuracy: 0.2322 - val_loss: 1.8777 - val_accuracy: 0.2315\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9407 - accuracy: 0.2185 - val_loss: 1.8761 - val_accuracy: 0.2383\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9519 - accuracy: 0.2285 - val_loss: 1.8735 - val_accuracy: 0.2349\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9382 - accuracy: 0.2202 - val_loss: 1.8696 - val_accuracy: 0.2383\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9290 - accuracy: 0.2316 - val_loss: 1.8646 - val_accuracy: 0.2383\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9563 - accuracy: 0.2276 - val_loss: 1.8607 - val_accuracy: 0.2416\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9312 - accuracy: 0.2205 - val_loss: 1.8558 - val_accuracy: 0.2315\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9154 - accuracy: 0.2275 - val_loss: 1.8524 - val_accuracy: 0.2282\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9202 - accuracy: 0.2261 - val_loss: 1.8515 - val_accuracy: 0.2315\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9280 - accuracy: 0.2432 - val_loss: 1.8510 - val_accuracy: 0.2383\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9512 - accuracy: 0.2078 - val_loss: 1.8540 - val_accuracy: 0.2383\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9168 - accuracy: 0.2371 - val_loss: 1.8553 - val_accuracy: 0.2349\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9096 - accuracy: 0.2174 - val_loss: 1.8507 - val_accuracy: 0.2349\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9305 - accuracy: 0.2383 - val_loss: 1.8470 - val_accuracy: 0.2282\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9084 - accuracy: 0.2274 - val_loss: 1.8430 - val_accuracy: 0.2416\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9115 - accuracy: 0.2283 - val_loss: 1.8406 - val_accuracy: 0.2416\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8978 - accuracy: 0.2223 - val_loss: 1.8358 - val_accuracy: 0.2383\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8958 - accuracy: 0.2443 - val_loss: 1.8329 - val_accuracy: 0.2450\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9543 - accuracy: 0.2191 - val_loss: 1.8347 - val_accuracy: 0.2450\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8874 - accuracy: 0.2395 - val_loss: 1.8340 - val_accuracy: 0.2517\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9247 - accuracy: 0.2391 - val_loss: 1.8347 - val_accuracy: 0.2383\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9213 - accuracy: 0.2574 - val_loss: 1.8360 - val_accuracy: 0.2383\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9195 - accuracy: 0.2449 - val_loss: 1.8354 - val_accuracy: 0.2349\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9039 - accuracy: 0.2232 - val_loss: 1.8355 - val_accuracy: 0.2416\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9128 - accuracy: 0.2129 - val_loss: 1.8343 - val_accuracy: 0.2483\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9003 - accuracy: 0.2479 - val_loss: 1.8313 - val_accuracy: 0.2517\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8993 - accuracy: 0.2521 - val_loss: 1.8295 - val_accuracy: 0.2483\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9042 - accuracy: 0.2431 - val_loss: 1.8267 - val_accuracy: 0.2483\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8764 - accuracy: 0.2470 - val_loss: 1.8247 - val_accuracy: 0.2450\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9070 - accuracy: 0.2269 - val_loss: 1.8221 - val_accuracy: 0.2517\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9096 - accuracy: 0.2387 - val_loss: 1.8223 - val_accuracy: 0.2517\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8873 - accuracy: 0.2452 - val_loss: 1.8241 - val_accuracy: 0.2550\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8688 - accuracy: 0.2572 - val_loss: 1.8198 - val_accuracy: 0.2517\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8904 - accuracy: 0.2468 - val_loss: 1.8190 - val_accuracy: 0.2550\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8954 - accuracy: 0.2406 - val_loss: 1.8172 - val_accuracy: 0.2450\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8853 - accuracy: 0.2660 - val_loss: 1.8146 - val_accuracy: 0.2416\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8868 - accuracy: 0.2378 - val_loss: 1.8111 - val_accuracy: 0.2550\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8918 - accuracy: 0.2511 - val_loss: 1.8066 - val_accuracy: 0.2651\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8905 - accuracy: 0.2472 - val_loss: 1.8038 - val_accuracy: 0.2584\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8663 - accuracy: 0.2560 - val_loss: 1.8003 - val_accuracy: 0.2550\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8831 - accuracy: 0.2369 - val_loss: 1.7960 - val_accuracy: 0.2584\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8736 - accuracy: 0.2462 - val_loss: 1.7955 - val_accuracy: 0.2617\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9173 - accuracy: 0.2395 - val_loss: 1.7984 - val_accuracy: 0.2550\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8786 - accuracy: 0.2634 - val_loss: 1.7973 - val_accuracy: 0.2685\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8606 - accuracy: 0.2718 - val_loss: 1.7964 - val_accuracy: 0.2651\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.7953 - val_accuracy: 0.2651\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8371 - accuracy: 0.2669 - val_loss: 1.7958 - val_accuracy: 0.2617\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8489 - accuracy: 0.2320 - val_loss: 1.7927 - val_accuracy: 0.2718\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8666 - accuracy: 0.2574 - val_loss: 1.7907 - val_accuracy: 0.2785\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8555 - accuracy: 0.2478 - val_loss: 1.7910 - val_accuracy: 0.2685\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8699 - accuracy: 0.2660 - val_loss: 1.7907 - val_accuracy: 0.2617\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8726 - accuracy: 0.2604 - val_loss: 1.7922 - val_accuracy: 0.2718\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8544 - accuracy: 0.2552 - val_loss: 1.7897 - val_accuracy: 0.2752\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8680 - accuracy: 0.2543 - val_loss: 1.7862 - val_accuracy: 0.2919\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8668 - accuracy: 0.2423 - val_loss: 1.7866 - val_accuracy: 0.2886\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8343 - accuracy: 0.2803 - val_loss: 1.7861 - val_accuracy: 0.2852\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8683 - accuracy: 0.2584 - val_loss: 1.7821 - val_accuracy: 0.2718\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8535 - accuracy: 0.2836 - val_loss: 1.7782 - val_accuracy: 0.2819\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8730 - accuracy: 0.2542 - val_loss: 1.7780 - val_accuracy: 0.2752\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8562 - accuracy: 0.2491 - val_loss: 1.7770 - val_accuracy: 0.2785\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8334 - accuracy: 0.2803 - val_loss: 1.7720 - val_accuracy: 0.2819\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8463 - accuracy: 0.2624 - val_loss: 1.7719 - val_accuracy: 0.2886\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8613 - accuracy: 0.2792 - val_loss: 1.7724 - val_accuracy: 0.2819\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8327 - accuracy: 0.2784 - val_loss: 1.7706 - val_accuracy: 0.2819\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8246 - accuracy: 0.2768 - val_loss: 1.7678 - val_accuracy: 0.2752\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8402 - accuracy: 0.2698 - val_loss: 1.7654 - val_accuracy: 0.2752\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8257 - accuracy: 0.2851 - val_loss: 1.7663 - val_accuracy: 0.2718\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8448 - accuracy: 0.2778 - val_loss: 1.7644 - val_accuracy: 0.2651\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8423 - accuracy: 0.2690 - val_loss: 1.7650 - val_accuracy: 0.2785\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8536 - accuracy: 0.2652 - val_loss: 1.7663 - val_accuracy: 0.2752\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8318 - accuracy: 0.2619 - val_loss: 1.7640 - val_accuracy: 0.2852\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8285 - accuracy: 0.2856 - val_loss: 1.7548 - val_accuracy: 0.2886\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8054 - accuracy: 0.2879 - val_loss: 1.7528 - val_accuracy: 0.2785\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8344 - accuracy: 0.2679 - val_loss: 1.7525 - val_accuracy: 0.2953\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8261 - accuracy: 0.2885 - val_loss: 1.7524 - val_accuracy: 0.3054\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8027 - accuracy: 0.2972 - val_loss: 1.7537 - val_accuracy: 0.2953\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8429 - accuracy: 0.2731 - val_loss: 1.7482 - val_accuracy: 0.2919\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8082 - accuracy: 0.2923 - val_loss: 1.7435 - val_accuracy: 0.2987\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8317 - accuracy: 0.2655 - val_loss: 1.7415 - val_accuracy: 0.2886\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8405 - accuracy: 0.2672 - val_loss: 1.7432 - val_accuracy: 0.2953\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8430 - accuracy: 0.2780 - val_loss: 1.7446 - val_accuracy: 0.2886\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.8109 - accuracy: 0.2843 - val_loss: 1.7451 - val_accuracy: 0.2919\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7913 - accuracy: 0.2895 - val_loss: 1.7440 - val_accuracy: 0.2852\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8548 - accuracy: 0.2689 - val_loss: 1.7410 - val_accuracy: 0.2919\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8025 - accuracy: 0.2718 - val_loss: 1.7419 - val_accuracy: 0.2819\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8096 - accuracy: 0.2806 - val_loss: 1.7407 - val_accuracy: 0.2852\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8066 - accuracy: 0.2851 - val_loss: 1.7388 - val_accuracy: 0.2785\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7952 - accuracy: 0.2933 - val_loss: 1.7369 - val_accuracy: 0.2785\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8123 - accuracy: 0.3019 - val_loss: 1.7333 - val_accuracy: 0.2852\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7807 - accuracy: 0.2910 - val_loss: 1.7296 - val_accuracy: 0.2953\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7734 - accuracy: 0.2872 - val_loss: 1.7236 - val_accuracy: 0.3054\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8183 - accuracy: 0.2918 - val_loss: 1.7206 - val_accuracy: 0.3121\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7983 - accuracy: 0.3056 - val_loss: 1.7205 - val_accuracy: 0.2953\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7888 - accuracy: 0.3047 - val_loss: 1.7216 - val_accuracy: 0.2953\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8083 - accuracy: 0.2652 - val_loss: 1.7233 - val_accuracy: 0.3020\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7827 - accuracy: 0.2868 - val_loss: 1.7226 - val_accuracy: 0.2919\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7832 - accuracy: 0.2789 - val_loss: 1.7215 - val_accuracy: 0.2987\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8086 - accuracy: 0.2992 - val_loss: 1.7180 - val_accuracy: 0.3020\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7918 - accuracy: 0.2869 - val_loss: 1.7143 - val_accuracy: 0.2886\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7747 - accuracy: 0.3057 - val_loss: 1.7119 - val_accuracy: 0.2785\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7915 - accuracy: 0.3146 - val_loss: 1.7098 - val_accuracy: 0.2919\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7848 - accuracy: 0.3122 - val_loss: 1.7086 - val_accuracy: 0.2987\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7672 - accuracy: 0.3125 - val_loss: 1.7074 - val_accuracy: 0.2987\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7733 - accuracy: 0.3008 - val_loss: 1.7055 - val_accuracy: 0.2919\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8072 - accuracy: 0.2816 - val_loss: 1.7060 - val_accuracy: 0.2953\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7820 - accuracy: 0.2989 - val_loss: 1.7062 - val_accuracy: 0.2953\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7703 - accuracy: 0.3063 - val_loss: 1.7075 - val_accuracy: 0.3020\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7585 - accuracy: 0.3220 - val_loss: 1.7063 - val_accuracy: 0.2886\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7683 - accuracy: 0.2966 - val_loss: 1.7067 - val_accuracy: 0.2852\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7859 - accuracy: 0.2782 - val_loss: 1.7043 - val_accuracy: 0.2752\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7690 - accuracy: 0.3145 - val_loss: 1.7025 - val_accuracy: 0.2919\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7717 - accuracy: 0.3074 - val_loss: 1.6997 - val_accuracy: 0.3020\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7839 - accuracy: 0.3027 - val_loss: 1.6968 - val_accuracy: 0.2852\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7920 - accuracy: 0.2805 - val_loss: 1.6931 - val_accuracy: 0.3020\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7405 - accuracy: 0.3211 - val_loss: 1.6905 - val_accuracy: 0.3087\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7647 - accuracy: 0.2996 - val_loss: 1.6901 - val_accuracy: 0.3020\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.7573 - accuracy: 0.3071 - val_loss: 1.6884 - val_accuracy: 0.3020\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7609 - accuracy: 0.3123 - val_loss: 1.6894 - val_accuracy: 0.3087\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7750 - accuracy: 0.3067 - val_loss: 1.6913 - val_accuracy: 0.3087\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7292 - accuracy: 0.3433 - val_loss: 1.6957 - val_accuracy: 0.3121\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7471 - accuracy: 0.3132 - val_loss: 1.6944 - val_accuracy: 0.3087\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7604 - accuracy: 0.3128 - val_loss: 1.6921 - val_accuracy: 0.3054\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7721 - accuracy: 0.2912 - val_loss: 1.6904 - val_accuracy: 0.2785\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7516 - accuracy: 0.3024 - val_loss: 1.6869 - val_accuracy: 0.2886\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7509 - accuracy: 0.3272 - val_loss: 1.6826 - val_accuracy: 0.2953\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7502 - accuracy: 0.3313 - val_loss: 1.6833 - val_accuracy: 0.2987\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7868 - accuracy: 0.2853 - val_loss: 1.6841 - val_accuracy: 0.3188\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7603 - accuracy: 0.3042 - val_loss: 1.6898 - val_accuracy: 0.2886\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7181 - accuracy: 0.3293 - val_loss: 1.6861 - val_accuracy: 0.2919\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7266 - accuracy: 0.3272 - val_loss: 1.6762 - val_accuracy: 0.3322\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7502 - accuracy: 0.2858 - val_loss: 1.6688 - val_accuracy: 0.3121\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7175 - accuracy: 0.3369 - val_loss: 1.6644 - val_accuracy: 0.3221\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7372 - accuracy: 0.3070 - val_loss: 1.6677 - val_accuracy: 0.3356\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7186 - accuracy: 0.3122 - val_loss: 1.6726 - val_accuracy: 0.2987\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7231 - accuracy: 0.3305 - val_loss: 1.6654 - val_accuracy: 0.3322\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7124 - accuracy: 0.3263 - val_loss: 1.6621 - val_accuracy: 0.3255\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6961 - accuracy: 0.3349 - val_loss: 1.6615 - val_accuracy: 0.3087\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7241 - accuracy: 0.3317 - val_loss: 1.6535 - val_accuracy: 0.3423\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7397 - accuracy: 0.3012 - val_loss: 1.6567 - val_accuracy: 0.3255\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7389 - accuracy: 0.3145 - val_loss: 1.6604 - val_accuracy: 0.3154\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7137 - accuracy: 0.3359 - val_loss: 1.6586 - val_accuracy: 0.3188\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7557 - accuracy: 0.2916 - val_loss: 1.6589 - val_accuracy: 0.3188\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7046 - accuracy: 0.3423 - val_loss: 1.6568 - val_accuracy: 0.3289\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7150 - accuracy: 0.3230 - val_loss: 1.6513 - val_accuracy: 0.3356\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7054 - accuracy: 0.3289 - val_loss: 1.6477 - val_accuracy: 0.3423\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6940 - accuracy: 0.3457 - val_loss: 1.6478 - val_accuracy: 0.3557\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7457 - accuracy: 0.3349 - val_loss: 1.6487 - val_accuracy: 0.3456\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7070 - accuracy: 0.3370 - val_loss: 1.6524 - val_accuracy: 0.3289\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6975 - accuracy: 0.3152 - val_loss: 1.6477 - val_accuracy: 0.3456\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6978 - accuracy: 0.3466 - val_loss: 1.6417 - val_accuracy: 0.3423\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7002 - accuracy: 0.3386 - val_loss: 1.6401 - val_accuracy: 0.3423\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7089 - accuracy: 0.3289 - val_loss: 1.6391 - val_accuracy: 0.3389\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.6810 - accuracy: 0.3321 - val_loss: 1.6379 - val_accuracy: 0.3389\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6965 - accuracy: 0.3457 - val_loss: 1.6352 - val_accuracy: 0.3389\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7056 - accuracy: 0.3550 - val_loss: 1.6315 - val_accuracy: 0.3523\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6781 - accuracy: 0.3153 - val_loss: 1.6324 - val_accuracy: 0.3389\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6912 - accuracy: 0.3521 - val_loss: 1.6319 - val_accuracy: 0.3423\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6604 - accuracy: 0.3486 - val_loss: 1.6307 - val_accuracy: 0.3389\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6844 - accuracy: 0.3360 - val_loss: 1.6334 - val_accuracy: 0.3423\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.6861 - accuracy: 0.3368 - val_loss: 1.6294 - val_accuracy: 0.3591\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7123 - accuracy: 0.3201 - val_loss: 1.6253 - val_accuracy: 0.3456\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7079 - accuracy: 0.3446 - val_loss: 1.6185 - val_accuracy: 0.3557\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6820 - accuracy: 0.3448 - val_loss: 1.6252 - val_accuracy: 0.3557\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6872 - accuracy: 0.3465 - val_loss: 1.6320 - val_accuracy: 0.3423\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6702 - accuracy: 0.3591 - val_loss: 1.6285 - val_accuracy: 0.3389\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6716 - accuracy: 0.3556 - val_loss: 1.6198 - val_accuracy: 0.3456\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6890 - accuracy: 0.3399 - val_loss: 1.6138 - val_accuracy: 0.3523\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6966 - accuracy: 0.3557 - val_loss: 1.6102 - val_accuracy: 0.3523\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6615 - accuracy: 0.3461 - val_loss: 1.6134 - val_accuracy: 0.3456\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6619 - accuracy: 0.3459 - val_loss: 1.6105 - val_accuracy: 0.3624\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6707 - accuracy: 0.3484 - val_loss: 1.6081 - val_accuracy: 0.3624\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6514 - accuracy: 0.3424 - val_loss: 1.6062 - val_accuracy: 0.3725\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6361 - accuracy: 0.3743 - val_loss: 1.6022 - val_accuracy: 0.3758\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6735 - accuracy: 0.3402 - val_loss: 1.6020 - val_accuracy: 0.3658\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6611 - accuracy: 0.3692 - val_loss: 1.6004 - val_accuracy: 0.3893\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6393 - accuracy: 0.3744 - val_loss: 1.6033 - val_accuracy: 0.3859\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6762 - accuracy: 0.3480 - val_loss: 1.6014 - val_accuracy: 0.3926\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6666 - accuracy: 0.3527 - val_loss: 1.6015 - val_accuracy: 0.3624\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6277 - accuracy: 0.3549 - val_loss: 1.5932 - val_accuracy: 0.3926\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6539 - accuracy: 0.3751 - val_loss: 1.5917 - val_accuracy: 0.3893\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6600 - accuracy: 0.3529 - val_loss: 1.5908 - val_accuracy: 0.3826\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6551 - accuracy: 0.3657 - val_loss: 1.5878 - val_accuracy: 0.3926\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6579 - accuracy: 0.3622 - val_loss: 1.5852 - val_accuracy: 0.3792\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.6514 - accuracy: 0.3594 - val_loss: 1.5893 - val_accuracy: 0.3859\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6451 - accuracy: 0.3645 - val_loss: 1.5938 - val_accuracy: 0.3926\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6524 - accuracy: 0.3566 - val_loss: 1.5917 - val_accuracy: 0.3859\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6332 - accuracy: 0.3706 - val_loss: 1.5874 - val_accuracy: 0.3792\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6137 - accuracy: 0.3806 - val_loss: 1.5808 - val_accuracy: 0.3725\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6236 - accuracy: 0.3685 - val_loss: 1.5805 - val_accuracy: 0.3893\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6332 - accuracy: 0.3634 - val_loss: 1.5762 - val_accuracy: 0.3826\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5933 - accuracy: 0.3850 - val_loss: 1.5720 - val_accuracy: 0.4128\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6126 - accuracy: 0.3632 - val_loss: 1.5711 - val_accuracy: 0.4060\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6286 - accuracy: 0.3878 - val_loss: 1.5709 - val_accuracy: 0.3960\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6112 - accuracy: 0.3818 - val_loss: 1.5629 - val_accuracy: 0.3926\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6245 - accuracy: 0.3537 - val_loss: 1.5598 - val_accuracy: 0.3859\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6217 - accuracy: 0.3696 - val_loss: 1.5673 - val_accuracy: 0.4094\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5637 - accuracy: 0.4066 - val_loss: 1.5617 - val_accuracy: 0.3993\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5931 - accuracy: 0.3824 - val_loss: 1.5586 - val_accuracy: 0.3893\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6290 - accuracy: 0.3875 - val_loss: 1.5565 - val_accuracy: 0.3826\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5962 - accuracy: 0.4017 - val_loss: 1.5534 - val_accuracy: 0.3926\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6097 - accuracy: 0.3954 - val_loss: 1.5608 - val_accuracy: 0.4027\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5951 - accuracy: 0.3881 - val_loss: 1.5689 - val_accuracy: 0.3725\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5665 - accuracy: 0.4192 - val_loss: 1.5545 - val_accuracy: 0.3993\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6182 - accuracy: 0.3984 - val_loss: 1.5509 - val_accuracy: 0.4161\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5864 - accuracy: 0.3935 - val_loss: 1.5571 - val_accuracy: 0.4094\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6097 - accuracy: 0.4016 - val_loss: 1.5537 - val_accuracy: 0.4027\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5964 - accuracy: 0.4011 - val_loss: 1.5450 - val_accuracy: 0.4161\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6314 - accuracy: 0.3862 - val_loss: 1.5392 - val_accuracy: 0.4161\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6019 - accuracy: 0.3838 - val_loss: 1.5477 - val_accuracy: 0.4128\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.5685 - accuracy: 0.3950 - val_loss: 1.5388 - val_accuracy: 0.4262\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5786 - accuracy: 0.4102 - val_loss: 1.5325 - val_accuracy: 0.4161\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5807 - accuracy: 0.3928 - val_loss: 1.5301 - val_accuracy: 0.4094\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5678 - accuracy: 0.4134 - val_loss: 1.5205 - val_accuracy: 0.4195\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5721 - accuracy: 0.4170 - val_loss: 1.5239 - val_accuracy: 0.4161\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5861 - accuracy: 0.4043 - val_loss: 1.5263 - val_accuracy: 0.4161\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5538 - accuracy: 0.4084 - val_loss: 1.5284 - val_accuracy: 0.4128\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.5918 - accuracy: 0.3978 - val_loss: 1.5257 - val_accuracy: 0.4228\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5622 - accuracy: 0.4184 - val_loss: 1.5307 - val_accuracy: 0.4027\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5534 - accuracy: 0.3899 - val_loss: 1.5224 - val_accuracy: 0.4295\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.5424 - accuracy: 0.4321 - val_loss: 1.5170 - val_accuracy: 0.4195\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5527 - accuracy: 0.4072 - val_loss: 1.5140 - val_accuracy: 0.4228\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5627 - accuracy: 0.4148 - val_loss: 1.5165 - val_accuracy: 0.4430\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5682 - accuracy: 0.4071 - val_loss: 1.5305 - val_accuracy: 0.4128\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5549 - accuracy: 0.4123 - val_loss: 1.5351 - val_accuracy: 0.4430\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5653 - accuracy: 0.4143 - val_loss: 1.5197 - val_accuracy: 0.4295\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5472 - accuracy: 0.4326 - val_loss: 1.4960 - val_accuracy: 0.4463\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5454 - accuracy: 0.4293 - val_loss: 1.4978 - val_accuracy: 0.4396\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5143 - accuracy: 0.4362 - val_loss: 1.4946 - val_accuracy: 0.4463\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5561 - accuracy: 0.4091 - val_loss: 1.4962 - val_accuracy: 0.4497\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5266 - accuracy: 0.4418 - val_loss: 1.4949 - val_accuracy: 0.4430\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5368 - accuracy: 0.4181 - val_loss: 1.4900 - val_accuracy: 0.4530\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5509 - accuracy: 0.4177 - val_loss: 1.4815 - val_accuracy: 0.4497\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5571 - accuracy: 0.3936 - val_loss: 1.4860 - val_accuracy: 0.4497\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5418 - accuracy: 0.4507 - val_loss: 1.4940 - val_accuracy: 0.4329\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5186 - accuracy: 0.4392 - val_loss: 1.4870 - val_accuracy: 0.4497\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5231 - accuracy: 0.4311 - val_loss: 1.4760 - val_accuracy: 0.4228\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5185 - accuracy: 0.4378 - val_loss: 1.4723 - val_accuracy: 0.4396\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4925 - accuracy: 0.4546 - val_loss: 1.4761 - val_accuracy: 0.4564\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5010 - accuracy: 0.3978 - val_loss: 1.4737 - val_accuracy: 0.4597\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5134 - accuracy: 0.4309 - val_loss: 1.4700 - val_accuracy: 0.4396\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4846 - accuracy: 0.4552 - val_loss: 1.4789 - val_accuracy: 0.4631\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5211 - accuracy: 0.4206 - val_loss: 1.4712 - val_accuracy: 0.4329\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4832 - accuracy: 0.4420 - val_loss: 1.4697 - val_accuracy: 0.4396\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4909 - accuracy: 0.4594 - val_loss: 1.4663 - val_accuracy: 0.4631\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5092 - accuracy: 0.4321 - val_loss: 1.4595 - val_accuracy: 0.4597\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4629 - accuracy: 0.4847 - val_loss: 1.4569 - val_accuracy: 0.4564\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4894 - accuracy: 0.4623 - val_loss: 1.4545 - val_accuracy: 0.4497\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4452 - accuracy: 0.4682 - val_loss: 1.4500 - val_accuracy: 0.4698\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4517 - accuracy: 0.4596 - val_loss: 1.4490 - val_accuracy: 0.4564\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4619 - accuracy: 0.4442 - val_loss: 1.4425 - val_accuracy: 0.4664\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4829 - accuracy: 0.4519 - val_loss: 1.4523 - val_accuracy: 0.4497\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4488 - accuracy: 0.4543 - val_loss: 1.4602 - val_accuracy: 0.4597\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4740 - accuracy: 0.4285 - val_loss: 1.4510 - val_accuracy: 0.4664\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4548 - accuracy: 0.4564 - val_loss: 1.4391 - val_accuracy: 0.4530\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4805 - accuracy: 0.4566 - val_loss: 1.4379 - val_accuracy: 0.4463\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4797 - accuracy: 0.4594 - val_loss: 1.4290 - val_accuracy: 0.4564\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4910 - accuracy: 0.4405 - val_loss: 1.4309 - val_accuracy: 0.4732\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4478 - accuracy: 0.4710 - val_loss: 1.4339 - val_accuracy: 0.4664\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4652 - accuracy: 0.4597 - val_loss: 1.4412 - val_accuracy: 0.4530\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3924 - accuracy: 0.4652 - val_loss: 1.4321 - val_accuracy: 0.4698\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4532 - accuracy: 0.4638 - val_loss: 1.4192 - val_accuracy: 0.4664\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4408 - accuracy: 0.4532 - val_loss: 1.4092 - val_accuracy: 0.4866\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4349 - accuracy: 0.4740 - val_loss: 1.4137 - val_accuracy: 0.4664\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4317 - accuracy: 0.4561 - val_loss: 1.4214 - val_accuracy: 0.4564\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4420 - accuracy: 0.4633 - val_loss: 1.4202 - val_accuracy: 0.4698\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4556 - accuracy: 0.4522 - val_loss: 1.4096 - val_accuracy: 0.4564\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4863 - accuracy: 0.4375 - val_loss: 1.4110 - val_accuracy: 0.4698\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4402 - accuracy: 0.4559 - val_loss: 1.4072 - val_accuracy: 0.4564\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4117 - accuracy: 0.4818 - val_loss: 1.4072 - val_accuracy: 0.4765\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4097 - accuracy: 0.4704 - val_loss: 1.4136 - val_accuracy: 0.4597\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4138 - accuracy: 0.4761 - val_loss: 1.4217 - val_accuracy: 0.4832\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4205 - accuracy: 0.4798 - val_loss: 1.4147 - val_accuracy: 0.4564\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4476 - accuracy: 0.4676 - val_loss: 1.3994 - val_accuracy: 0.4832\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4206 - accuracy: 0.4761 - val_loss: 1.3931 - val_accuracy: 0.4664\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4553 - accuracy: 0.4832 - val_loss: 1.3935 - val_accuracy: 0.4564\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4139 - accuracy: 0.4673 - val_loss: 1.3957 - val_accuracy: 0.4631\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3988 - accuracy: 0.5008 - val_loss: 1.3963 - val_accuracy: 0.4765\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4037 - accuracy: 0.4855 - val_loss: 1.3957 - val_accuracy: 0.4799\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4123 - accuracy: 0.4737 - val_loss: 1.3998 - val_accuracy: 0.4765\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4125 - accuracy: 0.4797 - val_loss: 1.3963 - val_accuracy: 0.4832\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3598 - accuracy: 0.5047 - val_loss: 1.3907 - val_accuracy: 0.4899\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3755 - accuracy: 0.4905 - val_loss: 1.3919 - val_accuracy: 0.4899\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4173 - accuracy: 0.4551 - val_loss: 1.3970 - val_accuracy: 0.4664\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.3958 - accuracy: 0.4917 - val_loss: 1.3993 - val_accuracy: 0.4899\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3832 - accuracy: 0.4949 - val_loss: 1.4003 - val_accuracy: 0.4732\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3797 - accuracy: 0.5031 - val_loss: 1.3965 - val_accuracy: 0.4933\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3845 - accuracy: 0.4912 - val_loss: 1.3906 - val_accuracy: 0.4597\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3674 - accuracy: 0.5003 - val_loss: 1.3873 - val_accuracy: 0.5000\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4168 - accuracy: 0.4593 - val_loss: 1.3787 - val_accuracy: 0.4732\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3511 - accuracy: 0.5234 - val_loss: 1.3723 - val_accuracy: 0.5000\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4166 - accuracy: 0.4789 - val_loss: 1.3773 - val_accuracy: 0.5101\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3739 - accuracy: 0.5097 - val_loss: 1.3730 - val_accuracy: 0.4664\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3855 - accuracy: 0.4762 - val_loss: 1.3555 - val_accuracy: 0.5067\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3817 - accuracy: 0.5244 - val_loss: 1.3537 - val_accuracy: 0.4832\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3604 - accuracy: 0.5083 - val_loss: 1.3591 - val_accuracy: 0.5034\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3686 - accuracy: 0.4976 - val_loss: 1.3603 - val_accuracy: 0.4933\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3709 - accuracy: 0.4835 - val_loss: 1.3606 - val_accuracy: 0.4832\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3507 - accuracy: 0.4989 - val_loss: 1.3528 - val_accuracy: 0.4765\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3453 - accuracy: 0.4989 - val_loss: 1.3467 - val_accuracy: 0.5000\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3620 - accuracy: 0.4942 - val_loss: 1.3447 - val_accuracy: 0.4966\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3666 - accuracy: 0.4931 - val_loss: 1.3476 - val_accuracy: 0.5034\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3228 - accuracy: 0.5334 - val_loss: 1.3465 - val_accuracy: 0.5034\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3435 - accuracy: 0.5039 - val_loss: 1.3444 - val_accuracy: 0.5000\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3343 - accuracy: 0.5295 - val_loss: 1.3450 - val_accuracy: 0.4933\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3121 - accuracy: 0.5227 - val_loss: 1.3361 - val_accuracy: 0.4899\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3221 - accuracy: 0.5150 - val_loss: 1.3338 - val_accuracy: 0.4933\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.3279 - accuracy: 0.5033 - val_loss: 1.3345 - val_accuracy: 0.4966\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3419 - accuracy: 0.4978 - val_loss: 1.3342 - val_accuracy: 0.5034\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3071 - accuracy: 0.5251 - val_loss: 1.3423 - val_accuracy: 0.5101\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3122 - accuracy: 0.5261 - val_loss: 1.3426 - val_accuracy: 0.5168\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2878 - accuracy: 0.5229 - val_loss: 1.3489 - val_accuracy: 0.4899\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3178 - accuracy: 0.5288 - val_loss: 1.3424 - val_accuracy: 0.5302\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3077 - accuracy: 0.5231 - val_loss: 1.3268 - val_accuracy: 0.5201\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2943 - accuracy: 0.5270 - val_loss: 1.3239 - val_accuracy: 0.5168\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2985 - accuracy: 0.5268 - val_loss: 1.3211 - val_accuracy: 0.5302\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2967 - accuracy: 0.5239 - val_loss: 1.3206 - val_accuracy: 0.4866\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2541 - accuracy: 0.5666 - val_loss: 1.2992 - val_accuracy: 0.5235\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3229 - accuracy: 0.5092 - val_loss: 1.3095 - val_accuracy: 0.5134\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3237 - accuracy: 0.5213 - val_loss: 1.3281 - val_accuracy: 0.5134\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2906 - accuracy: 0.5346 - val_loss: 1.3186 - val_accuracy: 0.5268\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3003 - accuracy: 0.5376 - val_loss: 1.3079 - val_accuracy: 0.5168\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2813 - accuracy: 0.5339 - val_loss: 1.2949 - val_accuracy: 0.5201\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3045 - accuracy: 0.5170 - val_loss: 1.3029 - val_accuracy: 0.4933\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3066 - accuracy: 0.5176 - val_loss: 1.3078 - val_accuracy: 0.5168\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3154 - accuracy: 0.5180 - val_loss: 1.3260 - val_accuracy: 0.4933\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2666 - accuracy: 0.5452 - val_loss: 1.3183 - val_accuracy: 0.5034\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2989 - accuracy: 0.5225 - val_loss: 1.3083 - val_accuracy: 0.5302\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2712 - accuracy: 0.5321 - val_loss: 1.2995 - val_accuracy: 0.5134\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2787 - accuracy: 0.5192 - val_loss: 1.2918 - val_accuracy: 0.5235\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2681 - accuracy: 0.5370 - val_loss: 1.2915 - val_accuracy: 0.5034\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3289 - accuracy: 0.5165 - val_loss: 1.2840 - val_accuracy: 0.5201\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2346 - accuracy: 0.5569 - val_loss: 1.2844 - val_accuracy: 0.5201\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2740 - accuracy: 0.5285 - val_loss: 1.3086 - val_accuracy: 0.5000\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2754 - accuracy: 0.5261 - val_loss: 1.2962 - val_accuracy: 0.5235\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2403 - accuracy: 0.5604 - val_loss: 1.2789 - val_accuracy: 0.5336\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2752 - accuracy: 0.5327 - val_loss: 1.2669 - val_accuracy: 0.5235\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2545 - accuracy: 0.5482 - val_loss: 1.2737 - val_accuracy: 0.5101\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2528 - accuracy: 0.5354 - val_loss: 1.2813 - val_accuracy: 0.5235\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2281 - accuracy: 0.5451 - val_loss: 1.2877 - val_accuracy: 0.5168\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2742 - accuracy: 0.5462 - val_loss: 1.2909 - val_accuracy: 0.5268\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2483 - accuracy: 0.5405 - val_loss: 1.2851 - val_accuracy: 0.5201\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2183 - accuracy: 0.5485 - val_loss: 1.2756 - val_accuracy: 0.5302\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2414 - accuracy: 0.5487 - val_loss: 1.2862 - val_accuracy: 0.5302\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2172 - accuracy: 0.5552 - val_loss: 1.2768 - val_accuracy: 0.5336\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2322 - accuracy: 0.5550 - val_loss: 1.2751 - val_accuracy: 0.5268\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2155 - accuracy: 0.5428 - val_loss: 1.2832 - val_accuracy: 0.5403\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1801 - accuracy: 0.5677 - val_loss: 1.2850 - val_accuracy: 0.5235\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1997 - accuracy: 0.5743 - val_loss: 1.2711 - val_accuracy: 0.5302\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2598 - accuracy: 0.5321 - val_loss: 1.2586 - val_accuracy: 0.5268\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2547 - accuracy: 0.5509 - val_loss: 1.2501 - val_accuracy: 0.5268\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2303 - accuracy: 0.5495 - val_loss: 1.2571 - val_accuracy: 0.5302\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1842 - accuracy: 0.5764 - val_loss: 1.2649 - val_accuracy: 0.5436\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2123 - accuracy: 0.5438 - val_loss: 1.2743 - val_accuracy: 0.5101\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2083 - accuracy: 0.5506 - val_loss: 1.2661 - val_accuracy: 0.5470\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1567 - accuracy: 0.5861 - val_loss: 1.2579 - val_accuracy: 0.5369\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1957 - accuracy: 0.5515 - val_loss: 1.2442 - val_accuracy: 0.5503\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1946 - accuracy: 0.5902 - val_loss: 1.2390 - val_accuracy: 0.5403\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2014 - accuracy: 0.5768 - val_loss: 1.2495 - val_accuracy: 0.5369\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1700 - accuracy: 0.5713 - val_loss: 1.2658 - val_accuracy: 0.5336\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2565 - accuracy: 0.5363 - val_loss: 1.2623 - val_accuracy: 0.5369\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1866 - accuracy: 0.5723 - val_loss: 1.2594 - val_accuracy: 0.5403\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1854 - accuracy: 0.5585 - val_loss: 1.2537 - val_accuracy: 0.5470\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1782 - accuracy: 0.5774 - val_loss: 1.2597 - val_accuracy: 0.5436\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1845 - accuracy: 0.5689 - val_loss: 1.2529 - val_accuracy: 0.5436\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1607 - accuracy: 0.5553 - val_loss: 1.2401 - val_accuracy: 0.5604\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2215 - accuracy: 0.5583 - val_loss: 1.2326 - val_accuracy: 0.5336\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1461 - accuracy: 0.5873 - val_loss: 1.2323 - val_accuracy: 0.5403\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1485 - accuracy: 0.5806 - val_loss: 1.2342 - val_accuracy: 0.5436\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1485 - accuracy: 0.5708 - val_loss: 1.2206 - val_accuracy: 0.5436\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1607 - accuracy: 0.5819 - val_loss: 1.2204 - val_accuracy: 0.5369\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1371 - accuracy: 0.5980 - val_loss: 1.2218 - val_accuracy: 0.5470\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1966 - accuracy: 0.5472 - val_loss: 1.2234 - val_accuracy: 0.5503\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1902 - accuracy: 0.5611 - val_loss: 1.2323 - val_accuracy: 0.5537\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1630 - accuracy: 0.5816 - val_loss: 1.2292 - val_accuracy: 0.5436\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1802 - accuracy: 0.5891 - val_loss: 1.2344 - val_accuracy: 0.5570\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1730 - accuracy: 0.5811 - val_loss: 1.2176 - val_accuracy: 0.5638\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1832 - accuracy: 0.5735 - val_loss: 1.2042 - val_accuracy: 0.5470\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1299 - accuracy: 0.5768 - val_loss: 1.2035 - val_accuracy: 0.5470\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1486 - accuracy: 0.5795 - val_loss: 1.2182 - val_accuracy: 0.5403\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1685 - accuracy: 0.5715 - val_loss: 1.2234 - val_accuracy: 0.5671\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1338 - accuracy: 0.5860 - val_loss: 1.2277 - val_accuracy: 0.5604\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1173 - accuracy: 0.5871 - val_loss: 1.2499 - val_accuracy: 0.5302\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1355 - accuracy: 0.5849 - val_loss: 1.2137 - val_accuracy: 0.5638\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1549 - accuracy: 0.5787 - val_loss: 1.2130 - val_accuracy: 0.5436\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1553 - accuracy: 0.5787 - val_loss: 1.2216 - val_accuracy: 0.5436\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1247 - accuracy: 0.5776 - val_loss: 1.2205 - val_accuracy: 0.5537\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1194 - accuracy: 0.5958 - val_loss: 1.2191 - val_accuracy: 0.5503\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1215 - accuracy: 0.6119 - val_loss: 1.2183 - val_accuracy: 0.5604\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1402 - accuracy: 0.5844 - val_loss: 1.2264 - val_accuracy: 0.5403\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1410 - accuracy: 0.5915 - val_loss: 1.2073 - val_accuracy: 0.5537\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1438 - accuracy: 0.5815 - val_loss: 1.2107 - val_accuracy: 0.5537\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1227 - accuracy: 0.5933 - val_loss: 1.2051 - val_accuracy: 0.5403\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1302 - accuracy: 0.5830 - val_loss: 1.2013 - val_accuracy: 0.5503\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1016 - accuracy: 0.6107 - val_loss: 1.1887 - val_accuracy: 0.5604\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1067 - accuracy: 0.5925 - val_loss: 1.1878 - val_accuracy: 0.5503\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1038 - accuracy: 0.5813 - val_loss: 1.2014 - val_accuracy: 0.5403\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0963 - accuracy: 0.6043 - val_loss: 1.2011 - val_accuracy: 0.5671\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1502 - accuracy: 0.5776 - val_loss: 1.1834 - val_accuracy: 0.5638\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1387 - accuracy: 0.5941 - val_loss: 1.1662 - val_accuracy: 0.5738\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1288 - accuracy: 0.5864 - val_loss: 1.1980 - val_accuracy: 0.5604\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1104 - accuracy: 0.6110 - val_loss: 1.2037 - val_accuracy: 0.5570\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1037 - accuracy: 0.5891 - val_loss: 1.2063 - val_accuracy: 0.5537\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0923 - accuracy: 0.5945 - val_loss: 1.2173 - val_accuracy: 0.5470\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1277 - accuracy: 0.6071 - val_loss: 1.1942 - val_accuracy: 0.5705\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0675 - accuracy: 0.6004 - val_loss: 1.1871 - val_accuracy: 0.5604\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1258 - accuracy: 0.5764 - val_loss: 1.1810 - val_accuracy: 0.5403\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0392 - accuracy: 0.6345 - val_loss: 1.1781 - val_accuracy: 0.5570\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0840 - accuracy: 0.5935 - val_loss: 1.1909 - val_accuracy: 0.5738\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0812 - accuracy: 0.5919 - val_loss: 1.1895 - val_accuracy: 0.5570\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0681 - accuracy: 0.6011 - val_loss: 1.1749 - val_accuracy: 0.5570\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0907 - accuracy: 0.5971 - val_loss: 1.1869 - val_accuracy: 0.5436\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0571 - accuracy: 0.6133 - val_loss: 1.1881 - val_accuracy: 0.5436\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0728 - accuracy: 0.6066 - val_loss: 1.1977 - val_accuracy: 0.5436\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0729 - accuracy: 0.6240 - val_loss: 1.1904 - val_accuracy: 0.5638\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0715 - accuracy: 0.6222 - val_loss: 1.1714 - val_accuracy: 0.5604\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0741 - accuracy: 0.5935 - val_loss: 1.1698 - val_accuracy: 0.5671\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0463 - accuracy: 0.6188 - val_loss: 1.1819 - val_accuracy: 0.5872\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0357 - accuracy: 0.6348 - val_loss: 1.1905 - val_accuracy: 0.5671\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0404 - accuracy: 0.6344 - val_loss: 1.2002 - val_accuracy: 0.5537\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0580 - accuracy: 0.5972 - val_loss: 1.1833 - val_accuracy: 0.5570\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0555 - accuracy: 0.6151 - val_loss: 1.1712 - val_accuracy: 0.5738\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0382 - accuracy: 0.6196 - val_loss: 1.1785 - val_accuracy: 0.5772\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0372 - accuracy: 0.6414 - val_loss: 1.1896 - val_accuracy: 0.5638\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0170 - accuracy: 0.6326 - val_loss: 1.1655 - val_accuracy: 0.5705\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0438 - accuracy: 0.6379 - val_loss: 1.1628 - val_accuracy: 0.5570\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0632 - accuracy: 0.6327 - val_loss: 1.1673 - val_accuracy: 0.5705\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0540 - accuracy: 0.6223 - val_loss: 1.1744 - val_accuracy: 0.5570\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0482 - accuracy: 0.6143 - val_loss: 1.1725 - val_accuracy: 0.5570\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0135 - accuracy: 0.6319 - val_loss: 1.1784 - val_accuracy: 0.5503\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0450 - accuracy: 0.6223 - val_loss: 1.1705 - val_accuracy: 0.5738\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0236 - accuracy: 0.6301 - val_loss: 1.1601 - val_accuracy: 0.5872\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0095 - accuracy: 0.6382 - val_loss: 1.1602 - val_accuracy: 0.5570\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0331 - accuracy: 0.6407 - val_loss: 1.1518 - val_accuracy: 0.5872\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0383 - accuracy: 0.6220 - val_loss: 1.1460 - val_accuracy: 0.5705\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0088 - accuracy: 0.6554 - val_loss: 1.1412 - val_accuracy: 0.5805\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0750 - accuracy: 0.6149 - val_loss: 1.1391 - val_accuracy: 0.5671\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9933 - accuracy: 0.6281 - val_loss: 1.1380 - val_accuracy: 0.5772\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9861 - accuracy: 0.6451 - val_loss: 1.1434 - val_accuracy: 0.5705\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0170 - accuracy: 0.6205 - val_loss: 1.1475 - val_accuracy: 0.5671\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0170 - accuracy: 0.6298 - val_loss: 1.1390 - val_accuracy: 0.5671\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0274 - accuracy: 0.6182 - val_loss: 1.1368 - val_accuracy: 0.5705\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0185 - accuracy: 0.6330 - val_loss: 1.1242 - val_accuracy: 0.5872\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0234 - accuracy: 0.6373 - val_loss: 1.1399 - val_accuracy: 0.5738\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9802 - accuracy: 0.6555 - val_loss: 1.1383 - val_accuracy: 0.5738\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9951 - accuracy: 0.6474 - val_loss: 1.1527 - val_accuracy: 0.5738\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9868 - accuracy: 0.6423 - val_loss: 1.1466 - val_accuracy: 0.5872\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0141 - accuracy: 0.6225 - val_loss: 1.1302 - val_accuracy: 0.5973\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0221 - accuracy: 0.6335 - val_loss: 1.1367 - val_accuracy: 0.5772\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9952 - accuracy: 0.6287 - val_loss: 1.1349 - val_accuracy: 0.5805\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0015 - accuracy: 0.6374 - val_loss: 1.1492 - val_accuracy: 0.5738\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9776 - accuracy: 0.6373 - val_loss: 1.1176 - val_accuracy: 0.6007\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0069 - accuracy: 0.6325 - val_loss: 1.1168 - val_accuracy: 0.5839\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9946 - accuracy: 0.6300 - val_loss: 1.1263 - val_accuracy: 0.5805\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9798 - accuracy: 0.6447 - val_loss: 1.1352 - val_accuracy: 0.5839\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0212 - accuracy: 0.6291 - val_loss: 1.1150 - val_accuracy: 0.5872\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0062 - accuracy: 0.6283 - val_loss: 1.1068 - val_accuracy: 0.5805\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9879 - accuracy: 0.6390 - val_loss: 1.1143 - val_accuracy: 0.5872\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9517 - accuracy: 0.6603 - val_loss: 1.1281 - val_accuracy: 0.5872\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9495 - accuracy: 0.6648 - val_loss: 1.1477 - val_accuracy: 0.5872\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.9703 - accuracy: 0.6483 - val_loss: 1.1520 - val_accuracy: 0.5940\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9650 - accuracy: 0.6528 - val_loss: 1.1339 - val_accuracy: 0.5872\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9815 - accuracy: 0.6399 - val_loss: 1.1338 - val_accuracy: 0.5839\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9736 - accuracy: 0.6455 - val_loss: 1.1262 - val_accuracy: 0.6107\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9911 - accuracy: 0.6537 - val_loss: 1.1444 - val_accuracy: 0.5839\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9689 - accuracy: 0.6349 - val_loss: 1.1037 - val_accuracy: 0.6007\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9475 - accuracy: 0.6373 - val_loss: 1.0986 - val_accuracy: 0.5973\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9337 - accuracy: 0.6666 - val_loss: 1.0974 - val_accuracy: 0.6007\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9145 - accuracy: 0.6748 - val_loss: 1.1220 - val_accuracy: 0.5839\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9660 - accuracy: 0.6519 - val_loss: 1.1447 - val_accuracy: 0.5772\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9366 - accuracy: 0.6723 - val_loss: 1.1231 - val_accuracy: 0.5973\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9346 - accuracy: 0.6738 - val_loss: 1.1268 - val_accuracy: 0.5906\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9533 - accuracy: 0.6623 - val_loss: 1.1166 - val_accuracy: 0.6074\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.9294 - accuracy: 0.6727 - val_loss: 1.1026 - val_accuracy: 0.6007\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8956 - accuracy: 0.6841 - val_loss: 1.1220 - val_accuracy: 0.5973\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.9010 - accuracy: 0.6660 - val_loss: 1.1078 - val_accuracy: 0.6074\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9286 - accuracy: 0.6549 - val_loss: 1.0937 - val_accuracy: 0.6107\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9031 - accuracy: 0.6793 - val_loss: 1.0925 - val_accuracy: 0.6040\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9343 - accuracy: 0.6778 - val_loss: 1.1338 - val_accuracy: 0.6007\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9620 - accuracy: 0.6482 - val_loss: 1.1470 - val_accuracy: 0.5872\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9324 - accuracy: 0.6750 - val_loss: 1.1206 - val_accuracy: 0.5906\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9237 - accuracy: 0.6509 - val_loss: 1.1044 - val_accuracy: 0.6007\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9365 - accuracy: 0.6582 - val_loss: 1.0988 - val_accuracy: 0.5872\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9824 - accuracy: 0.6411 - val_loss: 1.1453 - val_accuracy: 0.5705\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9140 - accuracy: 0.6792 - val_loss: 1.1347 - val_accuracy: 0.6074\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8833 - accuracy: 0.6772 - val_loss: 1.1328 - val_accuracy: 0.6074\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9266 - accuracy: 0.6573 - val_loss: 1.1188 - val_accuracy: 0.6007\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9526 - accuracy: 0.6613 - val_loss: 1.1233 - val_accuracy: 0.6007\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8975 - accuracy: 0.6715 - val_loss: 1.1095 - val_accuracy: 0.6040\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8981 - accuracy: 0.6752 - val_loss: 1.1022 - val_accuracy: 0.5973\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8930 - accuracy: 0.6646 - val_loss: 1.1002 - val_accuracy: 0.6040\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9014 - accuracy: 0.6635 - val_loss: 1.0868 - val_accuracy: 0.6107\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8680 - accuracy: 0.6955 - val_loss: 1.0800 - val_accuracy: 0.6074\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9234 - accuracy: 0.6619 - val_loss: 1.0737 - val_accuracy: 0.6040\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9132 - accuracy: 0.6573 - val_loss: 1.0781 - val_accuracy: 0.5839\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9053 - accuracy: 0.6805 - val_loss: 1.0688 - val_accuracy: 0.6007\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8804 - accuracy: 0.6749 - val_loss: 1.0861 - val_accuracy: 0.6174\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9081 - accuracy: 0.6778 - val_loss: 1.0968 - val_accuracy: 0.6040\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8680 - accuracy: 0.6792 - val_loss: 1.0885 - val_accuracy: 0.6074\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8635 - accuracy: 0.6822 - val_loss: 1.0896 - val_accuracy: 0.6040\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8812 - accuracy: 0.6604 - val_loss: 1.0880 - val_accuracy: 0.6007\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8587 - accuracy: 0.6877 - val_loss: 1.0712 - val_accuracy: 0.6174\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8999 - accuracy: 0.6816 - val_loss: 1.0813 - val_accuracy: 0.6208\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8715 - accuracy: 0.6894 - val_loss: 1.1001 - val_accuracy: 0.6040\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8635 - accuracy: 0.6903 - val_loss: 1.0937 - val_accuracy: 0.6107\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8916 - accuracy: 0.6793 - val_loss: 1.0761 - val_accuracy: 0.6107\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9226 - accuracy: 0.6705 - val_loss: 1.0438 - val_accuracy: 0.6141\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9002 - accuracy: 0.6784 - val_loss: 1.0544 - val_accuracy: 0.6275\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8153 - accuracy: 0.7009 - val_loss: 1.0592 - val_accuracy: 0.6174\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8269 - accuracy: 0.6968 - val_loss: 1.0625 - val_accuracy: 0.6141\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8673 - accuracy: 0.6964 - val_loss: 1.0364 - val_accuracy: 0.6443\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8410 - accuracy: 0.6973 - val_loss: 1.0483 - val_accuracy: 0.6342\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8420 - accuracy: 0.6924 - val_loss: 1.0460 - val_accuracy: 0.6141\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8731 - accuracy: 0.6838 - val_loss: 1.0500 - val_accuracy: 0.6074\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8468 - accuracy: 0.6947 - val_loss: 1.0552 - val_accuracy: 0.6007\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8377 - accuracy: 0.7173 - val_loss: 1.0790 - val_accuracy: 0.6107\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8112 - accuracy: 0.7062 - val_loss: 1.0807 - val_accuracy: 0.6074\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8290 - accuracy: 0.6927 - val_loss: 1.0647 - val_accuracy: 0.6074\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8719 - accuracy: 0.6750 - val_loss: 1.0669 - val_accuracy: 0.6275\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8256 - accuracy: 0.7257 - val_loss: 1.0493 - val_accuracy: 0.6275\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8575 - accuracy: 0.6891 - val_loss: 1.0667 - val_accuracy: 0.6074\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8521 - accuracy: 0.6840 - val_loss: 1.0617 - val_accuracy: 0.6242\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8754 - accuracy: 0.6844 - val_loss: 1.0491 - val_accuracy: 0.6074\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8422 - accuracy: 0.6836 - val_loss: 1.0521 - val_accuracy: 0.6208\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7929 - accuracy: 0.7205 - val_loss: 1.0198 - val_accuracy: 0.6443\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8329 - accuracy: 0.6900 - val_loss: 1.0180 - val_accuracy: 0.6443\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9004 - accuracy: 0.6861 - val_loss: 1.0277 - val_accuracy: 0.6174\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8207 - accuracy: 0.6958 - val_loss: 1.0383 - val_accuracy: 0.6376\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8411 - accuracy: 0.6985 - val_loss: 1.0323 - val_accuracy: 0.6208\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8615 - accuracy: 0.7064 - val_loss: 1.0221 - val_accuracy: 0.6275\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8346 - accuracy: 0.7077 - val_loss: 1.0258 - val_accuracy: 0.6510\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8057 - accuracy: 0.7103 - val_loss: 1.0214 - val_accuracy: 0.6376\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8289 - accuracy: 0.7007 - val_loss: 1.0339 - val_accuracy: 0.6443\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7981 - accuracy: 0.7079 - val_loss: 1.0542 - val_accuracy: 0.6342\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8423 - accuracy: 0.6852 - val_loss: 1.0355 - val_accuracy: 0.6443\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8437 - accuracy: 0.6884 - val_loss: 1.0357 - val_accuracy: 0.6477\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8235 - accuracy: 0.6953 - val_loss: 1.0134 - val_accuracy: 0.6275\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8144 - accuracy: 0.7115 - val_loss: 1.0187 - val_accuracy: 0.6376\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7692 - accuracy: 0.7198 - val_loss: 1.0340 - val_accuracy: 0.6208\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8061 - accuracy: 0.7032 - val_loss: 1.0530 - val_accuracy: 0.6174\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8145 - accuracy: 0.7145 - val_loss: 1.0447 - val_accuracy: 0.6275\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7996 - accuracy: 0.7152 - val_loss: 1.0510 - val_accuracy: 0.6376\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7866 - accuracy: 0.7304 - val_loss: 1.0671 - val_accuracy: 0.6309\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7940 - accuracy: 0.7177 - val_loss: 1.0669 - val_accuracy: 0.6342\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7849 - accuracy: 0.7042 - val_loss: 1.0619 - val_accuracy: 0.6443\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7630 - accuracy: 0.7365 - val_loss: 1.0533 - val_accuracy: 0.6544\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8119 - accuracy: 0.7129 - val_loss: 1.0700 - val_accuracy: 0.6443\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7861 - accuracy: 0.7084 - val_loss: 1.0565 - val_accuracy: 0.6409\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7777 - accuracy: 0.7199 - val_loss: 1.0590 - val_accuracy: 0.6376\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7820 - accuracy: 0.7254 - val_loss: 1.0643 - val_accuracy: 0.6174\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8326 - accuracy: 0.6899 - val_loss: 1.0631 - val_accuracy: 0.6208\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7886 - accuracy: 0.7205 - val_loss: 1.0350 - val_accuracy: 0.6309\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.7185 - val_loss: 1.0225 - val_accuracy: 0.6242\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7526 - accuracy: 0.7348 - val_loss: 1.0364 - val_accuracy: 0.6510\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7921 - accuracy: 0.7253 - val_loss: 1.0423 - val_accuracy: 0.6510\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7880 - accuracy: 0.7088 - val_loss: 1.0587 - val_accuracy: 0.6409\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7839 - accuracy: 0.7163 - val_loss: 1.0551 - val_accuracy: 0.6242\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7853 - accuracy: 0.7313 - val_loss: 1.0483 - val_accuracy: 0.6443\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7741 - accuracy: 0.6938 - val_loss: 1.0293 - val_accuracy: 0.6242\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7754 - accuracy: 0.7347 - val_loss: 1.0263 - val_accuracy: 0.6208\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7818 - accuracy: 0.7111 - val_loss: 1.0126 - val_accuracy: 0.6510\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7589 - accuracy: 0.7241 - val_loss: 1.0045 - val_accuracy: 0.6544\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7297 - accuracy: 0.7465 - val_loss: 0.9996 - val_accuracy: 0.6577\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7170 - val_loss: 1.0196 - val_accuracy: 0.6477\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7535 - accuracy: 0.7300 - val_loss: 1.0285 - val_accuracy: 0.6342\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7613 - accuracy: 0.7237 - val_loss: 1.0247 - val_accuracy: 0.6376\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7798 - accuracy: 0.7045 - val_loss: 1.0462 - val_accuracy: 0.6477\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7562 - accuracy: 0.7240 - val_loss: 1.0188 - val_accuracy: 0.6510\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7622 - accuracy: 0.7352 - val_loss: 1.0103 - val_accuracy: 0.6644\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7029 - accuracy: 0.7501 - val_loss: 1.0399 - val_accuracy: 0.6477\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7393 - accuracy: 0.7213 - val_loss: 1.0449 - val_accuracy: 0.6510\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7286 - accuracy: 0.7452 - val_loss: 1.0482 - val_accuracy: 0.6275\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7241 - accuracy: 0.7403 - val_loss: 1.0228 - val_accuracy: 0.6443\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7464 - accuracy: 0.7321 - val_loss: 1.0277 - val_accuracy: 0.6208\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7657 - accuracy: 0.7273 - val_loss: 1.0098 - val_accuracy: 0.6342\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7085 - accuracy: 0.7439 - val_loss: 1.0217 - val_accuracy: 0.6309\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7015 - accuracy: 0.7251 - val_loss: 1.0055 - val_accuracy: 0.6376\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7407 - accuracy: 0.7260 - val_loss: 1.0017 - val_accuracy: 0.6477\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7448 - accuracy: 0.7428 - val_loss: 1.0100 - val_accuracy: 0.6342\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7620 - accuracy: 0.7167 - val_loss: 1.0117 - val_accuracy: 0.6409\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7690 - accuracy: 0.7280 - val_loss: 1.0220 - val_accuracy: 0.6342\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7472 - accuracy: 0.7371 - val_loss: 1.0172 - val_accuracy: 0.6510\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6979 - accuracy: 0.7516 - val_loss: 1.0331 - val_accuracy: 0.6544\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6832 - accuracy: 0.7547 - val_loss: 1.0431 - val_accuracy: 0.6611\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7018 - accuracy: 0.7476 - val_loss: 1.0188 - val_accuracy: 0.6745\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7032 - accuracy: 0.7415 - val_loss: 1.0071 - val_accuracy: 0.6409\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7303 - accuracy: 0.7409 - val_loss: 1.0213 - val_accuracy: 0.6309\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7033 - accuracy: 0.7457 - val_loss: 1.0326 - val_accuracy: 0.6477\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7294 - accuracy: 0.7329 - val_loss: 1.0311 - val_accuracy: 0.6510\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7188 - accuracy: 0.7539 - val_loss: 1.0224 - val_accuracy: 0.6477\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6980 - accuracy: 0.7307 - val_loss: 1.0041 - val_accuracy: 0.6510\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6970 - accuracy: 0.7184 - val_loss: 1.0025 - val_accuracy: 0.6544\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7375 - accuracy: 0.7312 - val_loss: 1.0109 - val_accuracy: 0.6611\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6916 - accuracy: 0.7438 - val_loss: 1.0192 - val_accuracy: 0.6611\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7092 - accuracy: 0.7455 - val_loss: 1.0256 - val_accuracy: 0.6477\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6718 - accuracy: 0.7626 - val_loss: 0.9990 - val_accuracy: 0.6577\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6681 - accuracy: 0.7649 - val_loss: 1.0091 - val_accuracy: 0.6443\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7045 - accuracy: 0.7656 - val_loss: 0.9912 - val_accuracy: 0.6678\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7135 - accuracy: 0.7368 - val_loss: 0.9956 - val_accuracy: 0.6678\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6893 - accuracy: 0.7358 - val_loss: 1.0353 - val_accuracy: 0.6376\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6806 - accuracy: 0.7464 - val_loss: 1.0183 - val_accuracy: 0.6477\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6998 - accuracy: 0.7575 - val_loss: 1.0531 - val_accuracy: 0.6544\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6952 - accuracy: 0.7463 - val_loss: 1.0614 - val_accuracy: 0.6644\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7018 - accuracy: 0.7412 - val_loss: 1.0662 - val_accuracy: 0.6611\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7033 - accuracy: 0.7459 - val_loss: 1.0473 - val_accuracy: 0.6611\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7240 - accuracy: 0.7454 - val_loss: 0.9816 - val_accuracy: 0.6577\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6504 - accuracy: 0.7897 - val_loss: 0.9823 - val_accuracy: 0.6510\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6411 - accuracy: 0.7599 - val_loss: 0.9940 - val_accuracy: 0.6644\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6771 - accuracy: 0.7687 - val_loss: 0.9925 - val_accuracy: 0.6611\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6597 - accuracy: 0.7590 - val_loss: 0.9955 - val_accuracy: 0.6611\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6517 - accuracy: 0.7669 - val_loss: 0.9944 - val_accuracy: 0.6443\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6817 - accuracy: 0.7422 - val_loss: 1.0257 - val_accuracy: 0.6376\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6213 - accuracy: 0.7722 - val_loss: 1.0287 - val_accuracy: 0.6443\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6148 - accuracy: 0.7702 - val_loss: 0.9980 - val_accuracy: 0.6779\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6597 - accuracy: 0.7687 - val_loss: 0.9904 - val_accuracy: 0.6644\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6782 - accuracy: 0.7498 - val_loss: 0.9846 - val_accuracy: 0.6544\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.7830 - val_loss: 0.9806 - val_accuracy: 0.6711\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6695 - accuracy: 0.7767 - val_loss: 1.0015 - val_accuracy: 0.6611\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6764 - accuracy: 0.7632 - val_loss: 0.9943 - val_accuracy: 0.6342\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6480 - accuracy: 0.7613 - val_loss: 1.0420 - val_accuracy: 0.6409\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6298 - accuracy: 0.7787 - val_loss: 1.0493 - val_accuracy: 0.6510\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6731 - accuracy: 0.7571 - val_loss: 1.0021 - val_accuracy: 0.6577\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6511 - accuracy: 0.7741 - val_loss: 0.9930 - val_accuracy: 0.6711\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6399 - accuracy: 0.7748 - val_loss: 0.9779 - val_accuracy: 0.6711\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6508 - accuracy: 0.7656 - val_loss: 0.9766 - val_accuracy: 0.6846\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6552 - accuracy: 0.7659 - val_loss: 0.9701 - val_accuracy: 0.6711\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6493 - accuracy: 0.7633 - val_loss: 0.9739 - val_accuracy: 0.6812\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6258 - accuracy: 0.7828 - val_loss: 0.9993 - val_accuracy: 0.6644\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6414 - accuracy: 0.7715 - val_loss: 0.9990 - val_accuracy: 0.6711\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6378 - accuracy: 0.7613 - val_loss: 0.9865 - val_accuracy: 0.6812\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6095 - accuracy: 0.7795 - val_loss: 0.9750 - val_accuracy: 0.6846\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5821 - accuracy: 0.8013 - val_loss: 0.9828 - val_accuracy: 0.6611\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5860 - accuracy: 0.7893 - val_loss: 0.9772 - val_accuracy: 0.6711\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6036 - accuracy: 0.7752 - val_loss: 0.9710 - val_accuracy: 0.6577\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6498 - accuracy: 0.7703 - val_loss: 1.0085 - val_accuracy: 0.6510\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6740 - accuracy: 0.7671 - val_loss: 1.0178 - val_accuracy: 0.6644\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6231 - accuracy: 0.7864 - val_loss: 0.9842 - val_accuracy: 0.6812\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6202 - accuracy: 0.7977 - val_loss: 0.9793 - val_accuracy: 0.6711\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6015 - accuracy: 0.7829 - val_loss: 0.9612 - val_accuracy: 0.6745\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.7684 - val_loss: 0.9646 - val_accuracy: 0.6644\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6284 - accuracy: 0.7769 - val_loss: 0.9902 - val_accuracy: 0.6477\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6289 - accuracy: 0.7788 - val_loss: 0.9815 - val_accuracy: 0.6611\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6275 - accuracy: 0.7731 - val_loss: 0.9852 - val_accuracy: 0.6577\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5996 - accuracy: 0.7806 - val_loss: 0.9862 - val_accuracy: 0.6544\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6131 - accuracy: 0.7796 - val_loss: 0.9777 - val_accuracy: 0.6678\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5988 - accuracy: 0.7919 - val_loss: 1.0229 - val_accuracy: 0.6510\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6025 - accuracy: 0.7740 - val_loss: 1.0130 - val_accuracy: 0.6544\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6029 - accuracy: 0.7884 - val_loss: 1.0065 - val_accuracy: 0.6678\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5953 - accuracy: 0.7740 - val_loss: 0.9980 - val_accuracy: 0.6342\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6240 - accuracy: 0.7944 - val_loss: 1.0035 - val_accuracy: 0.6644\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6235 - accuracy: 0.7797 - val_loss: 1.0019 - val_accuracy: 0.6443\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6229 - accuracy: 0.7955 - val_loss: 0.9846 - val_accuracy: 0.6376\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6140 - accuracy: 0.7921 - val_loss: 0.9667 - val_accuracy: 0.6577\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5677 - accuracy: 0.7923 - val_loss: 0.9675 - val_accuracy: 0.6745\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6083 - accuracy: 0.7867 - val_loss: 0.9809 - val_accuracy: 0.6779\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6038 - accuracy: 0.7949 - val_loss: 0.9468 - val_accuracy: 0.6879\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6231 - accuracy: 0.7753 - val_loss: 0.9657 - val_accuracy: 0.6577\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6093 - accuracy: 0.7701 - val_loss: 0.9645 - val_accuracy: 0.6611\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5905 - accuracy: 0.7952 - val_loss: 0.9820 - val_accuracy: 0.6711\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5704 - accuracy: 0.7930 - val_loss: 0.9840 - val_accuracy: 0.6544\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5681 - accuracy: 0.8072 - val_loss: 0.9801 - val_accuracy: 0.6644\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5539 - accuracy: 0.7893 - val_loss: 0.9671 - val_accuracy: 0.6812\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6033 - accuracy: 0.7857 - val_loss: 0.9686 - val_accuracy: 0.6779\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5749 - accuracy: 0.7922 - val_loss: 0.9535 - val_accuracy: 0.6812\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6397 - accuracy: 0.7849 - val_loss: 0.9386 - val_accuracy: 0.6946\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5472 - accuracy: 0.8015 - val_loss: 0.9577 - val_accuracy: 0.6846\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5389 - accuracy: 0.8031 - val_loss: 0.9862 - val_accuracy: 0.6745\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5720 - accuracy: 0.8028 - val_loss: 0.9922 - val_accuracy: 0.6745\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5566 - accuracy: 0.7999 - val_loss: 1.0090 - val_accuracy: 0.6678\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.8130 - val_loss: 1.0195 - val_accuracy: 0.6644\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5735 - accuracy: 0.8064 - val_loss: 0.9949 - val_accuracy: 0.6644\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5526 - accuracy: 0.8026 - val_loss: 0.9747 - val_accuracy: 0.6745\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 0.8012 - val_loss: 0.9940 - val_accuracy: 0.6711\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5990 - accuracy: 0.7936 - val_loss: 0.9699 - val_accuracy: 0.6879\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5796 - accuracy: 0.7948 - val_loss: 0.9979 - val_accuracy: 0.6678\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5645 - accuracy: 0.7960 - val_loss: 0.9586 - val_accuracy: 0.6846\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.7927 - val_loss: 0.9547 - val_accuracy: 0.6846\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5603 - accuracy: 0.7871 - val_loss: 0.9625 - val_accuracy: 0.6946\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5643 - accuracy: 0.7948 - val_loss: 0.9628 - val_accuracy: 0.6980\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5539 - accuracy: 0.8081 - val_loss: 0.9713 - val_accuracy: 0.6711\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5655 - accuracy: 0.7911 - val_loss: 0.9616 - val_accuracy: 0.6745\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5894 - accuracy: 0.7761 - val_loss: 0.9689 - val_accuracy: 0.6745\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5197 - accuracy: 0.8241 - val_loss: 0.9789 - val_accuracy: 0.6644\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5468 - accuracy: 0.8114 - val_loss: 0.9984 - val_accuracy: 0.6745\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5652 - accuracy: 0.8003 - val_loss: 0.9872 - val_accuracy: 0.6678\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5485 - accuracy: 0.7973 - val_loss: 0.9561 - val_accuracy: 0.6779\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5211 - accuracy: 0.8183 - val_loss: 0.9642 - val_accuracy: 0.6879\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5505 - accuracy: 0.7924 - val_loss: 0.9826 - val_accuracy: 0.6745\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5509 - accuracy: 0.7850 - val_loss: 0.9760 - val_accuracy: 0.6577\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5079 - accuracy: 0.8173 - val_loss: 0.9900 - val_accuracy: 0.6577\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5931 - accuracy: 0.7880 - val_loss: 0.9905 - val_accuracy: 0.6812\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6072 - accuracy: 0.7771 - val_loss: 1.0053 - val_accuracy: 0.6879\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5720 - accuracy: 0.7954 - val_loss: 0.9927 - val_accuracy: 0.6846\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5649 - accuracy: 0.7903 - val_loss: 0.9906 - val_accuracy: 0.6980\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5596 - accuracy: 0.8065 - val_loss: 1.0175 - val_accuracy: 0.6879\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5659 - accuracy: 0.7981 - val_loss: 1.0046 - val_accuracy: 0.6678\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5896 - accuracy: 0.7931 - val_loss: 1.0100 - val_accuracy: 0.6644\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.7904 - val_loss: 0.9495 - val_accuracy: 0.6779\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.7811 - val_loss: 0.9492 - val_accuracy: 0.7013\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5478 - accuracy: 0.8097 - val_loss: 0.9484 - val_accuracy: 0.7047\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5502 - accuracy: 0.7895 - val_loss: 0.9801 - val_accuracy: 0.6779\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5925 - accuracy: 0.7861 - val_loss: 0.9843 - val_accuracy: 0.6644\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5067 - accuracy: 0.8245 - val_loss: 0.9852 - val_accuracy: 0.6913\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5453 - accuracy: 0.7956 - val_loss: 0.9819 - val_accuracy: 0.6779\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5307 - accuracy: 0.8070 - val_loss: 0.9778 - val_accuracy: 0.6812\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5234 - accuracy: 0.8056 - val_loss: 0.9565 - val_accuracy: 0.6946\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4797 - accuracy: 0.8392 - val_loss: 0.9521 - val_accuracy: 0.7013\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5435 - accuracy: 0.8007 - val_loss: 0.9651 - val_accuracy: 0.6846\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5076 - accuracy: 0.8226 - val_loss: 0.9609 - val_accuracy: 0.6846\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.8351 - val_loss: 0.9706 - val_accuracy: 0.6644\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5183 - accuracy: 0.8135 - val_loss: 0.9953 - val_accuracy: 0.6745\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4904 - accuracy: 0.8102 - val_loss: 0.9887 - val_accuracy: 0.6711\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5454 - accuracy: 0.8048 - val_loss: 0.9812 - val_accuracy: 0.6779\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5160 - accuracy: 0.8196 - val_loss: 0.9763 - val_accuracy: 0.6879\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4893 - accuracy: 0.8364 - val_loss: 0.9788 - val_accuracy: 0.6745\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5056 - accuracy: 0.8268 - val_loss: 0.9808 - val_accuracy: 0.6812\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4969 - accuracy: 0.8154 - val_loss: 0.9782 - val_accuracy: 0.6678\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5390 - accuracy: 0.8157 - val_loss: 0.9812 - val_accuracy: 0.6879\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5021 - accuracy: 0.8294 - val_loss: 1.0170 - val_accuracy: 0.6946\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5054 - accuracy: 0.8192 - val_loss: 1.0330 - val_accuracy: 0.6913\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4972 - accuracy: 0.8021 - val_loss: 1.0328 - val_accuracy: 0.6846\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4831 - accuracy: 0.8339 - val_loss: 1.0319 - val_accuracy: 0.6812\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4703 - accuracy: 0.8315 - val_loss: 1.0227 - val_accuracy: 0.6779\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5263 - accuracy: 0.8170 - val_loss: 0.9686 - val_accuracy: 0.6879\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5171 - accuracy: 0.8218 - val_loss: 0.9748 - val_accuracy: 0.7114\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5301 - accuracy: 0.8367 - val_loss: 0.9871 - val_accuracy: 0.6879\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4999 - accuracy: 0.8212 - val_loss: 0.9946 - val_accuracy: 0.6913\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4928 - accuracy: 0.8209 - val_loss: 0.9923 - val_accuracy: 0.6946\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5373 - accuracy: 0.8075 - val_loss: 0.9683 - val_accuracy: 0.7047\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4944 - accuracy: 0.8199 - val_loss: 0.9689 - val_accuracy: 0.6846\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5073 - accuracy: 0.8124 - val_loss: 0.9891 - val_accuracy: 0.6779\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4662 - accuracy: 0.8250 - val_loss: 0.9884 - val_accuracy: 0.6812\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5091 - accuracy: 0.8312 - val_loss: 0.9896 - val_accuracy: 0.6913\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5169 - accuracy: 0.8354 - val_loss: 1.0236 - val_accuracy: 0.6745\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.8308 - val_loss: 1.0469 - val_accuracy: 0.6644\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5223 - accuracy: 0.8064 - val_loss: 1.0031 - val_accuracy: 0.6711\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4785 - accuracy: 0.8250 - val_loss: 0.9867 - val_accuracy: 0.6913\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4704 - accuracy: 0.8356 - val_loss: 0.9756 - val_accuracy: 0.6913\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5044 - accuracy: 0.8227 - val_loss: 0.9698 - val_accuracy: 0.6812\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4908 - accuracy: 0.8315 - val_loss: 0.9707 - val_accuracy: 0.6846\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4976 - accuracy: 0.8389 - val_loss: 0.9574 - val_accuracy: 0.6779\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5000 - accuracy: 0.8196 - val_loss: 0.9674 - val_accuracy: 0.6812\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4833 - accuracy: 0.8399 - val_loss: 1.0381 - val_accuracy: 0.6745\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4732 - accuracy: 0.8319 - val_loss: 1.0634 - val_accuracy: 0.6779\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4514 - accuracy: 0.8366 - val_loss: 1.0318 - val_accuracy: 0.6812\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4399 - accuracy: 0.8532 - val_loss: 1.0064 - val_accuracy: 0.6779\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4814 - accuracy: 0.8268 - val_loss: 0.9833 - val_accuracy: 0.6946\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4628 - accuracy: 0.8372 - val_loss: 0.9944 - val_accuracy: 0.6711\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4553 - accuracy: 0.8539 - val_loss: 0.9830 - val_accuracy: 0.6812\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4373 - accuracy: 0.8448 - val_loss: 0.9911 - val_accuracy: 0.6711\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4814 - accuracy: 0.8368 - val_loss: 0.9975 - val_accuracy: 0.6544\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4878 - accuracy: 0.8206 - val_loss: 0.9889 - val_accuracy: 0.6812\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4605 - accuracy: 0.8324 - val_loss: 1.0085 - val_accuracy: 0.6644\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.8371 - val_loss: 1.0009 - val_accuracy: 0.6846\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4500 - accuracy: 0.8412 - val_loss: 1.0253 - val_accuracy: 0.6812\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4826 - accuracy: 0.8279 - val_loss: 1.0259 - val_accuracy: 0.7013\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4652 - accuracy: 0.8150 - val_loss: 1.0389 - val_accuracy: 0.6812\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.8230 - val_loss: 1.0481 - val_accuracy: 0.6812\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4773 - accuracy: 0.8504 - val_loss: 1.0368 - val_accuracy: 0.6812\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3915 - accuracy: 0.8776 - val_loss: 1.0363 - val_accuracy: 0.6711\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4324 - accuracy: 0.8420 - val_loss: 1.0157 - val_accuracy: 0.6711\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4489 - accuracy: 0.8396 - val_loss: 1.0357 - val_accuracy: 0.6879\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4739 - accuracy: 0.8245 - val_loss: 1.0156 - val_accuracy: 0.6846\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5007 - accuracy: 0.8128 - val_loss: 1.0338 - val_accuracy: 0.6711\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4523 - accuracy: 0.8263 - val_loss: 1.0062 - val_accuracy: 0.6846\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4342 - accuracy: 0.8290 - val_loss: 1.0265 - val_accuracy: 0.6779\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4366 - accuracy: 0.8407 - val_loss: 1.0237 - val_accuracy: 0.6779\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.8398 - val_loss: 0.9809 - val_accuracy: 0.6846\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4433 - accuracy: 0.8532 - val_loss: 0.9471 - val_accuracy: 0.6946\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4604 - accuracy: 0.8316 - val_loss: 0.9304 - val_accuracy: 0.7013\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4557 - accuracy: 0.8282 - val_loss: 0.9276 - val_accuracy: 0.7047\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4745 - accuracy: 0.8465 - val_loss: 0.9318 - val_accuracy: 0.7148\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4519 - accuracy: 0.8401 - val_loss: 0.9596 - val_accuracy: 0.6946\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4280 - accuracy: 0.8539 - val_loss: 0.9902 - val_accuracy: 0.6879\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4510 - accuracy: 0.8303 - val_loss: 0.9895 - val_accuracy: 0.6913\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4354 - accuracy: 0.8458 - val_loss: 0.9772 - val_accuracy: 0.6980\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3983 - accuracy: 0.8679 - val_loss: 0.9951 - val_accuracy: 0.6980\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4015 - accuracy: 0.8743 - val_loss: 1.0127 - val_accuracy: 0.6846\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4222 - accuracy: 0.8362 - val_loss: 0.9975 - val_accuracy: 0.6879\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4464 - accuracy: 0.8426 - val_loss: 0.9707 - val_accuracy: 0.6913\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.8569 - val_loss: 0.9834 - val_accuracy: 0.6913\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5011 - accuracy: 0.8351 - val_loss: 0.9820 - val_accuracy: 0.6946\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.8370 - val_loss: 0.9838 - val_accuracy: 0.6879\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4085 - accuracy: 0.8636 - val_loss: 0.9926 - val_accuracy: 0.6745\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4209 - accuracy: 0.8561 - val_loss: 0.9986 - val_accuracy: 0.6913\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4058 - accuracy: 0.8615 - val_loss: 0.9927 - val_accuracy: 0.6879\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4097 - accuracy: 0.8634 - val_loss: 0.9781 - val_accuracy: 0.6913\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.8375 - val_loss: 0.9994 - val_accuracy: 0.6980\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4101 - accuracy: 0.8745 - val_loss: 1.0200 - val_accuracy: 0.6946\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4181 - accuracy: 0.8469 - val_loss: 1.0233 - val_accuracy: 0.6879\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3933 - accuracy: 0.8706 - val_loss: 1.0157 - val_accuracy: 0.7013\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8425 - val_loss: 1.0177 - val_accuracy: 0.6913\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4147 - accuracy: 0.8428 - val_loss: 1.0205 - val_accuracy: 0.6913\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4379 - accuracy: 0.8497 - val_loss: 1.0155 - val_accuracy: 0.6913\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4224 - accuracy: 0.8557 - val_loss: 1.0293 - val_accuracy: 0.6745\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4128 - accuracy: 0.8429 - val_loss: 1.0031 - val_accuracy: 0.6846\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4181 - accuracy: 0.8461 - val_loss: 1.0156 - val_accuracy: 0.6812\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4224 - accuracy: 0.8510 - val_loss: 1.0022 - val_accuracy: 0.6745\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4294 - accuracy: 0.8357 - val_loss: 1.0114 - val_accuracy: 0.6846\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4222 - accuracy: 0.8529 - val_loss: 0.9980 - val_accuracy: 0.6879\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3905 - accuracy: 0.8698 - val_loss: 1.0067 - val_accuracy: 0.6879\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3790 - accuracy: 0.8669 - val_loss: 1.0451 - val_accuracy: 0.7047\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4201 - accuracy: 0.8558 - val_loss: 1.0569 - val_accuracy: 0.6711\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8536 - val_loss: 1.0537 - val_accuracy: 0.6812\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4150 - accuracy: 0.8543 - val_loss: 1.0464 - val_accuracy: 0.6779\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3698 - accuracy: 0.8657 - val_loss: 1.0159 - val_accuracy: 0.6879\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4003 - accuracy: 0.8683 - val_loss: 1.0117 - val_accuracy: 0.6946\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4203 - accuracy: 0.8540 - val_loss: 1.0289 - val_accuracy: 0.6946\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3858 - accuracy: 0.8628 - val_loss: 1.0519 - val_accuracy: 0.6846\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3948 - accuracy: 0.8633 - val_loss: 1.0565 - val_accuracy: 0.6913\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4212 - accuracy: 0.8554 - val_loss: 1.0276 - val_accuracy: 0.6946\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3869 - accuracy: 0.8822 - val_loss: 1.0032 - val_accuracy: 0.6846\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3839 - accuracy: 0.8660 - val_loss: 1.0301 - val_accuracy: 0.6745\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4261 - accuracy: 0.8484 - val_loss: 1.0375 - val_accuracy: 0.6779\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8466 - val_loss: 1.0225 - val_accuracy: 0.6812\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3594 - accuracy: 0.8852 - val_loss: 1.0094 - val_accuracy: 0.6711\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 0.8846 - val_loss: 1.0095 - val_accuracy: 0.6745\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3871 - accuracy: 0.8483 - val_loss: 0.9960 - val_accuracy: 0.6913\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3892 - accuracy: 0.8605 - val_loss: 0.9653 - val_accuracy: 0.6946\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3887 - accuracy: 0.8686 - val_loss: 0.9631 - val_accuracy: 0.6879\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - accuracy: 0.8765 - val_loss: 0.9986 - val_accuracy: 0.6745\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3782 - accuracy: 0.8656 - val_loss: 1.0075 - val_accuracy: 0.6711\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3958 - accuracy: 0.8649 - val_loss: 1.0409 - val_accuracy: 0.6779\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3816 - accuracy: 0.8545 - val_loss: 1.0621 - val_accuracy: 0.6913\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3618 - accuracy: 0.8673 - val_loss: 1.0178 - val_accuracy: 0.6779\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3887 - accuracy: 0.8596 - val_loss: 1.0132 - val_accuracy: 0.6812\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3573 - accuracy: 0.8926 - val_loss: 1.0326 - val_accuracy: 0.6913\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4307 - accuracy: 0.8464 - val_loss: 1.0054 - val_accuracy: 0.7081\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.8759 - val_loss: 0.9673 - val_accuracy: 0.6913\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3959 - accuracy: 0.8720 - val_loss: 0.9694 - val_accuracy: 0.6980\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.8621 - val_loss: 0.9713 - val_accuracy: 0.6913\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.8485 - val_loss: 1.0167 - val_accuracy: 0.7013\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4355 - accuracy: 0.8584 - val_loss: 1.0107 - val_accuracy: 0.6879\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3392 - accuracy: 0.8928 - val_loss: 1.0159 - val_accuracy: 0.6913\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3664 - accuracy: 0.8841 - val_loss: 1.0070 - val_accuracy: 0.6812\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.8687 - val_loss: 1.0025 - val_accuracy: 0.6846\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3923 - accuracy: 0.8687 - val_loss: 1.0163 - val_accuracy: 0.6946\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4033 - accuracy: 0.8620 - val_loss: 0.9873 - val_accuracy: 0.6980\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3693 - accuracy: 0.8685 - val_loss: 0.9701 - val_accuracy: 0.6779\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3772 - accuracy: 0.8704 - val_loss: 0.9582 - val_accuracy: 0.6745\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3795 - accuracy: 0.8658 - val_loss: 0.9816 - val_accuracy: 0.6946\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3764 - accuracy: 0.8733 - val_loss: 0.9625 - val_accuracy: 0.6980\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3772 - accuracy: 0.8689 - val_loss: 0.9812 - val_accuracy: 0.7013\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3465 - accuracy: 0.8809 - val_loss: 1.0135 - val_accuracy: 0.6946\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3440 - accuracy: 0.8774 - val_loss: 1.0562 - val_accuracy: 0.6711\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3769 - accuracy: 0.8750 - val_loss: 1.0134 - val_accuracy: 0.6644\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3897 - accuracy: 0.8595 - val_loss: 0.9796 - val_accuracy: 0.6879\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3475 - accuracy: 0.8864 - val_loss: 0.9696 - val_accuracy: 0.7081\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - accuracy: 0.8614 - val_loss: 1.0005 - val_accuracy: 0.7013\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3368 - accuracy: 0.8861 - val_loss: 0.9999 - val_accuracy: 0.7013\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3759 - accuracy: 0.8768 - val_loss: 0.9880 - val_accuracy: 0.6913\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3253 - accuracy: 0.8902 - val_loss: 0.9703 - val_accuracy: 0.6980\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3575 - accuracy: 0.8704 - val_loss: 0.9712 - val_accuracy: 0.7081\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3500 - accuracy: 0.8788 - val_loss: 0.9622 - val_accuracy: 0.7181\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3113 - accuracy: 0.8948 - val_loss: 0.9423 - val_accuracy: 0.7215\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3455 - accuracy: 0.8836 - val_loss: 0.9537 - val_accuracy: 0.6980\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3389 - accuracy: 0.8802 - val_loss: 0.9765 - val_accuracy: 0.6946\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3680 - accuracy: 0.8689 - val_loss: 1.0010 - val_accuracy: 0.7013\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8689 - val_loss: 0.9724 - val_accuracy: 0.6913\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.8854 - val_loss: 0.9816 - val_accuracy: 0.6846\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3434 - accuracy: 0.8848 - val_loss: 1.0036 - val_accuracy: 0.6879\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3448 - accuracy: 0.8896 - val_loss: 1.0084 - val_accuracy: 0.6980\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3508 - accuracy: 0.8720 - val_loss: 0.9872 - val_accuracy: 0.6779\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3616 - accuracy: 0.8740 - val_loss: 0.9969 - val_accuracy: 0.6946\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3294 - accuracy: 0.8927 - val_loss: 1.0266 - val_accuracy: 0.6846\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3396 - accuracy: 0.8924 - val_loss: 1.0042 - val_accuracy: 0.6846\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3833 - accuracy: 0.8706 - val_loss: 0.9858 - val_accuracy: 0.6946\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3561 - accuracy: 0.8678 - val_loss: 0.9628 - val_accuracy: 0.7013\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3144 - accuracy: 0.8943 - val_loss: 0.9652 - val_accuracy: 0.6913\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3654 - accuracy: 0.8734 - val_loss: 0.9998 - val_accuracy: 0.6913\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3514 - accuracy: 0.8893 - val_loss: 0.9828 - val_accuracy: 0.6879\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3535 - accuracy: 0.8809 - val_loss: 0.9648 - val_accuracy: 0.6879\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3574 - accuracy: 0.8769 - val_loss: 0.9617 - val_accuracy: 0.6879\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3370 - accuracy: 0.8898 - val_loss: 0.9892 - val_accuracy: 0.6913\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3489 - accuracy: 0.8810 - val_loss: 1.0083 - val_accuracy: 0.6879\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3391 - accuracy: 0.8799 - val_loss: 1.0160 - val_accuracy: 0.6779\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3547 - accuracy: 0.8802 - val_loss: 1.0122 - val_accuracy: 0.6913\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3539 - accuracy: 0.8790 - val_loss: 1.0213 - val_accuracy: 0.6913\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3180 - accuracy: 0.8846 - val_loss: 1.0003 - val_accuracy: 0.6779\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3235 - accuracy: 0.9024 - val_loss: 1.0041 - val_accuracy: 0.6711\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3386 - accuracy: 0.8786 - val_loss: 1.0089 - val_accuracy: 0.6879\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3197 - accuracy: 0.8830 - val_loss: 1.0036 - val_accuracy: 0.6879\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.8792 - val_loss: 1.0223 - val_accuracy: 0.6913\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3182 - accuracy: 0.8842 - val_loss: 1.0657 - val_accuracy: 0.6980\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3378 - accuracy: 0.8807 - val_loss: 1.0183 - val_accuracy: 0.7013\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.8846 - val_loss: 0.9601 - val_accuracy: 0.7181\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3268 - accuracy: 0.8916 - val_loss: 0.9384 - val_accuracy: 0.7047\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3312 - accuracy: 0.8967 - val_loss: 0.9606 - val_accuracy: 0.6980\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3542 - accuracy: 0.8739 - val_loss: 0.9555 - val_accuracy: 0.6980\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3429 - accuracy: 0.8780 - val_loss: 0.9878 - val_accuracy: 0.6846\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3513 - accuracy: 0.8786 - val_loss: 1.0498 - val_accuracy: 0.6779\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3159 - accuracy: 0.8896 - val_loss: 1.1028 - val_accuracy: 0.6644\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3233 - accuracy: 0.8857 - val_loss: 1.1133 - val_accuracy: 0.6913\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3304 - accuracy: 0.8891 - val_loss: 1.0876 - val_accuracy: 0.6980\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3113 - accuracy: 0.8960 - val_loss: 1.0644 - val_accuracy: 0.6846\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.8922 - val_loss: 1.0610 - val_accuracy: 0.6779\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3468 - accuracy: 0.8822 - val_loss: 1.0524 - val_accuracy: 0.6913\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3006 - accuracy: 0.8965 - val_loss: 1.0676 - val_accuracy: 0.6946\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3075 - accuracy: 0.8838 - val_loss: 1.0509 - val_accuracy: 0.6812\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3392 - accuracy: 0.8839 - val_loss: 1.0195 - val_accuracy: 0.6913\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.9038 - val_loss: 1.0202 - val_accuracy: 0.6846\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.8903 - val_loss: 1.0173 - val_accuracy: 0.6913\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2986 - accuracy: 0.8954 - val_loss: 1.0827 - val_accuracy: 0.7013\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3234 - accuracy: 0.8909 - val_loss: 1.0859 - val_accuracy: 0.7081\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2973 - accuracy: 0.8945 - val_loss: 1.0710 - val_accuracy: 0.6913\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3415 - accuracy: 0.8794 - val_loss: 1.0695 - val_accuracy: 0.6980\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.8926 - val_loss: 1.0315 - val_accuracy: 0.7047\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2760 - accuracy: 0.9145 - val_loss: 1.0013 - val_accuracy: 0.7148\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3192 - accuracy: 0.8986 - val_loss: 0.9875 - val_accuracy: 0.6946\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.9134 - val_loss: 1.0017 - val_accuracy: 0.6846\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3079 - accuracy: 0.8922 - val_loss: 1.0004 - val_accuracy: 0.7013\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3009 - accuracy: 0.8882 - val_loss: 0.9938 - val_accuracy: 0.7148\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3224 - accuracy: 0.8986 - val_loss: 1.0095 - val_accuracy: 0.7013\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3035 - accuracy: 0.8967 - val_loss: 1.0263 - val_accuracy: 0.7047\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3090 - accuracy: 0.8965 - val_loss: 0.9988 - val_accuracy: 0.6913\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3151 - accuracy: 0.8879 - val_loss: 1.0399 - val_accuracy: 0.6879\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2818 - accuracy: 0.9028 - val_loss: 1.1050 - val_accuracy: 0.6846\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2984 - accuracy: 0.9097 - val_loss: 1.1072 - val_accuracy: 0.6812\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2780 - accuracy: 0.9123 - val_loss: 1.0744 - val_accuracy: 0.6812\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3152 - accuracy: 0.8975 - val_loss: 1.0238 - val_accuracy: 0.6980\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3004 - accuracy: 0.9058 - val_loss: 1.0308 - val_accuracy: 0.6980\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2863 - accuracy: 0.9025 - val_loss: 1.0217 - val_accuracy: 0.6711\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3202 - accuracy: 0.8976 - val_loss: 1.0227 - val_accuracy: 0.6879\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3010 - accuracy: 0.9008 - val_loss: 1.0210 - val_accuracy: 0.6879\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2870 - accuracy: 0.8974 - val_loss: 1.0346 - val_accuracy: 0.6980\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3197 - accuracy: 0.8908 - val_loss: 1.0574 - val_accuracy: 0.6711\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2685 - accuracy: 0.9156 - val_loss: 1.0567 - val_accuracy: 0.6879\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2992 - accuracy: 0.8963 - val_loss: 1.0854 - val_accuracy: 0.7013\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2772 - accuracy: 0.9078 - val_loss: 1.0604 - val_accuracy: 0.6812\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2994 - accuracy: 0.9055 - val_loss: 1.0424 - val_accuracy: 0.6946\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3411 - accuracy: 0.8882 - val_loss: 1.0068 - val_accuracy: 0.6779\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2874 - accuracy: 0.9041 - val_loss: 0.9761 - val_accuracy: 0.6879\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2820 - accuracy: 0.9012 - val_loss: 0.9721 - val_accuracy: 0.6980\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3269 - accuracy: 0.8823 - val_loss: 1.0197 - val_accuracy: 0.6946\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3110 - accuracy: 0.9022 - val_loss: 1.0527 - val_accuracy: 0.7148\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2858 - accuracy: 0.8981 - val_loss: 1.0706 - val_accuracy: 0.6711\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2882 - accuracy: 0.9028 - val_loss: 1.0559 - val_accuracy: 0.6779\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2976 - accuracy: 0.8961 - val_loss: 1.0210 - val_accuracy: 0.6879\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3038 - accuracy: 0.9036 - val_loss: 1.0056 - val_accuracy: 0.7013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "om2osA1gA8Pz",
        "outputId": "81a99f99-6a78-4552-8a59-e7c5ef1d55cb"
      },
      "source": [
        "plotter(history)\n",
        "\n",
        "model.summary()\n",
        "result = model.evaluate(X_test,y_test)\n",
        "print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_11 (ModuleWra (None, 153, 64)           704       \n",
            "_________________________________________________________________\n",
            "module_wrapper_12 (ModuleWra (None, 144, 128)          82048     \n",
            "_________________________________________________________________\n",
            "module_wrapper_13 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_14 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_15 (ModuleWra (None, 9, 128)            163968    \n",
            "_________________________________________________________________\n",
            "module_wrapper_16 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_17 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_18 (ModuleWra (None, 1, 64)             41024     \n",
            "_________________________________________________________________\n",
            "module_wrapper_19 (ModuleWra (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_20 (ModuleWra (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_21 (ModuleWra (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "module_wrapper_22 (ModuleWra (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_23 (ModuleWra (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 306,440\n",
            "Trainable params: 306,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0056 - accuracy: 0.7013\n",
            "[1.0055959224700928, 0.7013422846794128]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COcIH-7CJZgy"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# X = Features.iloc[: ,:-1].values\n",
        "# y = Features['labels'].values\n",
        "\n",
        "# X = np.array(X)\n",
        "# y = np.array(y)\n",
        "# h,w = X.shape\n",
        "# X = X.reshape(h,w,1)\n",
        "# h = y.shape[0]\n",
        "# y = y.reshape(h,1)\n",
        "\n",
        "# X.shape, y.shape\n",
        "\n",
        "#### To be changed with data not random distribution\n",
        "# encoder = OneHotEncoder()\n",
        "# y = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, shuffle=False)\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# X_train = tf.expand_dims(X_train, axis=-1)\n",
        "# y_train = tf.expand_dims(y_train, axis=-1)\n",
        "# X_test = tf.expand_dims(X_test, axis=-1)\n",
        "# y_test = tf.expand_dims(y_test, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_j2iJM_Ji2f"
      },
      "source": [
        "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s47IPH-MGt-F"
      },
      "source": [
        "# #building CNN model \n",
        "# from keras import models\n",
        "# from keras import layers\n",
        "# from tensorflow.compat.v1 import ConfigProto\n",
        "# from tensorflow.compat.v1 import InteractiveSession\n",
        "# import tensorflow as tf\n",
        "# import tensorflow.keras \n",
        "\n",
        "# config = ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBqIfA1PBSOw"
      },
      "source": [
        "# model=models.Sequential()\n",
        "# model.add(tf.keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(X_train.shape, 1)))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# model.add(tf.keras.layers.Dense(units=8, activation='softmax'))\n",
        "# model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epkNrKQW1l4a"
      },
      "source": [
        "# input_shape=[X_train.shape, 1]\n",
        "# model = models.Sequential([\n",
        "#                             tf.keras.layers.Conv2D(128, 3, activation=tf.nn.relu, input_shape=input_shape),\n",
        "#                             tf.keras.layers.MaxPooling2D(2),\n",
        "#                             tf.keras.layers.Dropout(0.2),\n",
        "#                             tf.keras.layers.Conv2D(64, 3, activation=tf.nn.relu),\n",
        "#                             tf.keras.layers.MaxPooling2D(2),\n",
        "#                             tf.keras.layers.Dropout(0.2),\n",
        "#                             tf.keras.layers.Conv2D(64, 3, activation=tf.nn.relu),\n",
        "#                             tf.keras.layers.MaxPooling2D(2),\n",
        "#                             tf.keras.layers.Dropout(0.2),\n",
        "#                             tf.keras.layers.Conv2D(32, 3, activation=tf.nn.relu),\n",
        "#                             tf.keras.layers.MaxPooling2D(2),\n",
        "#                             tf.keras.layers.Dropout(0.2),\n",
        "                           \n",
        "#                             tf.keras.layers.Flatten(),\n",
        "#                             tf.keras.layers.Dense(8, activation=tf.nn.softmax)\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_P11qyK5lb"
      },
      "source": [
        "# history = model.fit(X_train,y_train,batch_size=256,epochs = 200,verbose=1,validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMJlhjEXK8Ax"
      },
      "source": [
        "# plotter(history)\n",
        "\n",
        "# model.summary()\n",
        "# result = model.evaluate(X_test,y_test)\n",
        "# print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}